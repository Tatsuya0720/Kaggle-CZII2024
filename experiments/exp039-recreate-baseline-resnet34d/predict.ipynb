{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import timm\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# import torchvision.transforms.functional as F\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import Unet3D\n",
    "from src.utils import save_images, PadToSize\n",
    "from src.metric import (\n",
    "    score,\n",
    "    create_cls_pos,\n",
    "    create_cls_pos_sikii,\n",
    "    create_df,\n",
    "    SegmentationLoss,\n",
    "    DiceLoss,\n",
    ")\n",
    "from metric import visualize_epoch_results\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "padf = PadToSize(CFG.resolution)\n",
    "\n",
    "\n",
    "def last_padding(tomogram, slice_size):\n",
    "    # tomogram: (tensor)\n",
    "    b, d, h, w = tomogram.shape\n",
    "    last_padding = slice_size - d % slice_size\n",
    "    if last_padding == slice_size:\n",
    "        return tomogram\n",
    "    else:\n",
    "        return torch.cat(\n",
    "            [tomogram, torch.zeros(b, last_padding, h, w).to(tomogram.device)], dim=1\n",
    "        )\n",
    "\n",
    "\n",
    "def preprocess_tensor(tensor):\n",
    "    batch_size, depth, height, width = tensor.shape\n",
    "    tensor = tensor.unsqueeze(2)  # (b, d, h, w) -> (b, d, 1, h, w)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def inference(model, exp_name, train=True):\n",
    "    dataset = EziiDataset(\n",
    "        exp_names=[exp_name],\n",
    "        base_dir=\"../../inputs/train/\",\n",
    "        particles_name=CFG.particles_name,\n",
    "        resolution=CFG.resolution,\n",
    "        zarr_type=[\"denoised\"],\n",
    "        train=train,\n",
    "        slice=False,\n",
    "    )\n",
    "    res_array = CFG.original_img_shape[CFG.resolution]\n",
    "    pred_array = np.zeros(\n",
    "        (len(CFG.particles_name) + 1, res_array[0], res_array[1], res_array[2])\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "    model.eval()\n",
    "    # tq = tqdm(loader)\n",
    "    for data in loader:  # 実験データ1つを取り出す\n",
    "        for i in range(0, data[\"normalized_tomogram\"].shape[1], CFG.slice_):\n",
    "            normalized_tomogram = data[\"normalized_tomogram\"][:, i : i + CFG.slice_]\n",
    "            normalized_tomogram = last_padding(normalized_tomogram, CFG.slice_)\n",
    "            normalized_tomogram = padf(normalized_tomogram)\n",
    "            normalized_tomogram = preprocess_tensor(normalized_tomogram).to(\"cuda\")\n",
    "            pred = model(normalized_tomogram)\n",
    "            prob_pred = (\n",
    "                torch.softmax(pred, dim=1).detach().cpu().numpy()\n",
    "            )  # torch.Size([1, 7, 32, 320, 320])\n",
    "            range_ = min(i + CFG.slice_, res_array[0])\n",
    "            hw_pad_diff = prob_pred.shape[-1] - res_array[-1]\n",
    "\n",
    "            if i >= res_array[0]:\n",
    "                continue\n",
    "\n",
    "            if range_ == res_array[0]:\n",
    "                pred_array[:, i:range_] += prob_pred[\n",
    "                    0, :, : res_array[0] - i, :-hw_pad_diff, :-hw_pad_diff\n",
    "                ]\n",
    "            else:\n",
    "                pred_array[:, i:range_] += prob_pred[\n",
    "                    0, :, :range_, :-hw_pad_diff, :-hw_pad_diff\n",
    "                ]\n",
    "\n",
    "        if train:\n",
    "            segmentation_map = data[\"segmentation_map\"]\n",
    "        else:\n",
    "            segmentation_map = None\n",
    "\n",
    "        normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "    # tq.close()\n",
    "\n",
    "    return pred_array, normalized_tomogram, segmentation_map  # (7, 92, 315, 315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./pretrained_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:11,  2.79s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ############### validation ################\n",
    "train_nshuffle_original_tomogram = defaultdict(list)\n",
    "train_nshuffle_pred_tomogram = defaultdict(list)\n",
    "train_nshuffle_gt_tomogram = defaultdict(list)\n",
    "train_cls_pos = defaultdict(list)\n",
    "train_cls_Apos = defaultdict(list)\n",
    "\n",
    "valid_original_tomogram = defaultdict(list)\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "valid_cls_pos = defaultdict(list)\n",
    "valid_cls_Apos = defaultdict(list)\n",
    "\n",
    "train_mean_scores = []\n",
    "valid_mean_scores = []\n",
    "\n",
    "# for exp_name in tqdm(CFG.train_exp_names):\n",
    "for exp_name in tqdm(CFG.train_exp_names):  # 5つのデータで試す\n",
    "    inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "        model, exp_name, train=True\n",
    "    )\n",
    "    train_nshuffle_pred_tomogram[exp_name] = inferenced_array\n",
    "    train_nshuffle_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "    train_nshuffle_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "    mean_score, scores, pred_df, gt_df, pred_cls_pos, pred_Ascale_pos = (\n",
    "        visualize_epoch_results(\n",
    "            train_nshuffle_pred_tomogram,\n",
    "            base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "            sikii_dict=CFG.initial_sikii,\n",
    "        )\n",
    "    )\n",
    "    train_cls_pos[exp_name] = pred_cls_pos\n",
    "    train_cls_Apos[exp_name] = pred_Ascale_pos\n",
    "    train_mean_scores.append(mean_score)\n",
    "print(\"train_mean_scores\", np.mean(train_mean_scores))\n",
    "\n",
    "for exp_name in tqdm(CFG.valid_exp_names):\n",
    "    inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "        model, exp_name, train=True\n",
    "    )\n",
    "    valid_pred_tomogram[exp_name] = inferenced_array\n",
    "    valid_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "    valid_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "    mean_score, scores, pred_df, gt_df, pred_cls_pos, pred_Ascale_pos = (\n",
    "        visualize_epoch_results(\n",
    "            valid_pred_tomogram,\n",
    "            base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "            sikii_dict=CFG.initial_sikii,\n",
    "        )\n",
    "    )\n",
    "    valid_cls_pos[exp_name] = pred_cls_pos\n",
    "    valid_cls_Apos[exp_name] = pred_Ascale_pos\n",
    "    valid_mean_scores.append(mean_score)\n",
    "print(\"valid_mean_scores\", np.mean(valid_mean_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[pred_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[gt_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "num_classes = len(CFG.particles_name)  # クラス数\n",
    "colors = plt.cm.tab10(\n",
    "    np.arange(len(CFG.particles_name))\n",
    ")  # \"tab10\" カラーマップから色を取得\n",
    "\n",
    "# ListedColormap を作成\n",
    "class_colormap = ListedColormap(colors)\n",
    "\n",
    "\n",
    "def plot_with_colormap(data, title, original_tomogram):\n",
    "    masked_data = np.ma.masked_where(data <= 0, data)  # クラス0をマスク\n",
    "    plt.imshow(original_tomogram, cmap=\"gray\")\n",
    "    im = plt.imshow(masked_data, cmap=class_colormap)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    return im\n",
    "\n",
    "\n",
    "def imshow_result(pred, gt, original, index):\n",
    "    # plt.figure(figsize=(20, 5))\n",
    "    ax = plt.subplot(1, 3, 1)\n",
    "    plot_with_colormap(\n",
    "        pred[index],\n",
    "        \"Train-Prediction\",\n",
    "        original[index],\n",
    "    )\n",
    "    ax = plt.subplot(1, 3, 2)\n",
    "    plot_with_colormap(gt[index], \"Gt\", original[index])\n",
    "\n",
    "    ax = plt.subplot(1, 3, 3)\n",
    "    plt.imshow(original[index], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"TS_5_4\"\n",
    "index = 12\n",
    "pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# imshow_result(pred, gt, original, index)\n",
    "\n",
    "for i in range(42):\n",
    "    imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"TS_5_4\"\n",
    "index = 12\n",
    "pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# imshow_result(pred, gt, original, index)\n",
    "\n",
    "for i in range(42):\n",
    "    imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = CFG.valid_exp_names[-1]\n",
    "\n",
    "pred = valid_pred_tomogram[exp_name].argmax(0)\n",
    "gt = valid_gt_tomogram[exp_name]\n",
    "original = valid_original_tomogram[exp_name]\n",
    "\n",
    "for i in range(42):\n",
    "    imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TS_69_2', array([  6. ,   3.5, 157. , 157. ]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = CFG.train_exp_names[-1]\n",
    "\n",
    "pred_cls_pos = train_cls_pos[exp_name]\n",
    "\n",
    "exp_name, np.array(pred_cls_pos).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cls_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = CFG.valid_exp_names[0]\n",
    "\n",
    "pred_cls_pos = valid_cls_pos[exp_name]\n",
    "\n",
    "np.array(pred_cls_pos).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 apo-ferritin\n",
      "2 beta-amylase\n",
      "3 beta-galactosidase\n",
      "4 ribosome\n",
      "5 thyroglobulin\n",
      "6 virus-like-particle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9433021415117242"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exp_name = CFG.valid_exp_names[0]\n",
    "# pred = valid_pred_tomogram[exp_name].argmax(0)\n",
    "# gt = valid_gt_tomogram[exp_name]\n",
    "# original = valid_original_tomogram[exp_name]\n",
    "\n",
    "exp_name = CFG.train_exp_names[2]\n",
    "pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)\n",
    "gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "import cc3d\n",
    "\n",
    "cls_pos = []\n",
    "Ascale_pos = []\n",
    "res2ratio = CFG.resolution2ratio\n",
    "\n",
    "for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "    print(pred_cls, CFG.cls2particles[pred_cls])\n",
    "    cc, P = cc3d.connected_components(pred == pred_cls, return_N=True)\n",
    "    stats = cc3d.statistics(cc)\n",
    "\n",
    "    for z, y, x in stats[\"centroids\"]:\n",
    "        Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "        Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "        Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "        cls_pos.append([pred_cls, z, y, x])\n",
    "        Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "\n",
    "score(\n",
    "    pred_original_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
