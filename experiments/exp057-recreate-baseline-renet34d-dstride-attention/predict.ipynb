{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import timm\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# import torchvision.transforms.functional as F\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import Unet3D\n",
    "from src.utils import save_images, PadToSize\n",
    "from src.metric import (\n",
    "    score,\n",
    "    create_cls_pos,\n",
    "    create_cls_pos_sikii,\n",
    "    create_df,\n",
    "    SegmentationLoss,\n",
    "    DiceLoss,\n",
    ")\n",
    "from metric import visualize_epoch_results\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "from src.inference import inference, inference2pos\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padf = PadToSize(CFG.resolution)\n",
    "\n",
    "\n",
    "# def last_padding(tomogram, slice_size):\n",
    "#     # tomogram: (tensor)\n",
    "#     b, d, h, w = tomogram.shape\n",
    "#     last_padding = slice_size - d % slice_size\n",
    "#     if last_padding == slice_size:\n",
    "#         return tomogram\n",
    "#     else:\n",
    "#         return torch.cat(\n",
    "#             [tomogram, torch.zeros(b, last_padding, h, w).to(tomogram.device)], dim=1\n",
    "#         )\n",
    "\n",
    "\n",
    "# def preprocess_tensor(tensor):\n",
    "#     batch_size, depth, height, width = tensor.shape\n",
    "#     tensor = tensor.unsqueeze(2)  # (b, d, h, w) -> (b, d, 1, h, w)\n",
    "#     return tensor\n",
    "\n",
    "\n",
    "# def inference(model, exp_name, train=True):\n",
    "#     dataset = EziiDataset(\n",
    "#         exp_names=[exp_name],\n",
    "#         base_dir=\"../../inputs/train/\",\n",
    "#         particles_name=CFG.particles_name,\n",
    "#         resolution=CFG.resolution,\n",
    "#         zarr_type=[\"denoised\"],\n",
    "#         train=train,\n",
    "#         slice=False,\n",
    "#     )\n",
    "#     res_array = CFG.original_img_shape[CFG.resolution]\n",
    "#     pred_array = np.zeros(\n",
    "#         (len(CFG.particles_name) + 1, res_array[0], res_array[1], res_array[2])\n",
    "#     )\n",
    "#     loader = DataLoader(dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "#     model.eval()\n",
    "#     # tq = tqdm(loader)\n",
    "#     for data in loader:  # 実験データ1つを取り出す\n",
    "#         for i in range(0, data[\"normalized_tomogram\"].shape[1], CFG.slice_):\n",
    "#             normalized_tomogram = data[\"normalized_tomogram\"][:, i : i + CFG.slice_]\n",
    "#             normalized_tomogram = last_padding(normalized_tomogram, CFG.slice_)\n",
    "#             normalized_tomogram = padf(normalized_tomogram)\n",
    "#             normalized_tomogram = preprocess_tensor(normalized_tomogram).to(\"cuda\")\n",
    "#             pred = model(normalized_tomogram)\n",
    "#             prob_pred = (\n",
    "#                 torch.softmax(pred, dim=1).detach().cpu().numpy()\n",
    "#             )  # torch.Size([1, 7, 32, 320, 320])\n",
    "#             range_ = min(i + CFG.slice_, res_array[0])\n",
    "#             hw_pad_diff = prob_pred.shape[-1] - res_array[-1]\n",
    "\n",
    "#             if i >= res_array[0]:\n",
    "#                 continue\n",
    "\n",
    "#             if range_ == res_array[0]:\n",
    "#                 pred_array[:, i:range_] += prob_pred[\n",
    "#                     0, :, : res_array[0] - i, :-hw_pad_diff, :-hw_pad_diff\n",
    "#                 ]\n",
    "#             else:\n",
    "#                 pred_array[:, i:range_] += prob_pred[\n",
    "#                     0, :, :range_, :-hw_pad_diff, :-hw_pad_diff\n",
    "#                 ]\n",
    "\n",
    "#         if train:\n",
    "#             segmentation_map = data[\"segmentation_map\"]\n",
    "#         else:\n",
    "#             segmentation_map = None\n",
    "\n",
    "#         normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "#     # tq.close()\n",
    "\n",
    "#     return pred_array, normalized_tomogram, segmentation_map  # (7, 92, 315, 315)\n",
    "\n",
    "\n",
    "# def inference2pos(pred_segmask, exp_name):\n",
    "#     import cc3d\n",
    "\n",
    "#     cls_pos = []\n",
    "#     Ascale_pos = []\n",
    "#     res2ratio = CFG.resolution2ratio\n",
    "\n",
    "#     for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#         print(pred_cls, CFG.cls2particles[pred_cls])\n",
    "#         cc, P = cc3d.connected_components(pred_segmask == pred_cls, return_N=True)\n",
    "#         stats = cc3d.statistics(cc)\n",
    "\n",
    "#         for z, y, x in stats[\"centroids\"]:\n",
    "#             Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#             cls_pos.append([pred_cls, z, y, x])\n",
    "#             Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "#     pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "\n",
    "#     return pred_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = EziiDataset(\n",
    "#     exp_names=CFG.train_exp_names,\n",
    "#     base_dir=\"../../inputs/train/\",\n",
    "#     particles_name=CFG.particles_name,\n",
    "#     resolution=CFG.resolution,\n",
    "#     zarr_type=CFG.train_zarr_types,\n",
    "#     train=True,\n",
    "#     augmentation=False,\n",
    "#     slice=False,\n",
    "#     pre_read=True,\n",
    "# )\n",
    "\n",
    "# # train_nshuffle_dataset = EziiDataset(\n",
    "# #     exp_names=CFG.train_exp_names,\n",
    "# #     base_dir=\"../../inputs/train/\",\n",
    "# #     particles_name=CFG.particles_name,\n",
    "# #     resolution=CFG.resolution,\n",
    "# #     zarr_type=CFG.train_zarr_types,\n",
    "# #     augmentation=False,\n",
    "# #     train=True,\n",
    "# # )\n",
    "\n",
    "# valid_dataset = EziiDataset(\n",
    "#     exp_names=CFG.valid_exp_names,\n",
    "#     base_dir=\"../../inputs/train/\",\n",
    "#     particles_name=CFG.particles_name,\n",
    "#     resolution=CFG.resolution,\n",
    "#     zarr_type=CFG.valid_zarr_types,\n",
    "#     augmentation=False,\n",
    "#     train=True,\n",
    "#     slice=False,\n",
    "#     pre_read=True,\n",
    "# )\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=CFG.batch_size,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=CFG.num_workers,\n",
    "# )\n",
    "# # train_nshuffle_loader = DataLoader(\n",
    "# #     train_nshuffle_dataset,\n",
    "# #     batch_size=1,\n",
    "# #     shuffle=True,\n",
    "# #     drop_last=True,\n",
    "# #     pin_memory=True,\n",
    "# #     num_workers=CFG.num_workers,\n",
    "# # )\n",
    "# valid_loader = DataLoader(\n",
    "#     valid_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=CFG.num_workers,\n",
    "# )\n",
    "\n",
    "# for data in tqdm(train_loader):\n",
    "#     normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "#     segmentation_map = data[\"segmentation_map\"]\n",
    "#     break\n",
    "\n",
    "# normalized_tomogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in tqdm(train_loader):\n",
    "#     exp_names = data[\"exp_name\"]\n",
    "#     normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "#     segmentation_map = data[\"segmentation_map\"]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_names, normalized_tomogram.shape, segmentation_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cc3d\n",
    "\n",
    "# all_pred = []\n",
    "\n",
    "# for data in tqdm(train_dataset):\n",
    "#     exp_name = data[\"exp_name\"]\n",
    "#     normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "#     segmentation_map = data[\"segmentation_map\"]\n",
    "#     # print(segmentation_map.shape)\n",
    "#     gt = segmentation_map  # .numpy()\n",
    "\n",
    "#     cls_pos = []\n",
    "#     Ascale_pos = []\n",
    "#     res2ratio = CFG.resolution2ratio\n",
    "#     # exp_name = exp_names[i]\n",
    "\n",
    "#     for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#         cc, P = cc3d.connected_components(gt == pred_cls, return_N=True)\n",
    "#         stats = cc3d.statistics(cc)\n",
    "\n",
    "#         for z, y, x in stats[\"centroids\"][1:]:\n",
    "#             Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#             cls_pos.append([pred_cls, z, y, x])\n",
    "#             Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "#     pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "#     all_pred.append(pred_original_df)\n",
    "\n",
    "# all_pred = pd.concat(all_pred).reset_index().drop_duplicates(subset=[\"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.train_exp_names)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score(all_pred, gt_df, row_id_column_name=\"index\", distance_multiplier=0.5, beta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# # ############### validation ################\n",
    "# train_nshuffle_original_tomogram = defaultdict(list)\n",
    "# train_nshuffle_pred_tomogram = defaultdict(list)\n",
    "# train_nshuffle_gt_tomogram = defaultdict(list)\n",
    "# train_cls_pos = defaultdict(list)\n",
    "# train_cls_Apos = defaultdict(list)\n",
    "\n",
    "# valid_original_tomogram = defaultdict(list)\n",
    "# valid_pred_tomogram = defaultdict(list)\n",
    "# valid_gt_tomogram = defaultdict(list)\n",
    "# valid_cls_pos = defaultdict(list)\n",
    "# valid_cls_Apos = defaultdict(list)\n",
    "\n",
    "# train_mean_scores = []\n",
    "# valid_mean_scores = []\n",
    "\n",
    "# # # for exp_name in tqdm(CFG.train_exp_names):\n",
    "# # for exp_name in tqdm(CFG.train_exp_names[:5]):  # 5つのデータで試す\n",
    "# #     inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "# #         model, exp_name, train=True\n",
    "# #     )\n",
    "# #     train_nshuffle_pred_tomogram[exp_name] = inferenced_array\n",
    "# #     train_nshuffle_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "# #     train_nshuffle_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "# #     mean_score, scores, pred_df, gt_df, pred_cls_pos, pred_Ascale_pos = (\n",
    "# #         visualize_epoch_results(\n",
    "# #             train_nshuffle_pred_tomogram,\n",
    "# #             base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "# #             sikii_dict=CFG.initial_sikii,\n",
    "# #         )\n",
    "# #     )\n",
    "# #     train_cls_pos[exp_name] = pred_cls_pos\n",
    "# #     train_cls_Apos[exp_name] = pred_Ascale_pos\n",
    "# #     train_mean_scores.append(mean_score)\n",
    "# # print(\"train_mean_scores\", np.mean(train_mean_scores))\n",
    "\n",
    "# for exp_name in tqdm(CFG.valid_exp_names):\n",
    "#     inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "#         model, exp_name, train=True\n",
    "#     )\n",
    "#     valid_pred_tomogram[exp_name] = inferenced_array\n",
    "#     valid_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "#     valid_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "#     mean_score, scores, pred_df, gt_df, pred_cls_pos, pred_Ascale_pos = (\n",
    "#         visualize_epoch_results(\n",
    "#             valid_pred_tomogram,\n",
    "#             base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "#             sikii_dict=CFG.initial_sikii,\n",
    "#         )\n",
    "#     )\n",
    "#     valid_cls_pos[exp_name] = pred_cls_pos\n",
    "#     valid_cls_Apos[exp_name] = pred_Ascale_pos\n",
    "#     valid_mean_scores.append(mean_score)\n",
    "# print(\"valid_mean_scores\", np.mean(valid_mean_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferenced_array, n_tomogram, segmentation_map = inference(model, exp_name, train=True)\n",
    "# pred_original_df = inference2pos(\n",
    "#     pred_segmask=inferenced_array,\n",
    "#     exp_name=exp_name,\n",
    "#     sikii_dict=CFG.initial_sikii,\n",
    "# )\n",
    "# pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference2pos(pred_segmask, exp_name, sikii_dict):\n",
    "    import cc3d\n",
    "\n",
    "    cls_pos = []\n",
    "    Ascale_pos = []\n",
    "    res2ratio = CFG.resolution2ratio\n",
    "\n",
    "    for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "        sikii = sikii_dict[CFG.cls2particles[pred_cls]]\n",
    "        # print(pred_segmask[pred_cls].shape)\n",
    "        cc, P = cc3d.connected_components(pred_segmask[pred_cls] > sikii, return_N=True)\n",
    "        # cc, P = cc3d.connected_components(pred_segmask == pred_cls, return_N=True)\n",
    "        stats = cc3d.statistics(cc)\n",
    "\n",
    "        for z, y, x in stats[\"centroids\"][1:]:\n",
    "            Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "            cls_pos.append([pred_cls, z, y, x])\n",
    "            Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "    pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "\n",
    "    return pred_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score(pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df[pred_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_df[gt_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "num_classes = len(CFG.particles_name)  # クラス数\n",
    "colors = plt.cm.tab10(\n",
    "    np.arange(len(CFG.particles_name))\n",
    ")  # \"tab10\" カラーマップから色を取得\n",
    "\n",
    "# ListedColormap を作成\n",
    "class_colormap = ListedColormap(colors)\n",
    "\n",
    "\n",
    "def plot_with_colormap(data, title, original_tomogram):\n",
    "    masked_data = np.ma.masked_where(data <= 0, data)  # クラス0をマスク\n",
    "    plt.imshow(original_tomogram, cmap=\"gray\")\n",
    "    im = plt.imshow(masked_data, cmap=class_colormap)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    return im\n",
    "\n",
    "\n",
    "def imshow_result(pred, gt, original, index):\n",
    "    # plt.figure(figsize=(20, 5))\n",
    "    ax = plt.subplot(1, 3, 1)\n",
    "    plot_with_colormap(\n",
    "        pred[index],\n",
    "        \"Train-Prediction\",\n",
    "        original[index],\n",
    "    )\n",
    "    ax = plt.subplot(1, 3, 2)\n",
    "    plot_with_colormap(gt[index], \"Gt\", original[index])\n",
    "\n",
    "    ax = plt.subplot(1, 3, 3)\n",
    "    plt.imshow(original[index], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = \"TS_5_4\"\n",
    "# index = 12\n",
    "# pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "# gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "# original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# # imshow_result(pred, gt, original, index)\n",
    "\n",
    "# for i in range(42):\n",
    "#     imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = \"TS_5_4\"\n",
    "# index = 12\n",
    "# pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "# gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "# original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# # imshow_result(pred, gt, original, index)\n",
    "\n",
    "# for i in range(42):\n",
    "#     imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = CFG.valid_exp_names[-1]\n",
    "\n",
    "# pred = valid_pred_tomogram[exp_name].argmax(0)\n",
    "# gt = valid_gt_tomogram[exp_name]\n",
    "# original = valid_original_tomogram[exp_name]\n",
    "\n",
    "# for i in range(42):\n",
    "#     imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = CFG.train_exp_names[-1]\n",
    "\n",
    "# pred_cls_pos = train_cls_pos[exp_name]\n",
    "\n",
    "# exp_name, np.array(pred_cls_pos).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = CFG.valid_exp_names[0]\n",
    "\n",
    "# pred_cls_pos = valid_cls_pos[exp_name]\n",
    "\n",
    "# np.array(pred_cls_pos).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # exp_name = CFG.valid_exp_names[0]\n",
    "# # pred = valid_pred_tomogram[exp_name].argmax(0)\n",
    "# # gt = valid_gt_tomogram[exp_name]\n",
    "# # original = valid_original_tomogram[exp_name]\n",
    "# import timm\n",
    "\n",
    "# encoder = timm.create_model(\n",
    "#     model_name=CFG.model_name,\n",
    "#     pretrained=True,\n",
    "#     in_chans=3,\n",
    "#     num_classes=0,\n",
    "#     global_pool=\"\",\n",
    "#     features_only=True,\n",
    "# )\n",
    "# model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "# model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "# exp_name = CFG.train_exp_names[2]\n",
    "# pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)\n",
    "# gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "# original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "# gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "# import cc3d\n",
    "\n",
    "# cls_pos = []\n",
    "# Ascale_pos = []\n",
    "# res2ratio = CFG.resolution2ratio\n",
    "\n",
    "# for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#     print(pred_cls, CFG.cls2particles[pred_cls])\n",
    "#     cc, P = cc3d.connected_components(pred == pred_cls, return_N=True)\n",
    "#     stats = cc3d.statistics(cc)\n",
    "\n",
    "#     for z, y, x in stats[\"centroids\"]:\n",
    "#         Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#         Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#         Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#         cls_pos.append([pred_cls, z, y, x])\n",
    "#         Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "# pred_original_df = create_df(Ascale_pos, exp_name).drop_duplicates(\n",
    "#     subset=[\"x\", \"y\", \"z\"]\n",
    "# )\n",
    "\n",
    "# score(\n",
    "#     pred_original_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "\n",
    "# encoder = timm.create_model(\n",
    "#     model_name=CFG.model_name,\n",
    "#     pretrained=True,\n",
    "#     in_chans=3,\n",
    "#     num_classes=0,\n",
    "#     global_pool=\"\",\n",
    "#     features_only=True,\n",
    "# )\n",
    "# model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "# model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "# exp_name = CFG.valid_exp_names[-1]\n",
    "# pred = valid_pred_tomogram[exp_name]\n",
    "# gt = valid_gt_tomogram[exp_name]\n",
    "# original = valid_original_tomogram[exp_name]\n",
    "\n",
    "# base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "# gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "\n",
    "# for constant in np.linspace(0.2, 0.9, 20):\n",
    "#     initial_sikii = {\n",
    "#         \"apo-ferritin\": constant,\n",
    "#         \"beta-amylase\": constant,\n",
    "#         \"beta-galactosidase\": constant,\n",
    "#         \"ribosome\": constant,\n",
    "#         \"thyroglobulin\": constant,\n",
    "#         \"virus-like-particle\": constant,\n",
    "#     }\n",
    "\n",
    "#     import cc3d\n",
    "\n",
    "#     cls_pos = []\n",
    "#     Ascale_pos = []\n",
    "#     res2ratio = CFG.resolution2ratio\n",
    "\n",
    "#     for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#         sikii = initial_sikii[CFG.cls2particles[pred_cls]]\n",
    "#         cc, P = cc3d.connected_components(pred[pred_cls] > sikii, return_N=True)\n",
    "#         stats = cc3d.statistics(cc)\n",
    "\n",
    "#         for z, y, x in stats[\"centroids\"]:\n",
    "#             Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#             cls_pos.append([pred_cls, z, y, x])\n",
    "#             Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "#     pred_original_df = create_df(Ascale_pos, exp_name).drop_duplicates(\n",
    "#         subset=[\"x\", \"y\", \"z\"]\n",
    "#     )\n",
    "\n",
    "#     score_ = score(\n",
    "#         pred_original_df,\n",
    "#         gt_df,\n",
    "#         row_id_column_name=\"index\",\n",
    "#         distance_multiplier=1.0,\n",
    "#         beta=4,\n",
    "#     )\n",
    "\n",
    "#     print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "\n",
    "# encoder = timm.create_model(\n",
    "#     model_name=CFG.model_name,\n",
    "#     pretrained=True,\n",
    "#     in_chans=3,\n",
    "#     num_classes=0,\n",
    "#     global_pool=\"\",\n",
    "#     features_only=True,\n",
    "# )\n",
    "# model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "# model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "# exp_name = CFG.valid_exp_names[0]\n",
    "# pred = valid_pred_tomogram[exp_name]\n",
    "# gt = valid_gt_tomogram[exp_name]\n",
    "# original = valid_original_tomogram[exp_name]\n",
    "\n",
    "# base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "# gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "\n",
    "# for constant in np.linspace(0.2, 0.9, 20):\n",
    "#     initial_sikii = {\n",
    "#         \"apo-ferritin\": constant,\n",
    "#         \"beta-amylase\": constant,\n",
    "#         \"beta-galactosidase\": constant,\n",
    "#         \"ribosome\": constant,\n",
    "#         \"thyroglobulin\": constant,\n",
    "#         \"virus-like-particle\": constant,\n",
    "#     }\n",
    "\n",
    "#     import cc3d\n",
    "\n",
    "#     cls_pos = []\n",
    "#     Ascale_pos = []\n",
    "#     res2ratio = CFG.resolution2ratio\n",
    "\n",
    "#     for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#         sikii = initial_sikii[CFG.cls2particles[pred_cls]]\n",
    "#         cc, P = cc3d.connected_components(pred[pred_cls] > sikii, return_N=True)\n",
    "#         stats = cc3d.statistics(cc)\n",
    "\n",
    "#         for z, y, x in stats[\"centroids\"]:\n",
    "#             Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#             cls_pos.append([pred_cls, z, y, x])\n",
    "#             Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "#     pred_original_df = create_df(Ascale_pos, exp_name).drop_duplicates(\n",
    "#         subset=[\"x\", \"y\", \"z\"]\n",
    "#     )\n",
    "\n",
    "#     score_ = score(\n",
    "#         pred_original_df,\n",
    "#         gt_df,\n",
    "#         row_id_column_name=\"index\",\n",
    "#         distance_multiplier=1.0,\n",
    "#         beta=4,\n",
    "#     )\n",
    "\n",
    "#     print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = CFG.valid_exp_names[1]\n",
    "# exp_name = CFG.train_exp_names[0]\n",
    "exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder, num_domains=5).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "# inferenced_array = inference(model, exp_name, train=False)\n",
    "# 0.7303962244998289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = [\"TS_6_4\", \"TS_5_4\", \"TS_69_2\"]\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "constant = 0.25\n",
    "sikii = {\n",
    "    \"apo-ferritin\": constant,\n",
    "    \"beta-amylase\": constant,\n",
    "    \"beta-galactosidase\": constant,\n",
    "    \"ribosome\": constant,\n",
    "    \"thyroglobulin\": constant,\n",
    "    \"virus-like-particle\": constant,\n",
    "}\n",
    "\n",
    "pred_dict = {}\n",
    "\n",
    "# for exp_name in tqdm(CFG.train_exp_names):\n",
    "for exp_name in tqdm(exp_names):  # 5つのデータで試す\n",
    "    # inferenced_array = inference(model, exp_name, train=False)\n",
    "    inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "        model,\n",
    "        exp_name,\n",
    "        train=False,\n",
    "        base_dir=\"../../inputs/train/\",\n",
    "    )\n",
    "    pred_dict[exp_name] = inferenced_array\n",
    "    # pred_df = inference2pos(\n",
    "    #     pred_segmask=inferenced_array, exp_name=exp_name, sikii_dict=sikii\n",
    "    # )\n",
    "\n",
    "    # all_pred.append(pred_df)\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pd.concat(all_pred, axis=0).reset_index(drop=True)\n",
    "# pred_df = pred_df[pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "# pred_df = pred_df.drop_duplicates(\n",
    "#     subset=[\"experiment\", \"x\", \"y\", \"z\"], keep=\"first\"\n",
    "# ).reset_index(drop=True)\n",
    "# pred_df = pred_df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "# pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", exp_names)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for constant in np.linspace(0.2, 0.9, 20):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": constant,\n",
    "        \"beta-amylase\": constant,\n",
    "        \"beta-galactosidase\": constant,\n",
    "        \"ribosome\": constant,\n",
    "        \"thyroglobulin\": constant,\n",
    "        \"virus-like-particle\": constant,\n",
    "    }\n",
    "\n",
    "    all_pred = []\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        pred_original_df = inference2pos(\n",
    "            pred_segmask=pred_dict[exp_name],\n",
    "            exp_name=exp_name,\n",
    "            sikii_dict=initial_sikii,\n",
    "        )\n",
    "        all_pred.append(pred_original_df)\n",
    "\n",
    "    pred_df = pd.concat(all_pred, axis=0).reset_index(drop=True)\n",
    "\n",
    "    gt_df = create_gt_df(\n",
    "        base_dir=\"../../inputs/train/overlay/ExperimentRuns/\", exp_names=exp_names\n",
    "    )\n",
    "\n",
    "    s = score(\n",
    "        pred_df,\n",
    "        gt_df,\n",
    "        row_id_column_name=\"index\",\n",
    "        distance_multiplier=0.5,\n",
    "        beta=4,\n",
    "    )\n",
    "    print(constant, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0.2 0.42886866017326397\n",
    "0.2368421052631579 0.44763846995979895\n",
    "0.2736842105263158 0.4804059446122441\n",
    "0.31052631578947365 0.4843158713629149\n",
    "0.34736842105263155 0.5199510011648549\n",
    "0.38421052631578945 0.5525385551828039\n",
    "0.42105263157894735 0.5790230089865157\n",
    "0.45789473684210524 0.6270203806695409\n",
    "0.49473684210526314 0.6630851348008636\n",
    "0.531578947368421 0.6898782365235326\n",
    "0.5684210526315789 0.7254659045615721\n",
    "0.6052631578947368 0.7185365400137919\n",
    "0.6421052631578947 0.7466747413107093\n",
    "0.6789473684210525 0.7474254728226583\n",
    "0.7157894736842105 0.7565872909933272\n",
    "0.7526315789473683 0.7802748413991157\n",
    "0.7894736842105263 0.782614114024948\n",
    "0.8263157894736841 0.7965023875014008\n",
    "0.8631578947368421 0.7649020542074689\n",
    "0.9 0.8140205630560696\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"particle_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[\"particle_type\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
