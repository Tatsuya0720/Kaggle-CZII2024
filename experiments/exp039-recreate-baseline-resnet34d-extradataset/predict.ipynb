{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import timm\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# import torchvision.transforms.functional as F\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import Unet3D\n",
    "from src.utils import save_images, PadToSize\n",
    "from src.metric import (\n",
    "    score,\n",
    "    create_cls_pos,\n",
    "    create_cls_pos_sikii,\n",
    "    create_df,\n",
    "    SegmentationLoss,\n",
    "    DiceLoss,\n",
    ")\n",
    "from metric import visualize_epoch_results\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "padf = PadToSize(CFG.resolution)\n",
    "\n",
    "\n",
    "def last_padding(tomogram, slice_size):\n",
    "    # tomogram: (tensor)\n",
    "    b, d, h, w = tomogram.shape\n",
    "    last_padding = slice_size - d % slice_size\n",
    "    if last_padding == slice_size:\n",
    "        return tomogram\n",
    "    else:\n",
    "        return torch.cat(\n",
    "            [tomogram, torch.zeros(b, last_padding, h, w).to(tomogram.device)], dim=1\n",
    "        )\n",
    "\n",
    "\n",
    "def preprocess_tensor(tensor):\n",
    "    batch_size, depth, height, width = tensor.shape\n",
    "    tensor = tensor.unsqueeze(2)  # (b, d, h, w) -> (b, d, 1, h, w)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def inference(model, exp_name, train=True):\n",
    "    dataset = EziiDataset(\n",
    "        exp_names=[exp_name],\n",
    "        base_dir=\"../../inputs/train/\",\n",
    "        particles_name=CFG.particles_name,\n",
    "        resolution=CFG.resolution,\n",
    "        zarr_type=[\"denoised\"],\n",
    "        train=train,\n",
    "        slice=False,\n",
    "    )\n",
    "    res_array = CFG.original_img_shape[CFG.resolution]\n",
    "    pred_array = np.zeros(\n",
    "        (len(CFG.particles_name) + 1, res_array[0], res_array[1], res_array[2])\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "    model.eval()\n",
    "    # tq = tqdm(loader)\n",
    "    for data in loader:  # 実験データ1つを取り出す\n",
    "        for i in range(0, data[\"normalized_tomogram\"].shape[1], CFG.slice_):\n",
    "            normalized_tomogram = data[\"normalized_tomogram\"][:, i : i + CFG.slice_]\n",
    "            normalized_tomogram = last_padding(normalized_tomogram, CFG.slice_)\n",
    "            normalized_tomogram = padf(normalized_tomogram)\n",
    "            normalized_tomogram = preprocess_tensor(normalized_tomogram).to(\"cuda\")\n",
    "            pred = model(normalized_tomogram)\n",
    "            prob_pred = (\n",
    "                torch.softmax(pred, dim=1).detach().cpu().numpy()\n",
    "            )  # torch.Size([1, 7, 32, 320, 320])\n",
    "            range_ = min(i + CFG.slice_, res_array[0])\n",
    "            hw_pad_diff = prob_pred.shape[-1] - res_array[-1]\n",
    "\n",
    "            if i >= res_array[0]:\n",
    "                continue\n",
    "\n",
    "            if range_ == res_array[0]:\n",
    "                pred_array[:, i:range_] += prob_pred[\n",
    "                    0, :, : res_array[0] - i, :-hw_pad_diff, :-hw_pad_diff\n",
    "                ]\n",
    "            else:\n",
    "                pred_array[:, i:range_] += prob_pred[\n",
    "                    0, :, :range_, :-hw_pad_diff, :-hw_pad_diff\n",
    "                ]\n",
    "\n",
    "        if train:\n",
    "            segmentation_map = data[\"segmentation_map\"]\n",
    "        else:\n",
    "            segmentation_map = None\n",
    "\n",
    "        normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "    # tq.close()\n",
    "\n",
    "    return pred_array, normalized_tomogram, segmentation_map  # (7, 92, 315, 315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./pretrained_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ############### validation ################\n",
    "train_nshuffle_original_tomogram = defaultdict(list)\n",
    "train_nshuffle_pred_tomogram = defaultdict(list)\n",
    "train_nshuffle_gt_tomogram = defaultdict(list)\n",
    "\n",
    "valid_original_tomogram = defaultdict(list)\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "\n",
    "train_mean_scores = []\n",
    "valid_mean_scores = []\n",
    "\n",
    "# for exp_name in tqdm(CFG.train_exp_names):\n",
    "for exp_name in tqdm(CFG.train_exp_names):  # 5つのデータで試す\n",
    "    inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "        model, exp_name, train=True\n",
    "    )\n",
    "    train_nshuffle_pred_tomogram[exp_name] = inferenced_array\n",
    "    train_nshuffle_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "    train_nshuffle_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "    mean_score, scores, pred_df, gt_df = visualize_epoch_results(\n",
    "        train_nshuffle_pred_tomogram,\n",
    "        base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "        sikii_dict=CFG.initial_sikii,\n",
    "    )\n",
    "    train_mean_scores.append(mean_score)\n",
    "print(\"train_mean_scores\", np.mean(train_mean_scores))\n",
    "\n",
    "for exp_name in tqdm(CFG.valid_exp_names):\n",
    "    inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "        model, exp_name, train=True\n",
    "    )\n",
    "    valid_pred_tomogram[exp_name] = inferenced_array\n",
    "    valid_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "    valid_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "    mean_score, scores, pred_df, gt_df = visualize_epoch_results(\n",
    "        valid_pred_tomogram,\n",
    "        base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "        sikii_dict=CFG.initial_sikii,\n",
    "    )\n",
    "    valid_mean_scores.append(mean_score)\n",
    "print(\"valid_mean_scores\", np.mean(valid_mean_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[pred_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[gt_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "num_classes = len(CFG.particles_name)  # クラス数\n",
    "colors = plt.cm.tab10(\n",
    "    np.arange(len(CFG.particles_name))\n",
    ")  # \"tab10\" カラーマップから色を取得\n",
    "\n",
    "# ListedColormap を作成\n",
    "class_colormap = ListedColormap(colors)\n",
    "\n",
    "\n",
    "def plot_with_colormap(data, title, original_tomogram):\n",
    "    masked_data = np.ma.masked_where(data <= 0, data)  # クラス0をマスク\n",
    "    plt.imshow(original_tomogram, cmap=\"gray\")\n",
    "    im = plt.imshow(masked_data, cmap=class_colormap)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    return im\n",
    "\n",
    "\n",
    "def imshow_result(pred, gt, original, index):\n",
    "    # plt.figure(figsize=(20, 5))\n",
    "    ax = plt.subplot(1, 3, 1)\n",
    "    plot_with_colormap(\n",
    "        pred[index],\n",
    "        \"Train-Prediction\",\n",
    "        original[index],\n",
    "    )\n",
    "    ax = plt.subplot(1, 3, 2)\n",
    "    plot_with_colormap(gt[index], \"Gt\", original[index])\n",
    "\n",
    "    ax = plt.subplot(1, 3, 3)\n",
    "    plt.imshow(original[index], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"TS_5_4\"\n",
    "index = 12\n",
    "pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# imshow_result(pred, gt, original, index)\n",
    "\n",
    "for i in range(42):\n",
    "    imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"TS_5_4\"\n",
    "index = 12\n",
    "pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# imshow_result(pred, gt, original, index)\n",
    "\n",
    "for i in range(42):\n",
    "    imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = CFG.valid_exp_names[-1]\n",
    "\n",
    "pred = valid_pred_tomogram[exp_name].argmax(0)\n",
    "gt = valid_gt_tomogram[exp_name]\n",
    "original = valid_original_tomogram[exp_name]\n",
    "\n",
    "for i in range(42):\n",
    "    imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
