{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import timm\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# import torchvision.transforms.functional as F\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import Unet3D\n",
    "from src.utils import save_images, PadToSize\n",
    "from src.metric import (\n",
    "    score,\n",
    "    create_cls_pos,\n",
    "    create_cls_pos_sikii,\n",
    "    create_df,\n",
    "    SegmentationLoss,\n",
    "    DiceLoss,\n",
    ")\n",
    "from metric import visualize_epoch_results\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "from src.inference import inference, inference2pos\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padf = PadToSize(CFG.resolution)\n",
    "\n",
    "\n",
    "# def last_padding(tomogram, slice_size):\n",
    "#     # tomogram: (tensor)\n",
    "#     b, d, h, w = tomogram.shape\n",
    "#     last_padding = slice_size - d % slice_size\n",
    "#     if last_padding == slice_size:\n",
    "#         return tomogram\n",
    "#     else:\n",
    "#         return torch.cat(\n",
    "#             [tomogram, torch.zeros(b, last_padding, h, w).to(tomogram.device)], dim=1\n",
    "#         )\n",
    "\n",
    "\n",
    "# def preprocess_tensor(tensor):\n",
    "#     batch_size, depth, height, width = tensor.shape\n",
    "#     tensor = tensor.unsqueeze(2)  # (b, d, h, w) -> (b, d, 1, h, w)\n",
    "#     return tensor\n",
    "\n",
    "\n",
    "# def inference(model, exp_name, train=True):\n",
    "#     dataset = EziiDataset(\n",
    "#         exp_names=[exp_name],\n",
    "#         base_dir=\"../../inputs/train/\",\n",
    "#         particles_name=CFG.particles_name,\n",
    "#         resolution=CFG.resolution,\n",
    "#         zarr_type=[\"denoised\"],\n",
    "#         train=train,\n",
    "#         slice=False,\n",
    "#     )\n",
    "#     res_array = CFG.original_img_shape[CFG.resolution]\n",
    "#     pred_array = np.zeros(\n",
    "#         (len(CFG.particles_name) + 1, res_array[0], res_array[1], res_array[2])\n",
    "#     )\n",
    "#     loader = DataLoader(dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "#     model.eval()\n",
    "#     # tq = tqdm(loader)\n",
    "#     for data in loader:  # 実験データ1つを取り出す\n",
    "#         for i in range(0, data[\"normalized_tomogram\"].shape[1], CFG.slice_):\n",
    "#             normalized_tomogram = data[\"normalized_tomogram\"][:, i : i + CFG.slice_]\n",
    "#             normalized_tomogram = last_padding(normalized_tomogram, CFG.slice_)\n",
    "#             normalized_tomogram = padf(normalized_tomogram)\n",
    "#             normalized_tomogram = preprocess_tensor(normalized_tomogram).to(\"cuda\")\n",
    "#             pred = model(normalized_tomogram)\n",
    "#             prob_pred = (\n",
    "#                 torch.softmax(pred, dim=1).detach().cpu().numpy()\n",
    "#             )  # torch.Size([1, 7, 32, 320, 320])\n",
    "#             range_ = min(i + CFG.slice_, res_array[0])\n",
    "#             hw_pad_diff = prob_pred.shape[-1] - res_array[-1]\n",
    "\n",
    "#             if i >= res_array[0]:\n",
    "#                 continue\n",
    "\n",
    "#             if range_ == res_array[0]:\n",
    "#                 pred_array[:, i:range_] += prob_pred[\n",
    "#                     0, :, : res_array[0] - i, :-hw_pad_diff, :-hw_pad_diff\n",
    "#                 ]\n",
    "#             else:\n",
    "#                 pred_array[:, i:range_] += prob_pred[\n",
    "#                     0, :, :range_, :-hw_pad_diff, :-hw_pad_diff\n",
    "#                 ]\n",
    "\n",
    "#         if train:\n",
    "#             segmentation_map = data[\"segmentation_map\"]\n",
    "#         else:\n",
    "#             segmentation_map = None\n",
    "\n",
    "#         normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "#     # tq.close()\n",
    "\n",
    "#     return pred_array, normalized_tomogram, segmentation_map  # (7, 92, 315, 315)\n",
    "\n",
    "\n",
    "# def inference2pos(pred_segmask, exp_name):\n",
    "#     import cc3d\n",
    "\n",
    "#     cls_pos = []\n",
    "#     Ascale_pos = []\n",
    "#     res2ratio = CFG.resolution2ratio\n",
    "\n",
    "#     for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#         print(pred_cls, CFG.cls2particles[pred_cls])\n",
    "#         cc, P = cc3d.connected_components(pred_segmask == pred_cls, return_N=True)\n",
    "#         stats = cc3d.statistics(cc)\n",
    "\n",
    "#         for z, y, x in stats[\"centroids\"]:\n",
    "#             Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#             cls_pos.append([pred_cls, z, y, x])\n",
    "#             Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "#     pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "\n",
    "#     return pred_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "  0%|          | 0/12 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 184, 630, 630])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = EziiDataset(\n",
    "    exp_names=CFG.train_exp_names,\n",
    "    base_dir=\"../../inputs/train/\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.train_zarr_types,\n",
    "    train=True,\n",
    "    augmentation=False,\n",
    "    slice=False,\n",
    "    pre_read=True,\n",
    ")\n",
    "\n",
    "# train_nshuffle_dataset = EziiDataset(\n",
    "#     exp_names=CFG.train_exp_names,\n",
    "#     base_dir=\"../../inputs/train/\",\n",
    "#     particles_name=CFG.particles_name,\n",
    "#     resolution=CFG.resolution,\n",
    "#     zarr_type=CFG.train_zarr_types,\n",
    "#     augmentation=False,\n",
    "#     train=True,\n",
    "# )\n",
    "\n",
    "valid_dataset = EziiDataset(\n",
    "    exp_names=CFG.valid_exp_names,\n",
    "    base_dir=\"../../inputs/train/\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.valid_zarr_types,\n",
    "    augmentation=False,\n",
    "    train=True,\n",
    "    slice=False,\n",
    "    pre_read=True,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=CFG.num_workers,\n",
    ")\n",
    "# train_nshuffle_loader = DataLoader(\n",
    "#     train_nshuffle_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=CFG.num_workers,\n",
    "# )\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=CFG.num_workers,\n",
    ")\n",
    "\n",
    "for data in tqdm(train_loader):\n",
    "    normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "    segmentation_map = data[\"segmentation_map\"]\n",
    "    break\n",
    "\n",
    "normalized_tomogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:04<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(train_loader):\n",
    "    exp_names = data[\"exp_name\"]\n",
    "    normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "    segmentation_map = data[\"segmentation_map\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['TS_86_3', 'TS_86_3'],\n",
       " torch.Size([2, 184, 630, 630]),\n",
       " torch.Size([2, 184, 630, 630]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_names, normalized_tomogram.shape, segmentation_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:48<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "import cc3d\n",
    "\n",
    "all_pred = []\n",
    "\n",
    "for data in tqdm(train_dataset):\n",
    "    exp_name = data[\"exp_name\"]\n",
    "    normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "    segmentation_map = data[\"segmentation_map\"]\n",
    "    # print(segmentation_map.shape)\n",
    "    gt = segmentation_map  # .numpy()\n",
    "\n",
    "    cls_pos = []\n",
    "    Ascale_pos = []\n",
    "    res2ratio = CFG.resolution2ratio\n",
    "    # exp_name = exp_names[i]\n",
    "\n",
    "    for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "        cc, P = cc3d.connected_components(gt == pred_cls, return_N=True)\n",
    "        stats = cc3d.statistics(cc)\n",
    "\n",
    "        for z, y, x in stats[\"centroids\"][1:]:\n",
    "            Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "            cls_pos.append([pred_cls, z, y, x])\n",
    "            Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "    pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "    all_pred.append(pred_original_df)\n",
    "\n",
    "all_pred = pd.concat(all_pred).reset_index().drop_duplicates(subset=[\"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>experiment</th>\n",
       "      <th>particle_type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>268.662</td>\n",
       "      <td>4730.318</td>\n",
       "      <td>916.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>238.946</td>\n",
       "      <td>4853.061</td>\n",
       "      <td>909.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>83.114</td>\n",
       "      <td>5729.560</td>\n",
       "      <td>1219.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>582.143</td>\n",
       "      <td>2769.968</td>\n",
       "      <td>1076.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>510.389</td>\n",
       "      <td>2157.244</td>\n",
       "      <td>362.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>1124</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2609.876</td>\n",
       "      <td>4569.876</td>\n",
       "      <td>1169.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1125</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2213.287</td>\n",
       "      <td>4135.017</td>\n",
       "      <td>1286.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1126</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>3303.905</td>\n",
       "      <td>5697.825</td>\n",
       "      <td>789.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1127</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>1008.748</td>\n",
       "      <td>5949.213</td>\n",
       "      <td>1077.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1128</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>5749.052</td>\n",
       "      <td>3911.392</td>\n",
       "      <td>275.342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index experiment        particle_type         x         y         z\n",
       "0         0    TS_73_6         apo-ferritin   268.662  4730.318   916.115\n",
       "1         1    TS_73_6         apo-ferritin   238.946  4853.061   909.898\n",
       "2         2    TS_73_6         apo-ferritin    83.114  5729.560  1219.524\n",
       "3         3    TS_73_6         apo-ferritin   582.143  2769.968  1076.364\n",
       "4         4    TS_73_6         apo-ferritin   510.389  2157.244   362.438\n",
       "...     ...        ...                  ...       ...       ...       ...\n",
       "1124   1124     TS_6_6  virus-like-particle  2609.876  4569.876  1169.759\n",
       "1125   1125     TS_6_6  virus-like-particle  2213.287  4135.017  1286.851\n",
       "1126   1126     TS_6_6  virus-like-particle  3303.905  5697.825   789.744\n",
       "1127   1127     TS_6_6  virus-like-particle  1008.748  5949.213  1077.303\n",
       "1128   1128     TS_6_6  virus-like-particle  5749.052  3911.392   275.342\n",
       "\n",
       "[1129 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.train_exp_names)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.987299215367147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(all_pred, gt_df, row_id_column_name=\"index\", distance_multiplier=0.5, beta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>experiment</th>\n",
       "      <th>particle_type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>5395.0</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>5265.0</td>\n",
       "      <td>4805.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>5535.0</td>\n",
       "      <td>3525.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>4625.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TS_73_6</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>135</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>395.0</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>136</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>5945.0</td>\n",
       "      <td>1075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>137</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2605.0</td>\n",
       "      <td>4565.0</td>\n",
       "      <td>1165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>138</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>3545.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>139</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>4135.0</td>\n",
       "      <td>1285.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1097 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index experiment        particle_type       x       y       z\n",
       "0         0    TS_73_6         apo-ferritin  5395.0  4745.0    35.0\n",
       "1         1    TS_73_6         apo-ferritin  5265.0  4805.0    35.0\n",
       "2         2    TS_73_6         apo-ferritin  5535.0  3525.0    45.0\n",
       "3         3    TS_73_6         apo-ferritin  5415.0  4625.0    45.0\n",
       "4         4    TS_73_6         apo-ferritin  4635.0  2185.0    55.0\n",
       "...     ...        ...                  ...     ...     ...     ...\n",
       "3963    135     TS_6_6  virus-like-particle   395.0  2705.0   965.0\n",
       "3964    136     TS_6_6  virus-like-particle  1005.0  5945.0  1075.0\n",
       "3965    137     TS_6_6  virus-like-particle  2605.0  4565.0  1165.0\n",
       "3966    138     TS_6_6  virus-like-particle  3545.0   995.0  1195.0\n",
       "3967    139     TS_6_6  virus-like-particle  2205.0  4135.0  1285.0\n",
       "\n",
       "[1097 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:00<00:00, 12.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mean_scores 0.0390025642831809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_mean_scores 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ############### validation ################\n",
    "train_nshuffle_original_tomogram = defaultdict(list)\n",
    "train_nshuffle_pred_tomogram = defaultdict(list)\n",
    "train_nshuffle_gt_tomogram = defaultdict(list)\n",
    "train_cls_pos = defaultdict(list)\n",
    "train_cls_Apos = defaultdict(list)\n",
    "\n",
    "valid_original_tomogram = defaultdict(list)\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "valid_cls_pos = defaultdict(list)\n",
    "valid_cls_Apos = defaultdict(list)\n",
    "\n",
    "train_mean_scores = []\n",
    "valid_mean_scores = []\n",
    "\n",
    "# for exp_name in tqdm(CFG.train_exp_names):\n",
    "for exp_name in tqdm(CFG.train_exp_names[:5]):  # 5つのデータで試す\n",
    "    inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "        model, exp_name, train=True\n",
    "    )\n",
    "    train_nshuffle_pred_tomogram[exp_name] = inferenced_array\n",
    "    train_nshuffle_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "    train_nshuffle_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "    mean_score, scores, pred_df, gt_df, pred_cls_pos, pred_Ascale_pos = (\n",
    "        visualize_epoch_results(\n",
    "            train_nshuffle_pred_tomogram,\n",
    "            base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "            sikii_dict=CFG.initial_sikii,\n",
    "        )\n",
    "    )\n",
    "    train_cls_pos[exp_name] = pred_cls_pos\n",
    "    train_cls_Apos[exp_name] = pred_Ascale_pos\n",
    "    train_mean_scores.append(mean_score)\n",
    "print(\"train_mean_scores\", np.mean(train_mean_scores))\n",
    "\n",
    "for exp_name in tqdm(CFG.valid_exp_names):\n",
    "    inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "        model, exp_name, train=True\n",
    "    )\n",
    "    valid_pred_tomogram[exp_name] = inferenced_array\n",
    "    valid_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "    valid_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "    mean_score, scores, pred_df, gt_df, pred_cls_pos, pred_Ascale_pos = (\n",
    "        visualize_epoch_results(\n",
    "            valid_pred_tomogram,\n",
    "            base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "            sikii_dict=CFG.initial_sikii,\n",
    "        )\n",
    "    )\n",
    "    valid_cls_pos[exp_name] = pred_cls_pos\n",
    "    valid_cls_Apos[exp_name] = pred_Ascale_pos\n",
    "    valid_mean_scores.append(mean_score)\n",
    "print(\"valid_mean_scores\", np.mean(valid_mean_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "inference2pos() missing 1 required positional argument: 'sikii_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inferenced_array, n_tomogram, segmentation_map \u001b[38;5;241m=\u001b[39m inference(model, exp_name, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m pred_original_df \u001b[38;5;241m=\u001b[39m \u001b[43minference2pos\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_segmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minferenced_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_name\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m pred_df\n",
      "\u001b[0;31mTypeError\u001b[0m: inference2pos() missing 1 required positional argument: 'sikii_dict'"
     ]
    }
   ],
   "source": [
    "inferenced_array, n_tomogram, segmentation_map = inference(model, exp_name, train=True)\n",
    "pred_original_df = inference2pos(\n",
    "    pred_segmask=inferenced_array.argmax(1), exp_name=exp_name\n",
    ")\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[pred_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[gt_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "num_classes = len(CFG.particles_name)  # クラス数\n",
    "colors = plt.cm.tab10(\n",
    "    np.arange(len(CFG.particles_name))\n",
    ")  # \"tab10\" カラーマップから色を取得\n",
    "\n",
    "# ListedColormap を作成\n",
    "class_colormap = ListedColormap(colors)\n",
    "\n",
    "\n",
    "def plot_with_colormap(data, title, original_tomogram):\n",
    "    masked_data = np.ma.masked_where(data <= 0, data)  # クラス0をマスク\n",
    "    plt.imshow(original_tomogram, cmap=\"gray\")\n",
    "    im = plt.imshow(masked_data, cmap=class_colormap)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    return im\n",
    "\n",
    "\n",
    "def imshow_result(pred, gt, original, index):\n",
    "    # plt.figure(figsize=(20, 5))\n",
    "    ax = plt.subplot(1, 3, 1)\n",
    "    plot_with_colormap(\n",
    "        pred[index],\n",
    "        \"Train-Prediction\",\n",
    "        original[index],\n",
    "    )\n",
    "    ax = plt.subplot(1, 3, 2)\n",
    "    plot_with_colormap(gt[index], \"Gt\", original[index])\n",
    "\n",
    "    ax = plt.subplot(1, 3, 3)\n",
    "    plt.imshow(original[index], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"TS_5_4\"\n",
    "index = 12\n",
    "pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# imshow_result(pred, gt, original, index)\n",
    "\n",
    "for i in range(42):\n",
    "    imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"TS_5_4\"\n",
    "index = 12\n",
    "pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# imshow_result(pred, gt, original, index)\n",
    "\n",
    "for i in range(42):\n",
    "    imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = CFG.valid_exp_names[-1]\n",
    "\n",
    "pred = valid_pred_tomogram[exp_name].argmax(0)\n",
    "gt = valid_gt_tomogram[exp_name]\n",
    "original = valid_original_tomogram[exp_name]\n",
    "\n",
    "for i in range(42):\n",
    "    imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = CFG.train_exp_names[-1]\n",
    "\n",
    "pred_cls_pos = train_cls_pos[exp_name]\n",
    "\n",
    "exp_name, np.array(pred_cls_pos).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cls_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = CFG.valid_exp_names[0]\n",
    "\n",
    "pred_cls_pos = valid_cls_pos[exp_name]\n",
    "\n",
    "np.array(pred_cls_pos).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = CFG.valid_exp_names[0]\n",
    "# pred = valid_pred_tomogram[exp_name].argmax(0)\n",
    "# gt = valid_gt_tomogram[exp_name]\n",
    "# original = valid_original_tomogram[exp_name]\n",
    "import timm\n",
    "\n",
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "exp_name = CFG.train_exp_names[2]\n",
    "pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)\n",
    "gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "import cc3d\n",
    "\n",
    "cls_pos = []\n",
    "Ascale_pos = []\n",
    "res2ratio = CFG.resolution2ratio\n",
    "\n",
    "for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "    print(pred_cls, CFG.cls2particles[pred_cls])\n",
    "    cc, P = cc3d.connected_components(pred == pred_cls, return_N=True)\n",
    "    stats = cc3d.statistics(cc)\n",
    "\n",
    "    for z, y, x in stats[\"centroids\"]:\n",
    "        Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "        Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "        Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "        cls_pos.append([pred_cls, z, y, x])\n",
    "        Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "\n",
    "score(\n",
    "    pred_original_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.5469462401375174\n",
      "0.2368421052631579 0.5871654781742873\n",
      "0.2736842105263158 0.6028198405536095\n",
      "0.31052631578947365 0.5922334866988573\n",
      "0.34736842105263155 0.6117187294214367\n",
      "0.38421052631578945 0.6305999160963964\n",
      "0.42105263157894735 0.5953271994405094\n",
      "0.45789473684210524 0.6337348439210094\n",
      "0.49473684210526314 0.6461677902531393\n",
      "0.531578947368421 0.6359704387996562\n",
      "0.5684210526315789 0.6934467027554885\n",
      "0.6052631578947368 0.6897470895583301\n",
      "0.6421052631578947 0.6754642284092973\n",
      "0.6789473684210525 0.6924073401108811\n",
      "0.7157894736842105 0.7252096853643878\n",
      "0.7526315789473683 0.6460158873731962\n",
      "0.7894736842105263 0.6560908764505983\n",
      "0.8263157894736841 0.6277111275237965\n",
      "0.8631578947368421 0.5529459390187434\n",
      "0.9 0.4664232085899627\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "exp_name = CFG.valid_exp_names[-1]\n",
    "pred = valid_pred_tomogram[exp_name]\n",
    "gt = valid_gt_tomogram[exp_name]\n",
    "original = valid_original_tomogram[exp_name]\n",
    "\n",
    "base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "\n",
    "for constant in np.linspace(0.2, 0.9, 20):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": constant,\n",
    "        \"beta-amylase\": constant,\n",
    "        \"beta-galactosidase\": constant,\n",
    "        \"ribosome\": constant,\n",
    "        \"thyroglobulin\": constant,\n",
    "        \"virus-like-particle\": constant,\n",
    "    }\n",
    "\n",
    "    import cc3d\n",
    "\n",
    "    cls_pos = []\n",
    "    Ascale_pos = []\n",
    "    res2ratio = CFG.resolution2ratio\n",
    "\n",
    "    for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "        sikii = initial_sikii[CFG.cls2particles[pred_cls]]\n",
    "        cc, P = cc3d.connected_components(pred[pred_cls] > sikii, return_N=True)\n",
    "        stats = cc3d.statistics(cc)\n",
    "\n",
    "        for z, y, x in stats[\"centroids\"]:\n",
    "            Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "            cls_pos.append([pred_cls, z, y, x])\n",
    "            Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "    pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "\n",
    "    score_ = score(\n",
    "        pred_original_df,\n",
    "        gt_df,\n",
    "        row_id_column_name=\"index\",\n",
    "        distance_multiplier=1.0,\n",
    "        beta=4,\n",
    "    )\n",
    "\n",
    "    print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "exp_name = CFG.valid_exp_names[0]\n",
    "pred = valid_pred_tomogram[exp_name]\n",
    "gt = valid_gt_tomogram[exp_name]\n",
    "original = valid_original_tomogram[exp_name]\n",
    "\n",
    "base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "\n",
    "for constant in np.linspace(0.2, 0.9, 20):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": constant,\n",
    "        \"beta-amylase\": constant,\n",
    "        \"beta-galactosidase\": constant,\n",
    "        \"ribosome\": constant,\n",
    "        \"thyroglobulin\": constant,\n",
    "        \"virus-like-particle\": constant,\n",
    "    }\n",
    "\n",
    "    import cc3d\n",
    "\n",
    "    cls_pos = []\n",
    "    Ascale_pos = []\n",
    "    res2ratio = CFG.resolution2ratio\n",
    "\n",
    "    for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "        sikii = initial_sikii[CFG.cls2particles[pred_cls]]\n",
    "        cc, P = cc3d.connected_components(pred[pred_cls] > sikii, return_N=True)\n",
    "        stats = cc3d.statistics(cc)\n",
    "\n",
    "        for z, y, x in stats[\"centroids\"]:\n",
    "            Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "            cls_pos.append([pred_cls, z, y, x])\n",
    "            Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "    pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "\n",
    "    score_ = score(\n",
    "        pred_original_df,\n",
    "        gt_df,\n",
    "        row_id_column_name=\"index\",\n",
    "        distance_multiplier=1.0,\n",
    "        beta=4,\n",
    "    )\n",
    "\n",
    "    print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "exp_name = CFG.valid_exp_names[0]\n",
    "inferenced_array, n_tomogram, segmentation_map = inference(model, exp_name, train=True)\n",
    "pred_original_df = inference2pos(\n",
    "    pred_segmask=inferenced_array.argmax(0), exp_name=exp_name\n",
    ")\n",
    "gt_df = create_gt_df(\n",
    "    base_dir=\"../../inputs/train/overlay/ExperimentRuns/\", exp_names=[exp_name]\n",
    ")\n",
    "\n",
    "score(\n",
    "    pred_original_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
