{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import UNet_2D, aug\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TS_86_3', 'denoised'), ('TS_6_6', 'denoised')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = EziiDataset(\n",
    "    exp_names=CFG.valid_exp_names,\n",
    "    # exp_names=CFG.train_exp_names,\n",
    "    base_dir=\"../../inputs/train\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.valid_zarr_types,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "for row in tqdm(valid_loader):\n",
    "    normalized_tomogram = row[\"normalized_tomogram\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadToSize(nn.Module):\n",
    "    def __init__(self, resolution):\n",
    "        super().__init__()\n",
    "        if resolution == \"0\":\n",
    "            self.size = 640\n",
    "        elif resolution == \"1\":\n",
    "            self.size = 320\n",
    "        elif resolution == \"2\":\n",
    "            self.size = 160\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.pad(x, (0, 0, self.size - x.shape[-1], self.size - x.shape[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4531617035036501: : 184it [00:07, 25.90it/s]                   \n"
     ]
    }
   ],
   "source": [
    "model = UNet_2D().to(\"cuda\")\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor([0.5, 32, 32, 32, 32, 32, 32]).to(\"cuda\")\n",
    ")\n",
    "# criterion = DiceLoss()\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "batch_size = 4\n",
    "\n",
    "valid_loss = []\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "model.eval()\n",
    "tq = tqdm(range(len(valid_loader) * normalized_tomogram.shape[0]))\n",
    "for data in valid_loader:\n",
    "    exp_name = data[\"exp_name\"][0]\n",
    "    tomogram = data[\"normalized_tomogram\"].to(\"cuda\")\n",
    "    segmentation_map = data[\"segmentation_map\"].to(\"cuda\").long()\n",
    "\n",
    "    for i in range(tomogram.shape[1]):\n",
    "        input_ = tomogram[:, i].unsqueeze(0)\n",
    "        gt = segmentation_map[:, i]\n",
    "\n",
    "        input_ = PadToSize(CFG.resolution)(input_)\n",
    "        gt = PadToSize(CFG.resolution)(gt)\n",
    "        output = model(input_)\n",
    "        output = nn.functional.softmax(output, dim=1)\n",
    "        loss = criterion(output, gt)\n",
    "\n",
    "        valid_loss.append(loss.item())\n",
    "        tq.set_description(f\"Loss: {np.mean(valid_loss)}\")\n",
    "        tq.update(1)\n",
    "\n",
    "        output = drop_padding(output, CFG.resolution)\n",
    "\n",
    "        valid_pred_tomogram[exp_name].append(output.cpu().detach().numpy())\n",
    "        valid_gt_tomogram[exp_name].append(gt.cpu().detach().numpy())\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>experiment</th>\n",
       "      <th>particle_type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TS_86_3</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>3870.343</td>\n",
       "      <td>4952.714</td>\n",
       "      <td>1261.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TS_86_3</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>4130.897</td>\n",
       "      <td>5422.292</td>\n",
       "      <td>501.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TS_86_3</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2735.000</td>\n",
       "      <td>4668.447</td>\n",
       "      <td>520.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TS_86_3</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2649.615</td>\n",
       "      <td>4690.615</td>\n",
       "      <td>600.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TS_86_3</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2665.353</td>\n",
       "      <td>4810.641</td>\n",
       "      <td>612.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>363</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2609.876</td>\n",
       "      <td>4569.876</td>\n",
       "      <td>1169.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>364</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2213.287</td>\n",
       "      <td>4135.017</td>\n",
       "      <td>1286.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>365</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>3303.905</td>\n",
       "      <td>5697.825</td>\n",
       "      <td>789.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>366</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>1008.748</td>\n",
       "      <td>5949.213</td>\n",
       "      <td>1077.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>367</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>5749.052</td>\n",
       "      <td>3911.392</td>\n",
       "      <td>275.342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index experiment        particle_type         x         y         z\n",
       "0        0    TS_86_3         apo-ferritin  3870.343  4952.714  1261.600\n",
       "1        1    TS_86_3         apo-ferritin  4130.897  5422.292   501.860\n",
       "2        2    TS_86_3         apo-ferritin  2735.000  4668.447   520.291\n",
       "3        3    TS_86_3         apo-ferritin  2649.615  4690.615   600.923\n",
       "4        4    TS_86_3         apo-ferritin  2665.353  4810.641   612.019\n",
       "..     ...        ...                  ...       ...       ...       ...\n",
       "340    363     TS_6_6  virus-like-particle  2609.876  4569.876  1169.759\n",
       "341    364     TS_6_6  virus-like-particle  2213.287  4135.017  1286.851\n",
       "342    365     TS_6_6  virus-like-particle  3303.905  5697.825   789.744\n",
       "343    366     TS_6_6  virus-like-particle  1008.748  5949.213  1077.303\n",
       "344    367     TS_6_6  virus-like-particle  5749.052  3911.392   275.342\n",
       "\n",
       "[345 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()  # index\texperiment\tparticle_type\tx\ty\tz\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.valid_exp_names)\n",
    "gt_df = gt_df[gt_df[\"particle_type\"] != \"beta-amylase\"].reset_index(drop=True)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pd.read_csv(\"../../inputs/train_submission.csv\")\n",
    "\n",
    "\n",
    "def calc_score(initial_sikii):\n",
    "    all_pred_df = None\n",
    "\n",
    "    for exp_name in CFG.valid_exp_names:\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "        # pred_df = create_df(pred_cls_pos, exp_name)\n",
    "\n",
    "        if all_pred_df is None:\n",
    "            all_pred_df = pred_df\n",
    "        else:\n",
    "            all_pred_df = pd.concat([all_pred_df, pred_df], axis=0).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "    pred_df = all_pred_df[all_pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "    pred_df = pred_df.drop_duplicates(subset=[\"x\", \"y\", \"z\"], keep=\"first\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    pred_df = pred_df.reset_index()\n",
    "\n",
    "    score_ = score(\n",
    "        pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "    )\n",
    "\n",
    "    return score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2940988707528569"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = 0.35\n",
    "\n",
    "initial_sikii = {\n",
    "    \"apo-ferritin\": constant,\n",
    "    \"beta-amylase\": constant,\n",
    "    \"beta-galactosidase\": constant,\n",
    "    \"ribosome\": constant,\n",
    "    \"thyroglobulin\": constant,\n",
    "    \"virus-like-particle\": constant,\n",
    "}\n",
    "\n",
    "score_ = calc_score(initial_sikii)\n",
    "score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.31017562998344744\n",
      "0.25202020202020203 0.3246136431729721\n",
      "0.25404040404040407 0.32493246588231145\n",
      "0.25606060606060604 0.3258421685913508\n",
      "0.2580808080808081 0.3332046199736326\n",
      "0.2601010101010101 0.3361490566742506\n",
      "0.26212121212121214 0.33629562034222193\n",
      "0.2641414141414141 0.33090394498688613\n",
      "0.26616161616161615 0.32415791324085436\n",
      "0.2681818181818182 0.3243147461667975\n",
      "0.2702020202020202 0.3273241941405885\n",
      "0.2722222222222222 0.33065178282696117\n",
      "0.27424242424242423 0.3331985262572261\n",
      "0.27626262626262627 0.33600860249612025\n",
      "0.2782828282828283 0.33604128308868425\n",
      "0.2803030303030303 0.33690536172928826\n",
      "0.2823232323232323 0.3309488999317635\n",
      "0.28434343434343434 0.3365209634637197\n",
      "0.2863636363636364 0.33671351571359714\n",
      "0.2883838383838384 0.3363542667022315\n",
      "0.2904040404040404 0.3362363507684512\n",
      "0.2924242424242424 0.33690503382143083\n",
      "0.29444444444444445 0.3368765242076117\n",
      "0.2964646464646465 0.3368859706554903\n",
      "0.29848484848484846 0.33685779906231633\n",
      "0.3005050505050505 0.3373560886543215\n",
      "0.30252525252525253 0.33753482197782886\n",
      "0.30454545454545456 0.3377061854662586\n",
      "0.3065656565656566 0.337752313274204\n",
      "0.3085858585858586 0.34562242241157043\n",
      "0.3106060606060606 0.34563170209903055\n",
      "0.31262626262626264 0.3099720720458602\n",
      "0.3146464646464646 0.31374755004008825\n",
      "0.31666666666666665 0.30749047728292755\n",
      "0.3186868686868687 0.30771708514857316\n",
      "0.3207070707070707 0.3077264755136443\n",
      "0.32272727272727275 0.3014708365695871\n",
      "0.32474747474747473 0.29434058318596296\n",
      "0.32676767676767676 0.2926222168764437\n",
      "0.3287878787878788 0.29260326739395265\n",
      "0.3308080808080808 0.28232934610656196\n",
      "0.3328282828282828 0.2849277267127692\n",
      "0.33484848484848484 0.28744165491502566\n",
      "0.3368686868686869 0.2878544496452035\n",
      "0.3388888888888889 0.29131503511533274\n",
      "0.34090909090909094 0.2917417903800382\n",
      "0.3429292929292929 0.2930458767726843\n",
      "0.34494949494949495 0.2930642728087713\n",
      "0.346969696969697 0.29329781392220106\n",
      "0.34898989898989896 0.2959637364970072\n",
      "0.351010101010101 0.294108150440317\n",
      "0.353030303030303 0.30230596638819024\n",
      "0.35505050505050506 0.29408047471676985\n",
      "0.3570707070707071 0.29783114548720413\n",
      "0.35909090909090907 0.30121991634425677\n",
      "0.3611111111111111 0.29981541147625757\n",
      "0.36313131313131314 0.30084412070787997\n",
      "0.36515151515151517 0.2917369778507371\n",
      "0.36717171717171715 0.2972251209351278\n",
      "0.3691919191919192 0.2974966525641603\n",
      "0.3712121212121212 0.2977898561677736\n",
      "0.37323232323232325 0.29834920205499754\n",
      "0.3752525252525253 0.29834920205499754\n",
      "0.37727272727272726 0.29835864850287613\n",
      "0.3792929292929293 0.2983398116899264\n",
      "0.3813131313131313 0.30166754933599665\n",
      "0.3833333333333333 0.30192085843059885\n",
      "0.38535353535353534 0.29198932857811233\n",
      "0.38737373737373737 0.2807447892967563\n",
      "0.3893939393939394 0.2807544651761408\n",
      "0.39141414141414144 0.2810110395652559\n",
      "0.39343434343434347 0.281020599696584\n",
      "0.39545454545454545 0.2812904980211068\n",
      "0.3974747474747475 0.2821325747182498\n",
      "0.39949494949494946 0.2843767090843204\n",
      "0.4015151515151515 0.28535204571916006\n",
      "0.4035353535353535 0.28545246538122143\n",
      "0.40555555555555556 0.28611087241443045\n",
      "0.4075757575757576 0.2864464085622935\n",
      "0.4095959595959596 0.2867768299145443\n",
      "0.4116161616161616 0.29000373855475176\n",
      "0.41363636363636364 0.2897922494156418\n",
      "0.41565656565656567 0.29015796864254384\n",
      "0.41767676767676765 0.29013844035689906\n",
      "0.4196969696969697 0.29047967955954807\n",
      "0.4217171717171717 0.2904893554389325\n",
      "0.42373737373737375 0.29050888372457734\n",
      "0.4257575757575758 0.29028914947039663\n",
      "0.4277777777777778 0.2899782211269253\n",
      "0.4297979797979798 0.28996818510498595\n",
      "0.4318181818181818 0.2922289029694857\n",
      "0.4338383838383838 0.29199190536759456\n",
      "0.43585858585858583 0.2919720169794739\n",
      "0.43787878787878787 0.2919720169794739\n",
      "0.4398989898989899 0.2923557049185089\n",
      "0.44191919191919193 0.29504354957263984\n",
      "0.44393939393939397 0.29503351355070045\n",
      "0.445959595959596 0.29858405657492776\n",
      "0.447979797979798 0.30260311619378616\n",
      "0.45 0.3035336085925741\n"
     ]
    }
   ],
   "source": [
    "best_sikii = 0\n",
    "best_score = -np.inf\n",
    "\n",
    "for sikii in np.linspace(0.25, 0.45, 100):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": sikii,\n",
    "        \"beta-amylase\": sikii,\n",
    "        \"beta-galactosidase\": sikii,\n",
    "        \"ribosome\": sikii,\n",
    "        \"thyroglobulin\": sikii,\n",
    "        \"virus-like-particle\": sikii,\n",
    "    }\n",
    "    score_ = calc_score(initial_sikii)\n",
    "    if score_ > best_score:\n",
    "        best_score = score_\n",
    "        best_sikii = sikii\n",
    "    print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3106060606060606, 0.34563170209903055)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sikii, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
