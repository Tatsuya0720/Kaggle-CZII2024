{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import UNet_2D, aug\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TS_5_4', 'denoised'), ('TS_5_4', 'ctfdeconvolved'), ('TS_5_4', 'wbp'), ('TS_5_4', 'isonetcorrected'), ('TS_73_6', 'denoised'), ('TS_73_6', 'ctfdeconvolved'), ('TS_73_6', 'wbp'), ('TS_73_6', 'isonetcorrected'), ('TS_99_9', 'denoised'), ('TS_99_9', 'ctfdeconvolved'), ('TS_99_9', 'wbp'), ('TS_99_9', 'isonetcorrected'), ('TS_6_4', 'denoised'), ('TS_6_4', 'ctfdeconvolved'), ('TS_6_4', 'wbp'), ('TS_6_4', 'isonetcorrected'), ('TS_69_2', 'denoised'), ('TS_69_2', 'ctfdeconvolved'), ('TS_69_2', 'wbp'), ('TS_69_2', 'isonetcorrected')]\n",
      "[('TS_86_3', 'denoised'), ('TS_6_6', 'denoised')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = EziiDataset(\n",
    "    exp_names=CFG.train_exp_names,\n",
    "    base_dir=\"../../inputs/train\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.train_zarr_types,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "valid_dataset = EziiDataset(\n",
    "    exp_names=CFG.valid_exp_names,\n",
    "    # exp_names=CFG.train_exp_names,\n",
    "    base_dir=\"../../inputs/train\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.valid_zarr_types,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "for row in tqdm(valid_loader):\n",
    "    normalized_tomogram = row[\"normalized_tomogram\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadToSize(nn.Module):\n",
    "    def __init__(self, resolution):\n",
    "        super().__init__()\n",
    "        if resolution == \"0\":\n",
    "            self.size = 640\n",
    "        elif resolution == \"1\":\n",
    "            self.size = 320\n",
    "        elif resolution == \"2\":\n",
    "            self.size = 160\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.pad(x, (0, 0, self.size - x.shape[-1], self.size - x.shape[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4293923941643343: : 184it [00:04, 42.35it/s]                   \n"
     ]
    }
   ],
   "source": [
    "model = UNet_2D().to(\"cuda\")\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor([0.5, 32, 32, 32, 32, 32, 32]).to(\"cuda\")\n",
    ")\n",
    "# criterion = DiceLoss()\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "batch_size = 4\n",
    "\n",
    "valid_loss = []\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "model.eval()\n",
    "tq = tqdm(range(len(valid_loader) * normalized_tomogram.shape[0]))\n",
    "for data in valid_loader:\n",
    "    exp_name = data[\"exp_name\"][0]\n",
    "    tomogram = data[\"normalized_tomogram\"].to(\"cuda\")\n",
    "    segmentation_map = data[\"segmentation_map\"].to(\"cuda\").long()\n",
    "\n",
    "    for i in range(tomogram.shape[1]):\n",
    "        input_ = tomogram[:, i].unsqueeze(0)\n",
    "        gt = segmentation_map[:, i]\n",
    "\n",
    "        input_ = PadToSize(CFG.resolution)(input_)\n",
    "        gt = PadToSize(CFG.resolution)(gt)\n",
    "        output = model(input_)\n",
    "        output = nn.functional.softmax(output, dim=1)\n",
    "        loss = criterion(output, gt)\n",
    "\n",
    "        valid_loss.append(loss.item())\n",
    "        tq.set_description(f\"Loss: {np.mean(valid_loss)}\")\n",
    "        tq.update(1)\n",
    "\n",
    "        output = drop_padding(output, CFG.resolution)\n",
    "\n",
    "        valid_pred_tomogram[exp_name].append(output.cpu().detach().numpy())\n",
    "        valid_gt_tomogram[exp_name].append(gt.cpu().detach().numpy())\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()  # index\texperiment\tparticle_type\tx\ty\tz\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.valid_exp_names)\n",
    "gt_df = gt_df[gt_df[\"particle_type\"] != \"beta-amylase\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pd.read_csv(\"../../inputs/train_submission.csv\")\n",
    "\n",
    "\n",
    "def calc_score(initial_sikii):\n",
    "    all_pred_df = None\n",
    "\n",
    "    for exp_name in CFG.valid_exp_names:\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "        # pred_df = create_df(pred_cls_pos, exp_name)\n",
    "\n",
    "        if all_pred_df is None:\n",
    "            all_pred_df = pred_df\n",
    "        else:\n",
    "            all_pred_df = pd.concat([all_pred_df, pred_df], axis=0).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "    pred_df = all_pred_df[all_pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "    pred_df = pred_df.drop_duplicates(subset=[\"x\", \"y\", \"z\"], keep=\"first\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    pred_df = pred_df.reset_index()\n",
    "\n",
    "    score_ = score(\n",
    "        pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "    )\n",
    "\n",
    "    return score_\n",
    "\n",
    "\n",
    "def calc_score_by_exp(initial_sikii):\n",
    "    exp_scores = {}\n",
    "\n",
    "    for exp_name in CFG.valid_exp_names:\n",
    "        gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", [exp_name])\n",
    "\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "\n",
    "        pred_df = pred_df[pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "        pred_df = pred_df.drop_duplicates(\n",
    "            subset=[\"x\", \"y\", \"z\"], keep=\"first\"\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        pred_df = pred_df.reset_index()\n",
    "\n",
    "        score_ = score(\n",
    "            pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "        )\n",
    "\n",
    "        exp_scores[exp_name] = score_\n",
    "\n",
    "    return exp_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36860293385709647"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = 0.35\n",
    "\n",
    "initial_sikii = {\n",
    "    \"apo-ferritin\": constant,\n",
    "    \"beta-amylase\": constant,\n",
    "    \"beta-galactosidase\": constant,\n",
    "    \"ribosome\": constant,\n",
    "    \"thyroglobulin\": constant,\n",
    "    \"virus-like-particle\": constant,\n",
    "}\n",
    "\n",
    "score_ = calc_score(initial_sikii)\n",
    "score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TS_86_3': 0.40603102493658433, 'TS_6_6': 0.3223497699636737}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = 0.35\n",
    "\n",
    "initial_sikii = {\n",
    "    \"apo-ferritin\": constant,\n",
    "    \"beta-amylase\": constant,\n",
    "    \"beta-galactosidase\": constant,\n",
    "    \"ribosome\": constant,\n",
    "    \"thyroglobulin\": constant,\n",
    "    \"virus-like-particle\": constant,\n",
    "}\n",
    "\n",
    "score_ = calc_score_by_exp(initial_sikii)\n",
    "score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.33673918066122355\n",
      "0.30404040404040406 0.3411127229927137\n",
      "0.30808080808080807 0.34304248125087844\n",
      "0.31212121212121213 0.3495508827470091\n",
      "0.31616161616161614 0.3509147590227553\n",
      "0.3202020202020202 0.3543681500852413\n",
      "0.3242424242424242 0.36157162044766933\n",
      "0.3282828282828283 0.3599567445543362\n",
      "0.3323232323232323 0.3587959760392257\n",
      "0.33636363636363636 0.3595025750060075\n",
      "0.3404040404040404 0.35896568883692886\n",
      "0.34444444444444444 0.3628377477787102\n",
      "0.34848484848484845 0.36446114363517923\n",
      "0.3525252525252525 0.3700907454751164\n",
      "0.35656565656565653 0.3755850867218819\n",
      "0.3606060606060606 0.37808045109985955\n",
      "0.36464646464646466 0.3804979305677422\n",
      "0.3686868686868687 0.3766523772725905\n",
      "0.3727272727272727 0.38082582661259096\n",
      "0.37676767676767675 0.386678644108659\n",
      "0.3808080808080808 0.38922909491571916\n",
      "0.38484848484848483 0.3945733305202078\n",
      "0.3888888888888889 0.39107533074233103\n",
      "0.3929292929292929 0.39389194332909955\n",
      "0.396969696969697 0.39527181345896967\n",
      "0.401010101010101 0.39713256869768687\n",
      "0.40505050505050505 0.38780272827606055\n",
      "0.40909090909090906 0.388678976344362\n",
      "0.4131313131313131 0.38938339716641135\n",
      "0.4171717171717172 0.3937163010485177\n",
      "0.4212121212121212 0.39507360812901904\n",
      "0.4252525252525252 0.39374266394468377\n",
      "0.4292929292929293 0.39715298818034933\n",
      "0.43333333333333335 0.40482640343051773\n",
      "0.43737373737373736 0.4079874656382307\n",
      "0.44141414141414137 0.4055344686107623\n",
      "0.44545454545454544 0.42223884460991595\n",
      "0.4494949494949495 0.4312984093142164\n",
      "0.4535353535353535 0.42638286886151766\n",
      "0.4575757575757575 0.43276330561197157\n",
      "0.4616161616161616 0.43825885790844277\n",
      "0.46565656565656566 0.4421055539141164\n",
      "0.4696969696969697 0.44936758357701584\n",
      "0.47373737373737373 0.4613704421852479\n",
      "0.47777777777777775 0.4658927186653381\n",
      "0.4818181818181818 0.46401556417706935\n",
      "0.4858585858585859 0.46604590753151937\n",
      "0.4898989898989899 0.47117400074983323\n",
      "0.4939393939393939 0.47163215715045614\n",
      "0.49797979797979797 0.47005324757246303\n",
      "0.502020202020202 0.47530570887336954\n",
      "0.5060606060606061 0.4768296394938331\n",
      "0.51010101010101 0.47761346633119656\n",
      "0.5141414141414141 0.47734722860053946\n",
      "0.5181818181818182 0.48187467456873573\n",
      "0.5222222222222221 0.48811577381171894\n",
      "0.5262626262626262 0.48804327620127685\n",
      "0.5303030303030303 0.4913877580849696\n",
      "0.5343434343434343 0.48827128794733893\n",
      "0.5383838383838384 0.4897564739593499\n",
      "0.5424242424242425 0.49855206384681316\n",
      "0.5464646464646464 0.5060299335787389\n",
      "0.5505050505050505 0.5072363848839035\n",
      "0.5545454545454545 0.5147341603404815\n",
      "0.5585858585858585 0.5232002401898503\n",
      "0.5626262626262626 0.5249461563229455\n",
      "0.5666666666666667 0.5293386277750814\n",
      "0.5707070707070707 0.5280544561790669\n",
      "0.5747474747474748 0.5148136811450849\n",
      "0.5787878787878789 0.505278541081249\n",
      "0.5828282828282828 0.5241101388099699\n",
      "0.5868686868686869 0.5232183242758083\n",
      "0.5909090909090908 0.5144355614245557\n",
      "0.5949494949494949 0.507335879522996\n",
      "0.598989898989899 0.4928484276092085\n",
      "0.603030303030303 0.4773713668111826\n",
      "0.6070707070707071 0.4727138772768952\n",
      "0.6111111111111112 0.48062499745072035\n",
      "0.6151515151515151 0.47648908550335783\n",
      "0.6191919191919192 0.46530487497704204\n",
      "0.6232323232323231 0.4274628813725106\n",
      "0.6272727272727272 0.4237152348869344\n",
      "0.6313131313131313 0.42071149840350136\n",
      "0.6353535353535353 0.45718021623869376\n",
      "0.6393939393939394 0.4670249661575229\n",
      "0.6434343434343435 0.4679792515900002\n",
      "0.6474747474747475 0.46741224916895874\n",
      "0.6515151515151515 0.46958043241980185\n",
      "0.6555555555555556 0.445585445211455\n",
      "0.6595959595959595 0.43182451836812585\n",
      "0.6636363636363636 0.42932703635646885\n",
      "0.6676767676767676 0.38554866248901376\n",
      "0.6717171717171717 0.39271174220667\n",
      "0.6757575757575758 0.39215198846129196\n",
      "0.6797979797979798 0.39068549947283465\n",
      "0.6838383838383838 0.40073208221720696\n",
      "0.6878787878787879 0.39906810929797937\n",
      "0.6919191919191919 0.39094964656769765\n",
      "0.6959595959595959 0.40956034577817\n",
      "0.7 0.41079171504516154\n"
     ]
    }
   ],
   "source": [
    "best_sikii = 0\n",
    "best_score = -np.inf\n",
    "\n",
    "for sikii in np.linspace(0.3, 0.7, 100):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": sikii,\n",
    "        \"beta-amylase\": sikii,\n",
    "        \"beta-galactosidase\": sikii,\n",
    "        \"ribosome\": sikii,\n",
    "        \"thyroglobulin\": sikii,\n",
    "        \"virus-like-particle\": sikii,\n",
    "    }\n",
    "    score_ = calc_score(initial_sikii)\n",
    "    if score_ > best_score:\n",
    "        best_score = score_\n",
    "        best_sikii = sikii\n",
    "    print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5666666666666667, 0.5293386277750814)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sikii, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4310990602425906: : 1840it [00:32, 57.34it/s]                    \n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor([0.5, 32, 32, 32, 32, 32, 32]).to(\"cuda\")\n",
    ")\n",
    "# criterion = DiceLoss()\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "batch_size = 4\n",
    "\n",
    "train_loss = []\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "model.eval()\n",
    "tq = tqdm(range(len(train_loader) * normalized_tomogram.shape[0]))\n",
    "for data in train_loader:\n",
    "    exp_name = data[\"exp_name\"][0]\n",
    "    tomogram = data[\"normalized_tomogram\"].to(\"cuda\")\n",
    "    segmentation_map = data[\"segmentation_map\"].to(\"cuda\").long()\n",
    "\n",
    "    for i in range(tomogram.shape[1]):\n",
    "        input_ = tomogram[:, i].unsqueeze(0)\n",
    "        gt = segmentation_map[:, i]\n",
    "\n",
    "        input_ = PadToSize(CFG.resolution)(input_)\n",
    "        gt = PadToSize(CFG.resolution)(gt)\n",
    "        output = model(input_)\n",
    "        output = nn.functional.softmax(output, dim=1)\n",
    "        loss = criterion(output, gt)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        tq.set_description(f\"Loss: {np.mean(train_loss)}\")\n",
    "        tq.update(1)\n",
    "\n",
    "        output = drop_padding(output, CFG.resolution)\n",
    "\n",
    "        valid_pred_tomogram[exp_name].append(output.cpu().detach().numpy())\n",
    "        valid_gt_tomogram[exp_name].append(gt.cpu().detach().numpy())\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(initial_sikii):\n",
    "    all_pred_df = None\n",
    "\n",
    "    for exp_name in CFG.train_exp_names:\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "        # pred_df = create_df(pred_cls_pos, exp_name)\n",
    "\n",
    "        if all_pred_df is None:\n",
    "            all_pred_df = pred_df\n",
    "        else:\n",
    "            all_pred_df = pd.concat([all_pred_df, pred_df], axis=0).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "    pred_df = all_pred_df[all_pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "    pred_df = pred_df.drop_duplicates(subset=[\"x\", \"y\", \"z\"], keep=\"first\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    pred_df = pred_df.reset_index()\n",
    "\n",
    "    score_ = score(\n",
    "        pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "    )\n",
    "\n",
    "    return score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.train_exp_names)\n",
    "gt_df = gt_df[gt_df[\"particle_type\"] != \"beta-amylase\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.29132777065298665\n",
      "0.25202020202020203 0.2927766880881479\n",
      "0.25404040404040407 0.29350447569485416\n",
      "0.25606060606060604 0.29442226483249534\n",
      "0.2580808080808081 0.2952753951595782\n",
      "0.2601010101010101 0.29641173006205646\n",
      "0.26212121212121214 0.2973902797084916\n",
      "0.2641414141414141 0.29877998142344675\n",
      "0.26616161616161615 0.30005512468012313\n",
      "0.2681818181818182 0.301765411711211\n",
      "0.2702020202020202 0.3032512396286127\n",
      "0.2722222222222222 0.30380683026735417\n",
      "0.27424242424242423 0.3044897584741107\n",
      "0.27626262626262627 0.30434947213184455\n",
      "0.2782828282828283 0.30428094295533825\n",
      "0.2803030303030303 0.30504629928258253\n",
      "0.2823232323232323 0.304276383292793\n",
      "0.28434343434343434 0.30519169595338547\n",
      "0.2863636363636364 0.3058865574382293\n",
      "0.2883838383838384 0.30765069660286104\n",
      "0.2904040404040404 0.30818807174245794\n",
      "0.2924242424242424 0.30890508698811026\n",
      "0.29444444444444445 0.30922328928753157\n",
      "0.2964646464646465 0.309424359829029\n",
      "0.29848484848484846 0.31020475100621564\n",
      "0.3005050505050505 0.31177813736226995\n",
      "0.30252525252525253 0.31263442160053795\n",
      "0.30454545454545456 0.3129137521274374\n",
      "0.3065656565656566 0.31329490746344885\n",
      "0.3085858585858586 0.31416767649835137\n",
      "0.3106060606060606 0.31543152778316497\n",
      "0.31262626262626264 0.3170083190056701\n",
      "0.3146464646464646 0.3164195583496398\n",
      "0.31666666666666665 0.3171654976587281\n",
      "0.3186868686868687 0.3181329780612132\n",
      "0.3207070707070707 0.31853729855345925\n",
      "0.32272727272727275 0.31885223316463895\n",
      "0.32474747474747473 0.32014910333783675\n",
      "0.32676767676767676 0.3215714334587916\n",
      "0.3287878787878788 0.32245345786090346\n",
      "0.3308080808080808 0.323839183498751\n",
      "0.3328282828282828 0.3243953947555677\n",
      "0.33484848484848484 0.3255998461009438\n",
      "0.3368686868686869 0.3267993399039239\n",
      "0.3388888888888889 0.32693615691225847\n",
      "0.34090909090909094 0.3275374010402075\n",
      "0.3429292929292929 0.3287818005095256\n",
      "0.34494949494949495 0.32994655536857787\n",
      "0.346969696969697 0.3293644329086031\n",
      "0.34898989898989896 0.3307618985031718\n",
      "0.351010101010101 0.3305754944705771\n",
      "0.353030303030303 0.3315792641437515\n",
      "0.35505050505050506 0.3323184058132275\n",
      "0.3570707070707071 0.33058252768040736\n",
      "0.35909090909090907 0.3309301346469851\n",
      "0.3611111111111111 0.33255811171305705\n",
      "0.36313131313131314 0.33438856739178896\n",
      "0.36515151515151517 0.33633392047059074\n",
      "0.36717171717171715 0.3366032008478014\n",
      "0.3691919191919192 0.33851771114694257\n",
      "0.3712121212121212 0.33932822970581117\n",
      "0.37323232323232325 0.3395279862381027\n",
      "0.3752525252525253 0.34065411752419533\n",
      "0.37727272727272726 0.34276518028685005\n",
      "0.3792929292929293 0.3433190466397499\n",
      "0.3813131313131313 0.3444611074805294\n",
      "0.3833333333333333 0.34303403723817955\n",
      "0.38535353535353534 0.3436397235675893\n",
      "0.38737373737373737 0.3450311631910856\n",
      "0.3893939393939394 0.3463472185912758\n",
      "0.39141414141414144 0.3479565477786514\n",
      "0.39343434343434347 0.34990249891371367\n",
      "0.39545454545454545 0.3511778251030358\n",
      "0.3974747474747475 0.35207528677547056\n",
      "0.39949494949494946 0.3548011990394522\n",
      "0.4015151515151515 0.35569222082688573\n",
      "0.4035353535353535 0.3575074261897245\n",
      "0.40555555555555556 0.35914271192850766\n",
      "0.4075757575757576 0.35895614831419015\n",
      "0.4095959595959596 0.360267303200452\n",
      "0.4116161616161616 0.36101413791131826\n",
      "0.41363636363636364 0.36192374984176723\n",
      "0.41565656565656567 0.3620170930176707\n",
      "0.41767676767676765 0.36360568823061523\n",
      "0.4196969696969697 0.36438761882706333\n",
      "0.4217171717171717 0.36462933238091066\n",
      "0.42373737373737375 0.36581948727312\n",
      "0.4257575757575758 0.36660940981028484\n",
      "0.4277777777777778 0.36688440264655114\n",
      "0.4297979797979798 0.36791853808516484\n",
      "0.4318181818181818 0.3677800642974292\n",
      "0.4338383838383838 0.368034333830984\n",
      "0.43585858585858583 0.36947659062099597\n",
      "0.43787878787878787 0.370100924257751\n",
      "0.4398989898989899 0.3716561463727815\n",
      "0.44191919191919193 0.37218011800647127\n",
      "0.44393939393939397 0.3730826331051424\n",
      "0.445959595959596 0.3731664132887255\n",
      "0.447979797979798 0.3756022591680725\n",
      "0.45 0.37598672547517936\n"
     ]
    }
   ],
   "source": [
    "best_sikii = 0\n",
    "best_score = -np.inf\n",
    "\n",
    "for sikii in np.linspace(0.25, 0.45, 100):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": sikii,\n",
    "        \"beta-amylase\": sikii,\n",
    "        \"beta-galactosidase\": sikii,\n",
    "        \"ribosome\": sikii,\n",
    "        \"thyroglobulin\": sikii,\n",
    "        \"virus-like-particle\": sikii,\n",
    "    }\n",
    "    score_ = calc_score(initial_sikii)\n",
    "    if score_ > best_score:\n",
    "        best_score = score_\n",
    "        best_sikii = sikii\n",
    "    print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
