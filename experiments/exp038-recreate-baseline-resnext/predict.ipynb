{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import UNet_2D, aug\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TS_5_4', 'denoised'), ('TS_73_6', 'denoised'), ('TS_99_9', 'denoised'), ('TS_6_4', 'denoised'), ('TS_69_2', 'denoised')]\n",
      "[('TS_86_3', 'denoised'), ('TS_6_6', 'denoised')]\n",
      "[('TS_6_4', 'denoised'), ('TS_5_4', 'denoised'), ('TS_69_2', 'denoised')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = EziiDataset(\n",
    "    exp_names=CFG.train_exp_names,\n",
    "    base_dir=\"../../inputs/train\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.train_zarr_types,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "valid_dataset = EziiDataset(\n",
    "    exp_names=CFG.valid_exp_names,\n",
    "    # exp_names=CFG.train_exp_names,\n",
    "    base_dir=\"../../inputs/train\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.valid_zarr_types,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "test_dataset = EziiDataset(\n",
    "    exp_names=[\"TS_6_4\", \"TS_5_4\", \"TS_69_2\"],\n",
    "    base_dir=\"../../inputs/test\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.valid_zarr_types,\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "for row in tqdm(valid_loader):\n",
    "    normalized_tomogram = row[\"normalized_tomogram\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadToSize(nn.Module):\n",
    "    def __init__(self, resolution):\n",
    "        super().__init__()\n",
    "        if resolution == \"0\":\n",
    "            self.size = 640\n",
    "        elif resolution == \"1\":\n",
    "            self.size = 320\n",
    "        elif resolution == \"2\":\n",
    "            self.size = 160\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.pad(x, (0, 0, self.size - x.shape[-1], self.size - x.shape[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4098689271056133: : 184it [00:05, 31.53it/s]                   \n"
     ]
    }
   ],
   "source": [
    "model = UNet_2D().to(\"cuda\")\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor([0.5, 32, 32, 32, 32, 32, 32]).to(\"cuda\")\n",
    ")\n",
    "# criterion = DiceLoss()\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "batch_size = 4\n",
    "\n",
    "valid_loss = []\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "model.eval()\n",
    "tq = tqdm(range(len(valid_loader) * normalized_tomogram.shape[0]))\n",
    "for data in valid_loader:\n",
    "    exp_name = data[\"exp_name\"][0]\n",
    "    tomogram = data[\"normalized_tomogram\"].to(\"cuda\")\n",
    "    segmentation_map = data[\"segmentation_map\"].to(\"cuda\").long()\n",
    "\n",
    "    for i in range(tomogram.shape[1]):\n",
    "        input_ = tomogram[:, i].unsqueeze(0)\n",
    "        gt = segmentation_map[:, i]\n",
    "\n",
    "        input_ = PadToSize(CFG.resolution)(input_)\n",
    "        gt = PadToSize(CFG.resolution)(gt)\n",
    "        output = model(input_)\n",
    "        output = nn.functional.softmax(output, dim=1)\n",
    "        loss = criterion(output, gt)\n",
    "\n",
    "        valid_loss.append(loss.item())\n",
    "        tq.set_description(f\"Loss: {np.mean(valid_loss)}\")\n",
    "        tq.update(1)\n",
    "\n",
    "        output = drop_padding(output, CFG.resolution)\n",
    "\n",
    "        valid_pred_tomogram[exp_name].append(output.cpu().detach().numpy())\n",
    "        valid_gt_tomogram[exp_name].append(gt.cpu().detach().numpy())\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()  # index\texperiment\tparticle_type\tx\ty\tz\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.valid_exp_names)\n",
    "gt_df = gt_df[gt_df[\"particle_type\"] != \"beta-amylase\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pd.read_csv(\"../../inputs/train_submission.csv\")\n",
    "\n",
    "\n",
    "def calc_score(initial_sikii):\n",
    "    all_pred_df = None\n",
    "\n",
    "    for exp_name in CFG.valid_exp_names:\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "        # pred_df = create_df(pred_cls_pos, exp_name)\n",
    "\n",
    "        if all_pred_df is None:\n",
    "            all_pred_df = pred_df\n",
    "        else:\n",
    "            all_pred_df = pd.concat([all_pred_df, pred_df], axis=0).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "    pred_df = all_pred_df[all_pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "    pred_df = pred_df.drop_duplicates(subset=[\"x\", \"y\", \"z\"], keep=\"first\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    pred_df = pred_df.reset_index()\n",
    "\n",
    "    score_ = score(\n",
    "        pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "    )\n",
    "\n",
    "    return score_\n",
    "\n",
    "\n",
    "def calc_score_by_exp(initial_sikii):\n",
    "    exp_scores = {}\n",
    "\n",
    "    for exp_name in CFG.valid_exp_names:\n",
    "        gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", [exp_name])\n",
    "\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "\n",
    "        pred_df = pred_df[pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "        pred_df = pred_df.drop_duplicates(\n",
    "            subset=[\"x\", \"y\", \"z\"], keep=\"first\"\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        pred_df = pred_df.reset_index()\n",
    "\n",
    "        score_ = score(\n",
    "            pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "        )\n",
    "\n",
    "        exp_scores[exp_name] = score_\n",
    "\n",
    "    return exp_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40961808882615064"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = 0.35\n",
    "\n",
    "initial_sikii = {\n",
    "    \"apo-ferritin\": constant,\n",
    "    \"beta-amylase\": constant,\n",
    "    \"beta-galactosidase\": constant,\n",
    "    \"ribosome\": constant,\n",
    "    \"thyroglobulin\": constant,\n",
    "    \"virus-like-particle\": constant,\n",
    "}\n",
    "\n",
    "score_ = calc_score(initial_sikii)\n",
    "score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TS_86_3': 0.44080015765748864, 'TS_6_6': 0.3910825215452486}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = 0.5666666666666667\n",
    "\n",
    "initial_sikii = {\n",
    "    \"apo-ferritin\": constant,\n",
    "    \"beta-amylase\": constant,\n",
    "    \"beta-galactosidase\": constant,\n",
    "    \"ribosome\": constant,\n",
    "    \"thyroglobulin\": constant,\n",
    "    \"virus-like-particle\": constant,\n",
    "}\n",
    "\n",
    "score_ = calc_score_by_exp(initial_sikii)\n",
    "score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.3957025779557223\n",
      "0.23947368421052634 0.40332092797237706\n",
      "0.2789473684210526 0.4030039120332141\n",
      "0.31842105263157894 0.40443421186720385\n",
      "0.35789473684210527 0.41181675756868813\n",
      "0.3973684210526316 0.413224127494667\n",
      "0.4368421052631579 0.4158814062366284\n",
      "0.4763157894736842 0.4158306046824602\n",
      "0.5157894736842106 0.4244004628470684\n",
      "0.5552631578947369 0.42358389254979595\n",
      "0.5947368421052632 0.4238015105183553\n",
      "0.6342105263157894 0.4236576024119786\n",
      "0.6736842105263158 0.4312050460170022\n",
      "0.713157894736842 0.4351301378710371\n",
      "0.7526315789473683 0.4353845448222253\n",
      "0.7921052631578946 0.4365060827310829\n",
      "0.831578947368421 0.44336313508708125\n",
      "0.8710526315789473 0.4413418707173969\n",
      "0.9105263157894736 0.4434044904336027\n",
      "0.95 0.4543961463399036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.95, 0.4543961463399036)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sikii = 0\n",
    "best_score = -np.inf\n",
    "\n",
    "for sikii in np.linspace(0.2, 0.95, 20):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": sikii,\n",
    "        \"beta-amylase\": sikii,\n",
    "        \"beta-galactosidase\": sikii,\n",
    "        \"ribosome\": sikii,\n",
    "        \"thyroglobulin\": sikii,\n",
    "        \"virus-like-particle\": sikii,\n",
    "    }\n",
    "    score_ = calc_score(initial_sikii)\n",
    "    if score_ > best_score:\n",
    "        best_score = score_\n",
    "        best_sikii = sikii\n",
    "    print(sikii, score_)\n",
    "\n",
    "best_sikii, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [00:08, 56.76it/s]                     \n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "model.eval()\n",
    "tq = tqdm(range(len(train_loader) * normalized_tomogram.shape[0]))\n",
    "for data in train_loader:\n",
    "    exp_name = data[\"exp_name\"][0]\n",
    "    tomogram = data[\"normalized_tomogram\"].to(\"cuda\")\n",
    "    segmentation_map = data[\"segmentation_map\"].to(\"cuda\").long()\n",
    "\n",
    "    for i in range(tomogram.shape[1]):\n",
    "        input_ = tomogram[:, i].unsqueeze(0)\n",
    "        gt = segmentation_map[:, i]\n",
    "\n",
    "        input_ = PadToSize(CFG.resolution)(input_)\n",
    "        gt = PadToSize(CFG.resolution)(gt)\n",
    "        output = model(input_)\n",
    "        output = nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        tq.update(1)\n",
    "\n",
    "        output = drop_padding(output, CFG.resolution)\n",
    "\n",
    "        valid_pred_tomogram[exp_name].append(output.cpu().detach().numpy())\n",
    "        valid_gt_tomogram[exp_name].append(gt.cpu().detach().numpy())\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(initial_sikii):\n",
    "    all_pred_df = None\n",
    "\n",
    "    for exp_name in CFG.train_exp_names:\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "        # pred_df = create_df(pred_cls_pos, exp_name)\n",
    "\n",
    "        if all_pred_df is None:\n",
    "            all_pred_df = pred_df\n",
    "        else:\n",
    "            all_pred_df = pd.concat([all_pred_df, pred_df], axis=0).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "    pred_df = all_pred_df[all_pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "    pred_df = pred_df.drop_duplicates(subset=[\"x\", \"y\", \"z\"], keep=\"first\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    pred_df = pred_df.reset_index()\n",
    "\n",
    "    score_ = score(\n",
    "        pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "    )\n",
    "\n",
    "    return score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.train_exp_names)\n",
    "gt_df = gt_df[gt_df[\"particle_type\"] != \"beta-amylase\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.5233371989538083\n",
      "0.41250000000000003 0.5220339476946451\n",
      "0.42500000000000004 0.5224742271358669\n",
      "0.4375 0.5231868690840479\n",
      "0.45 0.5238979923464432\n",
      "0.4625 0.5239415420117144\n",
      "0.475 0.525371329486292\n",
      "0.4875 0.5282893858892282\n",
      "0.5 0.5291182709045567\n",
      "0.5125 0.5305640521699773\n",
      "0.525 0.5318691197198139\n",
      "0.5375 0.5313935323424184\n",
      "0.55 0.5313930788383405\n",
      "0.5625 0.5333768106878524\n",
      "0.575 0.5333962746869853\n",
      "0.5874999999999999 0.5346341677905111\n",
      "0.6 0.5340835922066864\n",
      "0.6125 0.535174090572464\n",
      "0.625 0.5368187982391992\n",
      "0.6375 0.5384283346361342\n",
      "0.6499999999999999 0.5362759874135204\n",
      "0.6625 0.5381902330276026\n",
      "0.6749999999999999 0.539139617985237\n",
      "0.6875 0.539682098814598\n",
      "0.7 0.5414035081753893\n"
     ]
    }
   ],
   "source": [
    "best_sikii = 0\n",
    "best_score = -np.inf\n",
    "\n",
    "for sikii in np.linspace(0.4, 0.7, 25):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": sikii,\n",
    "        \"beta-amylase\": sikii,\n",
    "        \"beta-galactosidase\": sikii,\n",
    "        \"ribosome\": sikii,\n",
    "        \"thyroglobulin\": sikii,\n",
    "        \"virus-like-particle\": sikii,\n",
    "    }\n",
    "    score_ = calc_score(initial_sikii)\n",
    "    if score_ > best_score:\n",
    "        best_score = score_\n",
    "        best_sikii = sikii\n",
    "    print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.5414035081753893)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sikii, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [00:03, 71.27it/s]                     \n"
     ]
    }
   ],
   "source": [
    "valid_pred_tomogram = defaultdict(list)\n",
    "model.eval()\n",
    "tq = tqdm(range(len(test_loader) * normalized_tomogram.shape[0]))\n",
    "for data in test_loader:\n",
    "    exp_name = data[\"exp_name\"][0]\n",
    "    tomogram = data[\"normalized_tomogram\"].to(\"cuda\")\n",
    "\n",
    "    for i in range(tomogram.shape[1]):\n",
    "        input_ = tomogram[:, i].unsqueeze(0)\n",
    "\n",
    "        input_ = PadToSize(CFG.resolution)(input_)\n",
    "        output = model(input_)\n",
    "        output = nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        tq.update(1)\n",
    "\n",
    "        output = drop_padding(output, CFG.resolution)\n",
    "\n",
    "        valid_pred_tomogram[exp_name].append(output.cpu().detach().numpy())\n",
    "tq.close()\n",
    "\n",
    "all_pred_df = None\n",
    "\n",
    "for exp_name in [\"TS_6_4\", \"TS_5_4\", \"TS_69_2\"]:\n",
    "    pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "    pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "    pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "    pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "        pred_tomogram, sikii_dict=initial_sikii\n",
    "    )\n",
    "    pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "    # pred_df = create_df(pred_cls_pos, exp_name)\n",
    "\n",
    "    if all_pred_df is None:\n",
    "        all_pred_df = pred_df\n",
    "    else:\n",
    "        all_pred_df = pd.concat([all_pred_df, pred_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "pred_df = all_pred_df[all_pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "pred_df = pred_df.drop_duplicates(subset=[\"x\", \"y\", \"z\"], keep=\"first\").reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "pred_df = pred_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>experiment</th>\n",
       "      <th>particle_type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TS_6_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>3139.936425</td>\n",
       "      <td>3139.959793</td>\n",
       "      <td>910.076514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TS_6_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>4546.956522</td>\n",
       "      <td>2133.913043</td>\n",
       "      <td>214.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TS_6_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>4655.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TS_6_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>4029.863014</td>\n",
       "      <td>2881.917808</td>\n",
       "      <td>276.164384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TS_6_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>3890.000000</td>\n",
       "      <td>2450.000000</td>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>634</td>\n",
       "      <td>TS_69_2</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>3590.344828</td>\n",
       "      <td>2368.857759</td>\n",
       "      <td>911.077586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>635</td>\n",
       "      <td>TS_69_2</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>5119.028476</td>\n",
       "      <td>5666.733668</td>\n",
       "      <td>890.653266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>636</td>\n",
       "      <td>TS_69_2</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>5919.651036</td>\n",
       "      <td>3582.857143</td>\n",
       "      <td>944.340240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>637</td>\n",
       "      <td>TS_69_2</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>5926.583541</td>\n",
       "      <td>971.421446</td>\n",
       "      <td>923.890274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>638</td>\n",
       "      <td>TS_69_2</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>5052.868720</td>\n",
       "      <td>1711.799028</td>\n",
       "      <td>958.703404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index experiment        particle_type            x            y  \\\n",
       "0        0     TS_6_4         apo-ferritin  3139.936425  3139.959793   \n",
       "1        1     TS_6_4         apo-ferritin  4546.956522  2133.913043   \n",
       "2        2     TS_6_4         apo-ferritin  4655.000000  1960.000000   \n",
       "3        3     TS_6_4         apo-ferritin  4029.863014  2881.917808   \n",
       "4        4     TS_6_4         apo-ferritin  3890.000000  2450.000000   \n",
       "..     ...        ...                  ...          ...          ...   \n",
       "634    634    TS_69_2  virus-like-particle  3590.344828  2368.857759   \n",
       "635    635    TS_69_2  virus-like-particle  5119.028476  5666.733668   \n",
       "636    636    TS_69_2  virus-like-particle  5919.651036  3582.857143   \n",
       "637    637    TS_69_2  virus-like-particle  5926.583541   971.421446   \n",
       "638    638    TS_69_2  virus-like-particle  5052.868720  1711.799028   \n",
       "\n",
       "              z  \n",
       "0    910.076514  \n",
       "1    214.782609  \n",
       "2    240.000000  \n",
       "3    276.164384  \n",
       "4    260.000000  \n",
       "..          ...  \n",
       "634  911.077586  \n",
       "635  890.653266  \n",
       "636  944.340240  \n",
       "637  923.890274  \n",
       "638  958.703404  \n",
       "\n",
       "[639 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
