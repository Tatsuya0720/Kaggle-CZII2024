{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import timm\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# import torchvision.transforms.functional as F\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import Unet3D\n",
    "from src.utils import save_images, PadToSize\n",
    "from src.metric import (\n",
    "    score,\n",
    "    create_cls_pos,\n",
    "    create_cls_pos_sikii,\n",
    "    create_df,\n",
    "    SegmentationLoss,\n",
    "    DiceLoss,\n",
    ")\n",
    "from metric import visualize_epoch_results\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "from src.inference import inference, inference2pos\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padf = PadToSize(CFG.resolution)\n",
    "\n",
    "\n",
    "# def last_padding(tomogram, slice_size):\n",
    "#     # tomogram: (tensor)\n",
    "#     b, d, h, w = tomogram.shape\n",
    "#     last_padding = slice_size - d % slice_size\n",
    "#     if last_padding == slice_size:\n",
    "#         return tomogram\n",
    "#     else:\n",
    "#         return torch.cat(\n",
    "#             [tomogram, torch.zeros(b, last_padding, h, w).to(tomogram.device)], dim=1\n",
    "#         )\n",
    "\n",
    "\n",
    "# def preprocess_tensor(tensor):\n",
    "#     batch_size, depth, height, width = tensor.shape\n",
    "#     tensor = tensor.unsqueeze(2)  # (b, d, h, w) -> (b, d, 1, h, w)\n",
    "#     return tensor\n",
    "\n",
    "\n",
    "# def inference(model, exp_name, train=True):\n",
    "#     dataset = EziiDataset(\n",
    "#         exp_names=[exp_name],\n",
    "#         base_dir=\"../../inputs/train/\",\n",
    "#         particles_name=CFG.particles_name,\n",
    "#         resolution=CFG.resolution,\n",
    "#         zarr_type=[\"denoised\"],\n",
    "#         train=train,\n",
    "#         slice=False,\n",
    "#     )\n",
    "#     res_array = CFG.original_img_shape[CFG.resolution]\n",
    "#     pred_array = np.zeros(\n",
    "#         (len(CFG.particles_name) + 1, res_array[0], res_array[1], res_array[2])\n",
    "#     )\n",
    "#     loader = DataLoader(dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "#     model.eval()\n",
    "#     # tq = tqdm(loader)\n",
    "#     for data in loader:  # 実験データ1つを取り出す\n",
    "#         for i in range(0, data[\"normalized_tomogram\"].shape[1], CFG.slice_):\n",
    "#             normalized_tomogram = data[\"normalized_tomogram\"][:, i : i + CFG.slice_]\n",
    "#             normalized_tomogram = last_padding(normalized_tomogram, CFG.slice_)\n",
    "#             normalized_tomogram = padf(normalized_tomogram)\n",
    "#             normalized_tomogram = preprocess_tensor(normalized_tomogram).to(\"cuda\")\n",
    "#             pred = model(normalized_tomogram)\n",
    "#             prob_pred = (\n",
    "#                 torch.softmax(pred, dim=1).detach().cpu().numpy()\n",
    "#             )  # torch.Size([1, 7, 32, 320, 320])\n",
    "#             range_ = min(i + CFG.slice_, res_array[0])\n",
    "#             hw_pad_diff = prob_pred.shape[-1] - res_array[-1]\n",
    "\n",
    "#             if i >= res_array[0]:\n",
    "#                 continue\n",
    "\n",
    "#             if range_ == res_array[0]:\n",
    "#                 pred_array[:, i:range_] += prob_pred[\n",
    "#                     0, :, : res_array[0] - i, :-hw_pad_diff, :-hw_pad_diff\n",
    "#                 ]\n",
    "#             else:\n",
    "#                 pred_array[:, i:range_] += prob_pred[\n",
    "#                     0, :, :range_, :-hw_pad_diff, :-hw_pad_diff\n",
    "#                 ]\n",
    "\n",
    "#         if train:\n",
    "#             segmentation_map = data[\"segmentation_map\"]\n",
    "#         else:\n",
    "#             segmentation_map = None\n",
    "\n",
    "#         normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "#     # tq.close()\n",
    "\n",
    "#     return pred_array, normalized_tomogram, segmentation_map  # (7, 92, 315, 315)\n",
    "\n",
    "\n",
    "# def inference2pos(pred_segmask, exp_name):\n",
    "#     import cc3d\n",
    "\n",
    "#     cls_pos = []\n",
    "#     Ascale_pos = []\n",
    "#     res2ratio = CFG.resolution2ratio\n",
    "\n",
    "#     for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#         print(pred_cls, CFG.cls2particles[pred_cls])\n",
    "#         cc, P = cc3d.connected_components(pred_segmask == pred_cls, return_N=True)\n",
    "#         stats = cc3d.statistics(cc)\n",
    "\n",
    "#         for z, y, x in stats[\"centroids\"]:\n",
    "#             Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#             cls_pos.append([pred_cls, z, y, x])\n",
    "#             Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "#     pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "\n",
    "#     return pred_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = EziiDataset(\n",
    "#     exp_names=CFG.train_exp_names,\n",
    "#     base_dir=\"../../inputs/train/\",\n",
    "#     particles_name=CFG.particles_name,\n",
    "#     resolution=CFG.resolution,\n",
    "#     zarr_type=CFG.train_zarr_types,\n",
    "#     train=True,\n",
    "#     augmentation=False,\n",
    "#     slice=False,\n",
    "#     pre_read=True,\n",
    "# )\n",
    "\n",
    "# # train_nshuffle_dataset = EziiDataset(\n",
    "# #     exp_names=CFG.train_exp_names,\n",
    "# #     base_dir=\"../../inputs/train/\",\n",
    "# #     particles_name=CFG.particles_name,\n",
    "# #     resolution=CFG.resolution,\n",
    "# #     zarr_type=CFG.train_zarr_types,\n",
    "# #     augmentation=False,\n",
    "# #     train=True,\n",
    "# # )\n",
    "\n",
    "# valid_dataset = EziiDataset(\n",
    "#     exp_names=CFG.valid_exp_names,\n",
    "#     base_dir=\"../../inputs/train/\",\n",
    "#     particles_name=CFG.particles_name,\n",
    "#     resolution=CFG.resolution,\n",
    "#     zarr_type=CFG.valid_zarr_types,\n",
    "#     augmentation=False,\n",
    "#     train=True,\n",
    "#     slice=False,\n",
    "#     pre_read=True,\n",
    "# )\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=CFG.batch_size,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=CFG.num_workers,\n",
    "# )\n",
    "# # train_nshuffle_loader = DataLoader(\n",
    "# #     train_nshuffle_dataset,\n",
    "# #     batch_size=1,\n",
    "# #     shuffle=True,\n",
    "# #     drop_last=True,\n",
    "# #     pin_memory=True,\n",
    "# #     num_workers=CFG.num_workers,\n",
    "# # )\n",
    "# valid_loader = DataLoader(\n",
    "#     valid_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=CFG.num_workers,\n",
    "# )\n",
    "\n",
    "# for data in tqdm(train_loader):\n",
    "#     normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "#     segmentation_map = data[\"segmentation_map\"]\n",
    "#     break\n",
    "\n",
    "# normalized_tomogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in tqdm(train_loader):\n",
    "#     exp_names = data[\"exp_name\"]\n",
    "#     normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "#     segmentation_map = data[\"segmentation_map\"]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_names, normalized_tomogram.shape, segmentation_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cc3d\n",
    "\n",
    "# all_pred = []\n",
    "\n",
    "# for data in tqdm(train_dataset):\n",
    "#     exp_name = data[\"exp_name\"]\n",
    "#     normalized_tomogram = data[\"normalized_tomogram\"]\n",
    "#     segmentation_map = data[\"segmentation_map\"]\n",
    "#     # print(segmentation_map.shape)\n",
    "#     gt = segmentation_map  # .numpy()\n",
    "\n",
    "#     cls_pos = []\n",
    "#     Ascale_pos = []\n",
    "#     res2ratio = CFG.resolution2ratio\n",
    "#     # exp_name = exp_names[i]\n",
    "\n",
    "#     for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#         cc, P = cc3d.connected_components(gt == pred_cls, return_N=True)\n",
    "#         stats = cc3d.statistics(cc)\n",
    "\n",
    "#         for z, y, x in stats[\"centroids\"][1:]:\n",
    "#             Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#             cls_pos.append([pred_cls, z, y, x])\n",
    "#             Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "#     pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "#     all_pred.append(pred_original_df)\n",
    "\n",
    "# all_pred = pd.concat(all_pred).reset_index().drop_duplicates(subset=[\"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>experiment</th>\n",
       "      <th>particle_type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>3045.036742</td>\n",
       "      <td>919.139280</td>\n",
       "      <td>421.270403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2969.078552</td>\n",
       "      <td>1027.114255</td>\n",
       "      <td>440.085721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2839.792769</td>\n",
       "      <td>1069.080767</td>\n",
       "      <td>425.839468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2875.180486</td>\n",
       "      <td>1077.907940</td>\n",
       "      <td>298.254286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2765.950544</td>\n",
       "      <td>1019.336833</td>\n",
       "      <td>322.072039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14400</th>\n",
       "      <td>14400</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2609.876000</td>\n",
       "      <td>4569.876000</td>\n",
       "      <td>1169.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14401</th>\n",
       "      <td>14401</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2213.287000</td>\n",
       "      <td>4135.017000</td>\n",
       "      <td>1286.851000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14402</th>\n",
       "      <td>14402</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>3303.905000</td>\n",
       "      <td>5697.825000</td>\n",
       "      <td>789.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14403</th>\n",
       "      <td>14403</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>1008.748000</td>\n",
       "      <td>5949.213000</td>\n",
       "      <td>1077.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14404</th>\n",
       "      <td>14404</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>5749.052000</td>\n",
       "      <td>3911.392000</td>\n",
       "      <td>275.342000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14405 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index experiment        particle_type            x            y  \\\n",
       "0          0       TS_4         apo-ferritin  3045.036742   919.139280   \n",
       "1          1       TS_4         apo-ferritin  2969.078552  1027.114255   \n",
       "2          2       TS_4         apo-ferritin  2839.792769  1069.080767   \n",
       "3          3       TS_4         apo-ferritin  2875.180486  1077.907940   \n",
       "4          4       TS_4         apo-ferritin  2765.950544  1019.336833   \n",
       "...      ...        ...                  ...          ...          ...   \n",
       "14400  14400     TS_6_6  virus-like-particle  2609.876000  4569.876000   \n",
       "14401  14401     TS_6_6  virus-like-particle  2213.287000  4135.017000   \n",
       "14402  14402     TS_6_6  virus-like-particle  3303.905000  5697.825000   \n",
       "14403  14403     TS_6_6  virus-like-particle  1008.748000  5949.213000   \n",
       "14404  14404     TS_6_6  virus-like-particle  5749.052000  3911.392000   \n",
       "\n",
       "                 z  \n",
       "0       421.270403  \n",
       "1       440.085721  \n",
       "2       425.839468  \n",
       "3       298.254286  \n",
       "4       322.072039  \n",
       "...            ...  \n",
       "14400  1169.759000  \n",
       "14401  1286.851000  \n",
       "14402   789.744000  \n",
       "14403  1077.303000  \n",
       "14404   275.342000  \n",
       "\n",
       "[14405 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.train_exp_names)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score(all_pred, gt_df, row_id_column_name=\"index\", distance_multiplier=0.5, beta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# # ############### validation ################\n",
    "# train_nshuffle_original_tomogram = defaultdict(list)\n",
    "# train_nshuffle_pred_tomogram = defaultdict(list)\n",
    "# train_nshuffle_gt_tomogram = defaultdict(list)\n",
    "# train_cls_pos = defaultdict(list)\n",
    "# train_cls_Apos = defaultdict(list)\n",
    "\n",
    "# valid_original_tomogram = defaultdict(list)\n",
    "# valid_pred_tomogram = defaultdict(list)\n",
    "# valid_gt_tomogram = defaultdict(list)\n",
    "# valid_cls_pos = defaultdict(list)\n",
    "# valid_cls_Apos = defaultdict(list)\n",
    "\n",
    "# train_mean_scores = []\n",
    "# valid_mean_scores = []\n",
    "\n",
    "# # # for exp_name in tqdm(CFG.train_exp_names):\n",
    "# # for exp_name in tqdm(CFG.train_exp_names[:5]):  # 5つのデータで試す\n",
    "# #     inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "# #         model, exp_name, train=True\n",
    "# #     )\n",
    "# #     train_nshuffle_pred_tomogram[exp_name] = inferenced_array\n",
    "# #     train_nshuffle_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "# #     train_nshuffle_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "# #     mean_score, scores, pred_df, gt_df, pred_cls_pos, pred_Ascale_pos = (\n",
    "# #         visualize_epoch_results(\n",
    "# #             train_nshuffle_pred_tomogram,\n",
    "# #             base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "# #             sikii_dict=CFG.initial_sikii,\n",
    "# #         )\n",
    "# #     )\n",
    "# #     train_cls_pos[exp_name] = pred_cls_pos\n",
    "# #     train_cls_Apos[exp_name] = pred_Ascale_pos\n",
    "# #     train_mean_scores.append(mean_score)\n",
    "# # print(\"train_mean_scores\", np.mean(train_mean_scores))\n",
    "\n",
    "# for exp_name in tqdm(CFG.valid_exp_names):\n",
    "#     inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "#         model, exp_name, train=True\n",
    "#     )\n",
    "#     valid_pred_tomogram[exp_name] = inferenced_array\n",
    "#     valid_gt_tomogram[exp_name] = segmentation_map.squeeze(0)\n",
    "#     valid_original_tomogram[exp_name] = n_tomogram.squeeze(0)\n",
    "\n",
    "#     mean_score, scores, pred_df, gt_df, pred_cls_pos, pred_Ascale_pos = (\n",
    "#         visualize_epoch_results(\n",
    "#             valid_pred_tomogram,\n",
    "#             base_dir=\"../../inputs/train/overlay/ExperimentRuns/\",\n",
    "#             sikii_dict=CFG.initial_sikii,\n",
    "#         )\n",
    "#     )\n",
    "#     valid_cls_pos[exp_name] = pred_cls_pos\n",
    "#     valid_cls_Apos[exp_name] = pred_Ascale_pos\n",
    "#     valid_mean_scores.append(mean_score)\n",
    "# print(\"valid_mean_scores\", np.mean(valid_mean_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferenced_array, n_tomogram, segmentation_map = inference(model, exp_name, train=True)\n",
    "# pred_original_df = inference2pos(\n",
    "#     pred_segmask=inferenced_array,\n",
    "#     exp_name=exp_name,\n",
    "#     sikii_dict=CFG.initial_sikii,\n",
    "# )\n",
    "# pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference2pos(pred_segmask, exp_name, sikii_dict):\n",
    "    import cc3d\n",
    "\n",
    "    cls_pos = []\n",
    "    Ascale_pos = []\n",
    "    res2ratio = CFG.resolution2ratio\n",
    "\n",
    "    for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "        sikii = sikii_dict[CFG.cls2particles[pred_cls]]\n",
    "        # print(pred_segmask[pred_cls].shape)\n",
    "        cc, P = cc3d.connected_components(pred_segmask[pred_cls] > sikii, return_N=True)\n",
    "        # cc, P = cc3d.connected_components(pred_segmask == pred_cls, return_N=True)\n",
    "        stats = cc3d.statistics(cc)\n",
    "\n",
    "        for z, y, x in stats[\"centroids\"][1:]:\n",
    "            Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "            Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "            cls_pos.append([pred_cls, z, y, x])\n",
    "            Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "    pred_original_df = create_df(Ascale_pos, exp_name)\n",
    "\n",
    "    return pred_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score(pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df[pred_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_df[gt_df[\"particle_type\"] == \"apo-ferritin\"].sort_values(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "num_classes = len(CFG.particles_name)  # クラス数\n",
    "colors = plt.cm.tab10(\n",
    "    np.arange(len(CFG.particles_name))\n",
    ")  # \"tab10\" カラーマップから色を取得\n",
    "\n",
    "# ListedColormap を作成\n",
    "class_colormap = ListedColormap(colors)\n",
    "\n",
    "\n",
    "def plot_with_colormap(data, title, original_tomogram):\n",
    "    masked_data = np.ma.masked_where(data <= 0, data)  # クラス0をマスク\n",
    "    plt.imshow(original_tomogram, cmap=\"gray\")\n",
    "    im = plt.imshow(masked_data, cmap=class_colormap)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    return im\n",
    "\n",
    "\n",
    "def imshow_result(pred, gt, original, index):\n",
    "    # plt.figure(figsize=(20, 5))\n",
    "    ax = plt.subplot(1, 3, 1)\n",
    "    plot_with_colormap(\n",
    "        pred[index],\n",
    "        \"Train-Prediction\",\n",
    "        original[index],\n",
    "    )\n",
    "    ax = plt.subplot(1, 3, 2)\n",
    "    plot_with_colormap(gt[index], \"Gt\", original[index])\n",
    "\n",
    "    ax = plt.subplot(1, 3, 3)\n",
    "    plt.imshow(original[index], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = \"TS_5_4\"\n",
    "# index = 12\n",
    "# pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "# gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "# original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# # imshow_result(pred, gt, original, index)\n",
    "\n",
    "# for i in range(42):\n",
    "#     imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = \"TS_5_4\"\n",
    "# index = 12\n",
    "# pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)  # (92, 315, 315)\n",
    "# gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "# original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# # imshow_result(pred, gt, original, index)\n",
    "\n",
    "# for i in range(42):\n",
    "#     imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = CFG.valid_exp_names[-1]\n",
    "\n",
    "# pred = valid_pred_tomogram[exp_name].argmax(0)\n",
    "# gt = valid_gt_tomogram[exp_name]\n",
    "# original = valid_original_tomogram[exp_name]\n",
    "\n",
    "# for i in range(42):\n",
    "#     imshow_result(pred, gt, original, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = CFG.train_exp_names[-1]\n",
    "\n",
    "# pred_cls_pos = train_cls_pos[exp_name]\n",
    "\n",
    "# exp_name, np.array(pred_cls_pos).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = CFG.valid_exp_names[0]\n",
    "\n",
    "# pred_cls_pos = valid_cls_pos[exp_name]\n",
    "\n",
    "# np.array(pred_cls_pos).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>experiment</th>\n",
       "      <th>particle_type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>3045.036742</td>\n",
       "      <td>919.139280</td>\n",
       "      <td>421.270403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2969.078552</td>\n",
       "      <td>1027.114255</td>\n",
       "      <td>440.085721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2839.792769</td>\n",
       "      <td>1069.080767</td>\n",
       "      <td>425.839468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2875.180486</td>\n",
       "      <td>1077.907940</td>\n",
       "      <td>298.254286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2765.950544</td>\n",
       "      <td>1019.336833</td>\n",
       "      <td>322.072039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14400</th>\n",
       "      <td>14400</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2609.876000</td>\n",
       "      <td>4569.876000</td>\n",
       "      <td>1169.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14401</th>\n",
       "      <td>14401</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2213.287000</td>\n",
       "      <td>4135.017000</td>\n",
       "      <td>1286.851000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14402</th>\n",
       "      <td>14402</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>3303.905000</td>\n",
       "      <td>5697.825000</td>\n",
       "      <td>789.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14403</th>\n",
       "      <td>14403</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>1008.748000</td>\n",
       "      <td>5949.213000</td>\n",
       "      <td>1077.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14404</th>\n",
       "      <td>14404</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>5749.052000</td>\n",
       "      <td>3911.392000</td>\n",
       "      <td>275.342000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14405 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index experiment        particle_type            x            y  \\\n",
       "0          0       TS_4         apo-ferritin  3045.036742   919.139280   \n",
       "1          1       TS_4         apo-ferritin  2969.078552  1027.114255   \n",
       "2          2       TS_4         apo-ferritin  2839.792769  1069.080767   \n",
       "3          3       TS_4         apo-ferritin  2875.180486  1077.907940   \n",
       "4          4       TS_4         apo-ferritin  2765.950544  1019.336833   \n",
       "...      ...        ...                  ...          ...          ...   \n",
       "14400  14400     TS_6_6  virus-like-particle  2609.876000  4569.876000   \n",
       "14401  14401     TS_6_6  virus-like-particle  2213.287000  4135.017000   \n",
       "14402  14402     TS_6_6  virus-like-particle  3303.905000  5697.825000   \n",
       "14403  14403     TS_6_6  virus-like-particle  1008.748000  5949.213000   \n",
       "14404  14404     TS_6_6  virus-like-particle  5749.052000  3911.392000   \n",
       "\n",
       "                 z  \n",
       "0       421.270403  \n",
       "1       440.085721  \n",
       "2       425.839468  \n",
       "3       298.254286  \n",
       "4       322.072039  \n",
       "...            ...  \n",
       "14400  1169.759000  \n",
       "14401  1286.851000  \n",
       "14402   789.744000  \n",
       "14403  1077.303000  \n",
       "14404   275.342000  \n",
       "\n",
       "[14405 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # exp_name = CFG.valid_exp_names[0]\n",
    "# # pred = valid_pred_tomogram[exp_name].argmax(0)\n",
    "# # gt = valid_gt_tomogram[exp_name]\n",
    "# # original = valid_original_tomogram[exp_name]\n",
    "# import timm\n",
    "\n",
    "# encoder = timm.create_model(\n",
    "#     model_name=CFG.model_name,\n",
    "#     pretrained=True,\n",
    "#     in_chans=3,\n",
    "#     num_classes=0,\n",
    "#     global_pool=\"\",\n",
    "#     features_only=True,\n",
    "# )\n",
    "# model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "# model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "# exp_name = CFG.train_exp_names[2]\n",
    "# pred = train_nshuffle_pred_tomogram[exp_name].argmax(0)\n",
    "# gt = train_nshuffle_gt_tomogram[exp_name]\n",
    "# original = train_nshuffle_original_tomogram[exp_name]\n",
    "\n",
    "# base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "# gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "# import cc3d\n",
    "\n",
    "# cls_pos = []\n",
    "# Ascale_pos = []\n",
    "# res2ratio = CFG.resolution2ratio\n",
    "\n",
    "# for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#     print(pred_cls, CFG.cls2particles[pred_cls])\n",
    "#     cc, P = cc3d.connected_components(pred == pred_cls, return_N=True)\n",
    "#     stats = cc3d.statistics(cc)\n",
    "\n",
    "#     for z, y, x in stats[\"centroids\"]:\n",
    "#         Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#         Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#         Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#         cls_pos.append([pred_cls, z, y, x])\n",
    "#         Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "# pred_original_df = create_df(Ascale_pos, exp_name).drop_duplicates(\n",
    "#     subset=[\"x\", \"y\", \"z\"]\n",
    "# )\n",
    "\n",
    "# score(\n",
    "#     pred_original_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1.0, beta=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "\n",
    "# encoder = timm.create_model(\n",
    "#     model_name=CFG.model_name,\n",
    "#     pretrained=True,\n",
    "#     in_chans=3,\n",
    "#     num_classes=0,\n",
    "#     global_pool=\"\",\n",
    "#     features_only=True,\n",
    "# )\n",
    "# model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "# model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "# exp_name = CFG.valid_exp_names[-1]\n",
    "# pred = valid_pred_tomogram[exp_name]\n",
    "# gt = valid_gt_tomogram[exp_name]\n",
    "# original = valid_original_tomogram[exp_name]\n",
    "\n",
    "# base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "# gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "\n",
    "# for constant in np.linspace(0.2, 0.9, 20):\n",
    "#     initial_sikii = {\n",
    "#         \"apo-ferritin\": constant,\n",
    "#         \"beta-amylase\": constant,\n",
    "#         \"beta-galactosidase\": constant,\n",
    "#         \"ribosome\": constant,\n",
    "#         \"thyroglobulin\": constant,\n",
    "#         \"virus-like-particle\": constant,\n",
    "#     }\n",
    "\n",
    "#     import cc3d\n",
    "\n",
    "#     cls_pos = []\n",
    "#     Ascale_pos = []\n",
    "#     res2ratio = CFG.resolution2ratio\n",
    "\n",
    "#     for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#         sikii = initial_sikii[CFG.cls2particles[pred_cls]]\n",
    "#         cc, P = cc3d.connected_components(pred[pred_cls] > sikii, return_N=True)\n",
    "#         stats = cc3d.statistics(cc)\n",
    "\n",
    "#         for z, y, x in stats[\"centroids\"]:\n",
    "#             Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#             cls_pos.append([pred_cls, z, y, x])\n",
    "#             Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "#     pred_original_df = create_df(Ascale_pos, exp_name).drop_duplicates(\n",
    "#         subset=[\"x\", \"y\", \"z\"]\n",
    "#     )\n",
    "\n",
    "#     score_ = score(\n",
    "#         pred_original_df,\n",
    "#         gt_df,\n",
    "#         row_id_column_name=\"index\",\n",
    "#         distance_multiplier=1.0,\n",
    "#         beta=4,\n",
    "#     )\n",
    "\n",
    "#     print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "\n",
    "# encoder = timm.create_model(\n",
    "#     model_name=CFG.model_name,\n",
    "#     pretrained=True,\n",
    "#     in_chans=3,\n",
    "#     num_classes=0,\n",
    "#     global_pool=\"\",\n",
    "#     features_only=True,\n",
    "# )\n",
    "# model = Unet3D(encoder=encoder).to(\"cuda\")\n",
    "# model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "# exp_name = CFG.valid_exp_names[0]\n",
    "# pred = valid_pred_tomogram[exp_name]\n",
    "# gt = valid_gt_tomogram[exp_name]\n",
    "# original = valid_original_tomogram[exp_name]\n",
    "\n",
    "# base_dir = \"../../inputs/train/overlay/ExperimentRuns/\"\n",
    "# gt_df = create_gt_df(base_dir=base_dir, exp_names=[exp_name])\n",
    "\n",
    "\n",
    "# for constant in np.linspace(0.2, 0.9, 20):\n",
    "#     initial_sikii = {\n",
    "#         \"apo-ferritin\": constant,\n",
    "#         \"beta-amylase\": constant,\n",
    "#         \"beta-galactosidase\": constant,\n",
    "#         \"ribosome\": constant,\n",
    "#         \"thyroglobulin\": constant,\n",
    "#         \"virus-like-particle\": constant,\n",
    "#     }\n",
    "\n",
    "#     import cc3d\n",
    "\n",
    "#     cls_pos = []\n",
    "#     Ascale_pos = []\n",
    "#     res2ratio = CFG.resolution2ratio\n",
    "\n",
    "#     for pred_cls in range(1, len(CFG.particles_name) + 1):\n",
    "#         sikii = initial_sikii[CFG.cls2particles[pred_cls]]\n",
    "#         cc, P = cc3d.connected_components(pred[pred_cls] > sikii, return_N=True)\n",
    "#         stats = cc3d.statistics(cc)\n",
    "\n",
    "#         for z, y, x in stats[\"centroids\"]:\n",
    "#             Ascale_z = z * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_x = x * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "#             Ascale_y = y * res2ratio[CFG.resolution] / res2ratio[\"A\"]\n",
    "\n",
    "#             cls_pos.append([pred_cls, z, y, x])\n",
    "#             Ascale_pos.append([pred_cls, Ascale_z, Ascale_y, Ascale_x])\n",
    "\n",
    "#     pred_original_df = create_df(Ascale_pos, exp_name).drop_duplicates(\n",
    "#         subset=[\"x\", \"y\", \"z\"]\n",
    "#     )\n",
    "\n",
    "#     score_ = score(\n",
    "#         pred_original_df,\n",
    "#         gt_df,\n",
    "#         row_id_column_name=\"index\",\n",
    "#         distance_multiplier=1.0,\n",
    "#         beta=4,\n",
    "#     )\n",
    "\n",
    "#     print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TS_86_3'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = CFG.valid_exp_names[1]\n",
    "# exp_name = CFG.train_exp_names[0]\n",
    "exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "model = Unet3D(encoder=encoder, num_domains=5).to(\"cuda\")\n",
    "# model.load_state_dict(torch.load(\"./pretrained_model.pth\"))\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "# inferenced_array = inference(model, exp_name, train=False)\n",
    "# 0.7303962244998289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.5439822059121053\n",
      "0.2368421052631579 0.56942568651182\n",
      "0.2736842105263158 0.5771054625292799\n",
      "0.31052631578947365 0.6033438216593364\n",
      "0.34736842105263155 0.5984356478229041\n",
      "0.38421052631578945 0.608549748025765\n",
      "0.42105263157894735 0.6740271693490227\n",
      "0.45789473684210524 0.6920711393692851\n",
      "0.49473684210526314 0.7326705431762172\n",
      "0.531578947368421 0.7569495638242325\n",
      "0.5684210526315789 0.7456705228303695\n",
      "0.6052631578947368 0.7362428218187984\n",
      "0.6421052631578947 0.7274560890957555\n",
      "0.6789473684210525 0.7095801959014353\n",
      "0.7157894736842105 0.7491593681163969\n",
      "0.7526315789473683 0.7273795977095846\n",
      "0.7894736842105263 0.7484340878878675\n",
      "0.8263157894736841 0.5604614897122662\n",
      "0.8631578947368421 0.5694608503456614\n",
      "0.9 0.4920017160175263\n"
     ]
    }
   ],
   "source": [
    "inferenced_array, n_tomogram, segmentation_map = inference(model, exp_name, train=False)\n",
    "\n",
    "for constant in np.linspace(0.2, 0.9, 20):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": constant,\n",
    "        \"beta-amylase\": constant,\n",
    "        \"beta-galactosidase\": constant,\n",
    "        \"ribosome\": constant,\n",
    "        \"thyroglobulin\": constant,\n",
    "        \"virus-like-particle\": constant,\n",
    "    }\n",
    "\n",
    "    pred_original_df = inference2pos(\n",
    "        pred_segmask=inferenced_array,\n",
    "        exp_name=exp_name,\n",
    "        sikii_dict=initial_sikii,\n",
    "    )\n",
    "    gt_df = create_gt_df(\n",
    "        base_dir=\"../../inputs/train/overlay/ExperimentRuns/\", exp_names=[exp_name]\n",
    "    )\n",
    "\n",
    "    s = score(\n",
    "        pred_original_df,\n",
    "        gt_df,\n",
    "        row_id_column_name=\"index\",\n",
    "        distance_multiplier=1.0,\n",
    "        beta=4,\n",
    "    )\n",
    "    print(constant, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0.2 0.577301975832386\n",
    "0.2368421052631579 0.5960608219347279\n",
    "0.2736842105263158 0.5890730623695157\n",
    "0.31052631578947365 0.6194835887149536\n",
    "0.34736842105263155 0.6269012204690084\n",
    "0.38421052631578945 0.6388460262490633\n",
    "0.42105263157894735 0.6540888823901926\n",
    "0.45789473684210524 0.6547000465241928\n",
    "0.49473684210526314 0.6909810176438802\n",
    "0.531578947368421 0.7154658784783322\n",
    "0.5684210526315789 0.7073897586202395\n",
    "0.6052631578947368 0.6913788825703978\n",
    "0.6421052631578947 0.6940959897200774\n",
    "0.6789473684210525 0.7275935266658902\n",
    "0.7157894736842105 0.7432382969379473\n",
    "0.7526315789473683 0.7539132667175555\n",
    "0.7894736842105263 0.7647795362277954\n",
    "0.8263157894736841 0.6789610776305818\n",
    "0.8631578947368421 0.6107513709024934\n",
    "0.9 0.45345976993168013\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion\n",
    "import matplotlib.pyplot as pp\n",
    "\n",
    "\n",
    "def detect_peaks(image, cls_index):\n",
    "    \"\"\"\n",
    "    Takes an image and detect the peaks usingthe local maximum filter.\n",
    "    Returns a boolean mask of the peaks (i.e. 1 when\n",
    "    the pixel's value is the neighborhood maximum, 0 otherwise)\n",
    "    \"\"\"\n",
    "\n",
    "    # define an 8-connected neighborhood\n",
    "    neighborhood = generate_binary_structure(2, 2)\n",
    "\n",
    "    # apply the local maximum filter; all pixel of maximal value\n",
    "    # in their neighborhood are set to 1\n",
    "    local_max = maximum_filter(image, footprint=neighborhood) == image\n",
    "    # local_max is a mask that contains the peaks we are\n",
    "    # looking for, but also the background.\n",
    "    # In order to isolate the peaks we must remove the background from the mask.\n",
    "\n",
    "    # we create the mask of the background\n",
    "    background = image == 0\n",
    "\n",
    "    # a little technicality: we must erode the background in order to\n",
    "    # successfully subtract it form local_max, otherwise a line will\n",
    "    # appear along the background border (artifact of the local maximum filter)\n",
    "    eroded_background = binary_erosion(\n",
    "        background, structure=neighborhood, border_value=cls_index\n",
    "    )\n",
    "\n",
    "    # we obtain the final mask, containing only peaks,\n",
    "    # by removing the background from the local_max mask (xor operation)\n",
    "    detected_peaks = local_max ^ eroded_background\n",
    "\n",
    "    return detected_peaks\n",
    "\n",
    "\n",
    "# test\n",
    "x = np.linspace(0, 4 * np.pi, 100)\n",
    "y = np.sin(x).reshape(-1, 10)\n",
    "# peaks = detect_peaks(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import (\n",
    "    binary_dilation,\n",
    "    binary_erosion,\n",
    "    binary_opening,\n",
    "    binary_closing,\n",
    ")\n",
    "\n",
    "\n",
    "def apply_morphology(\n",
    "    segmentation: np.ndarray, class_range: tuple[int, int]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    セマンティックセグメンテーション結果にモルフォロジー処理を適用して鮮鋭化します。\n",
    "\n",
    "    Args:\n",
    "        segmentation (np.ndarray): セグメンテーション結果 (2Dまたは3D配列)。\n",
    "        class_range (tuple[int, int]): モルフォロジー処理対象のクラス範囲 (min_class, max_class)。\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: モルフォロジー処理後のセグメンテーション結果。\n",
    "    \"\"\"\n",
    "    # 背景クラス (0) は処理対象外\n",
    "    processed_segmentation = np.zeros_like(segmentation)\n",
    "    for cls in range(class_range[0], class_range[1] + 1):\n",
    "        # 特定のクラスのバイナリマスクを作成\n",
    "        binary_mask = segmentation == cls\n",
    "\n",
    "        # モルフォロジー処理 (例: 開操作)\n",
    "        refined_mask = binary_opening(\n",
    "            binary_mask, structure=np.ones((3, 3))\n",
    "        )  # 3x3の構造要素を使用\n",
    "        refined_mask = binary_closing(\n",
    "            refined_mask, structure=np.ones((3, 3))\n",
    "        )  # 閉操作でギャップを埋める\n",
    "\n",
    "        # 処理後のマスクを反映\n",
    "        processed_segmentation[refined_mask] = cls\n",
    "\n",
    "    return processed_segmentation\n",
    "\n",
    "\n",
    "# 使用例\n",
    "# セグメンテーション結果 (例)\n",
    "segmentation_result = np.random.randint(\n",
    "    0, 8, size=(100, 100)\n",
    ")  # ランダムなセグメンテーション結果\n",
    "\n",
    "# クラス1~7を鮮鋭化\n",
    "processed_result = apply_morphology(segmentation_result, class_range=(1, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import binary_opening, binary_closing, label\n",
    "\n",
    "\n",
    "def refine_segmentation(\n",
    "    segmentation: np.ndarray, class_range: tuple[int, int], min_size: int = 10\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    小さなクラス同士を分離したまま、セマンティックセグメンテーション結果を鮮鋭化します。\n",
    "\n",
    "    Args:\n",
    "        segmentation (np.ndarray): セグメンテーション結果 (2Dまたは3D配列)。\n",
    "        class_range (tuple[int, int]): 処理対象のクラス範囲 (min_class, max_class)。\n",
    "        min_size (int): 小さい領域を除去する際の最小ピクセルサイズ。\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 鮮鋭化されたセグメンテーション結果。\n",
    "    \"\"\"\n",
    "    processed_segmentation = np.zeros_like(segmentation)\n",
    "\n",
    "    for cls in range(class_range[0], class_range[1] + 1):\n",
    "        # 特定クラスのバイナリマスクを作成\n",
    "        binary_mask = segmentation == cls\n",
    "\n",
    "        # 開操作でノイズ除去、閉操作でギャップを埋める\n",
    "        refined_mask = binary_opening(binary_mask, structure=np.ones((1, 1)))\n",
    "        refined_mask = binary_closing(refined_mask, structure=np.ones((1, 1)))\n",
    "\n",
    "        # ラベリングで分離された領域を管理\n",
    "        labeled_mask, num_features = label(refined_mask)\n",
    "\n",
    "        # 小さい領域をフィルタリング\n",
    "        for region in range(1, num_features + 1):\n",
    "            region_mask = labeled_mask == region\n",
    "            if np.sum(region_mask) >= min_size:  # 最小サイズ以上の領域を保持\n",
    "                processed_segmentation[region_mask] = cls\n",
    "\n",
    "    return processed_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = inferenced_array.argmax(0)\n",
    "zeros_array = np.zeros_like(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(zeros_array.shape[0]):\n",
    "    zeros_array[i] = refine_segmentation(seg[i], class_range=(1, 6), min_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2485bbbf40>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMIAAAJBCAYAAACkgxnsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxcElEQVR4nO3df5TVdZ348deMw4z88N4RlBkmgehk4SSYgQ03bdfNWUmp1ZVa9ZBRy8kjO1iKmbJrmNaKx872w12VrW3Fc9LY3LNkUmKEgZUjKMkGWKTFBqUzY7HMABvDDPP5/tGXW6PsygwXh+H9eJxzz2E+n8+9877vA8zrPGfm3rIsy7IAAAAAgGNc+UAvAAAAAABeC0IYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRjQEHbXXXfF61//+jj++OOjoaEh1q1bN5DLAQCgRMx5AMDRaMBC2L/927/F/Pnz4+abb44f/ehHccYZZ8T06dOjra1toJYEAEAJmPMAgKNVWZZl2UB84oaGhjjrrLPin/7pnyIioqenJ8aOHRtXX3113HjjjQOxJAAASsCcBwAcrSoG4pPu27cv1q9fHwsWLCgeKy8vj8bGxmhubn7F9Z2dndHZ2Vn8uKenJ3bs2BGjRo2KsrKy12TNAMDgl2VZ7Nq1K+rq6qK83EulHgnmPABgIBzqnDcgIew3v/lN7N+/P2pqanodr6mpiZ/+9KevuH7RokVxyy23vFbLAwCOcdu3b49TTjlloJdxTDLnAQAD6dXmvAEJYX21YMGCmD9/fvHj9vb2GDduXJwTF0ZFDBnAlQEAg0l3dMUP4ttxwgknDPRS+P/MeQBAKRzqnDcgIeykk06K4447LlpbW3sdb21tjdra2ldcX1VVFVVVVa84XhFDoqLMgAQAHKL//8qofuXuyDHnAQAD4hDnvAF5cYzKysqYMmVKrFq1qnisp6cnVq1aFYVCYSCWBABACZjzAICj2YD9auT8+fNj9uzZMXXq1Hj7298eX/jCF2LPnj3x4Q9/eKCWBABACZjzAICj1YCFsEsvvTReeumlWLhwYbS0tMRb3/rWWLFixSteWBUAgMHFnAcAHK3KsizLBnoRfdXR0RH5fD7OjYu8dgQAcMi6s65YHQ9Fe3t75HK5gV4OB2HOAwD641DnvAF5jTAAAAAAeK0JYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCT0OYQ9/vjj8d73vjfq6uqirKwsvvGNb/Q6n2VZLFy4MMaMGRNDhw6NxsbGeO6553pds2PHjpg1a1bkcrmorq6OOXPmxO7duw/riQAAcHjMeQDAsa7PIWzPnj1xxhlnxF133XXQ83fccUfceeedsXjx4li7dm0MHz48pk+fHnv37i1eM2vWrNi8eXOsXLkyli9fHo8//nhceeWV/X8WAAAcNnMeAHCsK8uyLOv3ncvKYtmyZXHxxRdHxO+/S1hXVxfXXXddfPzjH4+IiPb29qipqYklS5bEZZddFj/5yU+ivr4+nnrqqZg6dWpERKxYsSIuvPDC+NWvfhV1dXWv+nk7Ojoin8/HuXFRVJQN6e/yAYDEdGddsToeivb29sjlcgO9nKOaOQ8AGEwOdc4r6WuEbd26NVpaWqKxsbF4LJ/PR0NDQzQ3N0dERHNzc1RXVxeHo4iIxsbGKC8vj7Vr1x70cTs7O6Ojo6PXDQCA1445DwA4FpQ0hLW0tERERE1NTa/jNTU1xXMtLS0xevToXucrKipi5MiRxWtebtGiRZHP54u3sWPHlnLZAAC8CnMeAHAsGBTvGrlgwYJob28v3rZv3z7QSwIAoATMeQDAa6mkIay2tjYiIlpbW3sdb21tLZ6rra2Ntra2Xue7u7tjx44dxWterqqqKnK5XK8bAACvHXMeAHAsKGkImzBhQtTW1saqVauKxzo6OmLt2rVRKBQiIqJQKMTOnTtj/fr1xWsee+yx6OnpiYaGhlIuBwCAEjHnAQDHgoq+3mH37t3x/PPPFz/eunVrbNiwIUaOHBnjxo2La665Jj7zmc/EqaeeGhMmTIhPfvKTUVdXV3zHodNOOy3e/e53x0c+8pFYvHhxdHV1xbx58+Kyyy47pHcSAgDgyDDnAQDHuj6HsKeffjr+7M/+rPjx/PnzIyJi9uzZsWTJkvjEJz4Re/bsiSuvvDJ27twZ55xzTqxYsSKOP/744n3uv//+mDdvXpx33nlRXl4eM2fOjDvvvLMETwcAgP4y5wEAx7qyLMuygV5EX3V0dEQ+n49z46KoKBsy0MsBAAaJ7qwrVsdD0d7e7rWojlLmPACgPw51zhsU7xoJAAAAAIdLCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACShTyFs0aJFcdZZZ8UJJ5wQo0ePjosvvji2bNnS65q9e/dGU1NTjBo1KkaMGBEzZ86M1tbWXtds27YtZsyYEcOGDYvRo0fH9ddfH93d3Yf/bAAA6BdzHgCQgj6FsDVr1kRTU1M8+eSTsXLlyujq6orzzz8/9uzZU7zm2muvjYcffjgefPDBWLNmTbzwwgtxySWXFM/v378/ZsyYEfv27Ysnnngi7rvvvliyZEksXLiwdM8KAIA+MecBACkoy7Is6++dX3rppRg9enSsWbMm/uRP/iTa29vj5JNPjgceeCDe9773RUTET3/60zjttNOiubk5pk2bFo888ki85z3viRdeeCFqamoiImLx4sVxww03xEsvvRSVlZWv+nk7Ojoin8/HuXFRVJQN6e/yAYDEdGddsToeivb29sjlcgO9nKOaOQ8AGEwOdc47rNcIa29vj4iIkSNHRkTE+vXro6urKxobG4vXTJw4McaNGxfNzc0REdHc3ByTJk0qDkcREdOnT4+Ojo7YvHnzQT9PZ2dndHR09LoBAHDkmPMAgGNRv0NYT09PXHPNNXH22WfH6aefHhERLS0tUVlZGdXV1b2urampiZaWluI1fzwcHTh/4NzBLFq0KPL5fPE2duzY/i4bAIBXYc4DAI5V/Q5hTU1NsWnTpli6dGkp13NQCxYsiPb29uJt+/btR/xzAgCkypwHAByrKvpzp3nz5sXy5cvj8ccfj1NOOaV4vLa2Nvbt2xc7d+7s9d3C1tbWqK2tLV6zbt26Xo934N2GDlzzclVVVVFVVdWfpQIA0AfmPADgWNannwjLsizmzZsXy5Yti8ceeywmTJjQ6/yUKVNiyJAhsWrVquKxLVu2xLZt26JQKERERKFQiI0bN0ZbW1vxmpUrV0Yul4v6+vrDeS4AAPSTOQ8ASEGffiKsqakpHnjggXjooYfihBNOKL7WQz6fj6FDh0Y+n485c+bE/PnzY+TIkZHL5eLqq6+OQqEQ06ZNi4iI888/P+rr6+OKK66IO+64I1paWuKmm26KpqYm3w0EABgg5jwAIAVlWZZlh3xxWdlBj997773xoQ99KCIi9u7dG9ddd1187Wtfi87Ozpg+fXrcfffdvX4c/pe//GXMnTs3Vq9eHcOHD4/Zs2fH7bffHhUVh9blvK02ANAfh/q22iky5wEAg9mhznl9CmFHCwMSANAfQtjRz5wHAPTHoc55/X7XSAAAAAAYTIQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEvoUwu65556YPHly5HK5yOVyUSgU4pFHHime37t3bzQ1NcWoUaNixIgRMXPmzGhtbe31GNu2bYsZM2bEsGHDYvTo0XH99ddHd3d3aZ4NAAD9Ys4DAFLQpxB2yimnxO233x7r16+Pp59+Ot71rnfFRRddFJs3b46IiGuvvTYefvjhePDBB2PNmjXxwgsvxCWXXFK8//79+2PGjBmxb9++eOKJJ+K+++6LJUuWxMKFC0v7rAAA6BNzHgCQgrIsy7LDeYCRI0fGZz/72Xjf+94XJ598cjzwwAPxvve9LyIifvrTn8Zpp50Wzc3NMW3atHjkkUfiPe95T7zwwgtRU1MTERGLFy+OG264IV566aWorKw8pM/Z0dER+Xw+zo2LoqJsyOEsHwBISHfWFavjoWhvb49cLjfQyznqmfMAgMHiUOe8fr9G2P79+2Pp0qWxZ8+eKBQKsX79+ujq6orGxsbiNRMnToxx48ZFc3NzREQ0NzfHpEmTisNRRMT06dOjo6Oj+N3Gg+ns7IyOjo5eNwAAjgxzHgBwrOpzCNu4cWOMGDEiqqqq4qqrroply5ZFfX19tLS0RGVlZVRXV/e6vqamJlpaWiIioqWlpddwdOD8gXP/m0WLFkU+ny/exo4d29dlAwDwKsx5AMCxrs8h7M1vfnNs2LAh1q5dG3Pnzo3Zs2fHs88+eyTWVrRgwYJob28v3rZv335EPx8AQIrMeQDAsa6ir3eorKyMN77xjRERMWXKlHjqqafii1/8Ylx66aWxb9++2LlzZ6/vFra2tkZtbW1ERNTW1sa6det6Pd6Bdxs6cM3BVFVVRVVVVV+XCgBAH5jzAIBjXb9fI+yAnp6e6OzsjClTpsSQIUNi1apVxXNbtmyJbdu2RaFQiIiIQqEQGzdujLa2tuI1K1eujFwuF/X19Ye7FAAASsicBwAca/r0E2ELFiyICy64IMaNGxe7du2KBx54IFavXh2PPvpo5PP5mDNnTsyfPz9GjhwZuVwurr766igUCjFt2rSIiDj//POjvr4+rrjiirjjjjuipaUlbrrppmhqavKdQACAAWTOAwBS0KcQ1tbWFh/84AfjxRdfjHw+H5MnT45HH300/vzP/zwiIj7/+c9HeXl5zJw5Mzo7O2P69Olx9913F+9/3HHHxfLly2Pu3LlRKBRi+PDhMXv27Lj11ltL+6wAAOgTcx4AkIKyLMuygV5EX3V0dEQ+n49z46KoKBsy0MsBAAaJ7qwrVsdD0d7eHrlcbqCXw0GY8wCA/jjUOe+wXyMMAAAAAAYDIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAknBYIez222+PsrKyuOaaa4rH9u7dG01NTTFq1KgYMWJEzJw5M1pbW3vdb9u2bTFjxowYNmxYjB49Oq6//vro7u4+nKUAAFBC5jwA4FjU7xD21FNPxT//8z/H5MmTex2/9tpr4+GHH44HH3ww1qxZEy+88EJccsklxfP79++PGTNmxL59++KJJ56I++67L5YsWRILFy7s/7MAAKBkzHkAwLGqXyFs9+7dMWvWrPjyl78cJ554YvF4e3t7fOUrX4nPfe5z8a53vSumTJkS9957bzzxxBPx5JNPRkTEd77znXj22Wfjq1/9arz1rW+NCy64ID796U/HXXfdFfv27SvNswIAoF/MeQDAsaxfIaypqSlmzJgRjY2NvY6vX78+urq6eh2fOHFijBs3LpqbmyMiorm5OSZNmhQ1NTXFa6ZPnx4dHR2xefPm/iwHAIASMecBAMeyir7eYenSpfGjH/0onnrqqVeca2lpicrKyqiuru51vKamJlpaWorX/PFwdOD8gXMH09nZGZ2dncWPOzo6+rpsAABehTkPADjW9eknwrZv3x4f+9jH4v7774/jjz/+SK3pFRYtWhT5fL54Gzt27Gv2uQEAUmDOAwBS0KcQtn79+mhra4u3ve1tUVFRERUVFbFmzZq48847o6KiImpqamLfvn2xc+fOXvdrbW2N2traiIiora19xbsLHfj4wDUvt2DBgmhvby/etm/f3pdlAwDwKsx5AEAK+hTCzjvvvNi4cWNs2LCheJs6dWrMmjWr+OchQ4bEqlWrivfZsmVLbNu2LQqFQkREFAqF2LhxY7S1tRWvWblyZeRyuaivrz/o562qqopcLtfrBgBA6ZjzAIAU9Ok1wk444YQ4/fTTex0bPnx4jBo1qnh8zpw5MX/+/Bg5cmTkcrm4+uqro1AoxLRp0yIi4vzzz4/6+vq44oor4o477oiWlpa46aaboqmpKaqqqkr0tAAA6AtzHgCQgj6/WP6r+fznPx/l5eUxc+bM6OzsjOnTp8fdd99dPH/cccfF8uXLY+7cuVEoFGL48OExe/bsuPXWW0u9FAAASsicBwAMdmVZlmUDvYi+6ujoiHw+H+fGRVFRNmSglwMADBLdWVesjoeivb3dr+Adpcx5AEB/HOqc16fXCAMAAACAwUoIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJKFPIexTn/pUlJWV9bpNnDixeH7v3r3R1NQUo0aNihEjRsTMmTOjtbW112Ns27YtZsyYEcOGDYvRo0fH9ddfH93d3aV5NgAA9Is5DwBIQUVf7/CWt7wlvvvd7/7hASr+8BDXXnttfOtb34oHH3ww8vl8zJs3Ly655JL44Q9/GBER+/fvjxkzZkRtbW088cQT8eKLL8YHP/jBGDJkSNx2220leDoAAPSXOQ8AONb1OYRVVFREbW3tK463t7fHV77ylXjggQfiXe96V0RE3HvvvXHaaafFk08+GdOmTYvvfOc78eyzz8Z3v/vdqKmpibe+9a3x6U9/Om644Yb41Kc+FZWVlYf/jAAA6BdzHgBwrOvza4Q999xzUVdXF294wxti1qxZsW3btoiIWL9+fXR1dUVjY2Px2okTJ8a4ceOiubk5IiKam5tj0qRJUVNTU7xm+vTp0dHREZs3bz7c5wIAwGEw5wEAx7o+/URYQ0NDLFmyJN785jfHiy++GLfccku8853vjE2bNkVLS0tUVlZGdXV1r/vU1NRES0tLRES0tLT0Go4OnD9w7n/T2dkZnZ2dxY87Ojr6smwAAF6FOQ8ASEGfQtgFF1xQ/PPkyZOjoaEhxo8fH1//+tdj6NChJV/cAYsWLYpbbrnliD0+AEDqzHkAQAr6/KuRf6y6ujre9KY3xfPPPx+1tbWxb9++2LlzZ69rWltbi681UVtb+4p3Fzrw8cFej+KABQsWRHt7e/G2ffv2w1k2AACvwpwHAByLDiuE7d69O37+85/HmDFjYsqUKTFkyJBYtWpV8fyWLVti27ZtUSgUIiKiUCjExo0bo62trXjNypUrI5fLRX19/f/6eaqqqiKXy/W6AQBw5JjzAIBjUZ9+NfLjH/94vPe9743x48fHCy+8EDfffHMcd9xxcfnll0c+n485c+bE/PnzY+TIkZHL5eLqq6+OQqEQ06ZNi4iI888/P+rr6+OKK66IO+64I1paWuKmm26KpqamqKqqOiJPEACAV2fOAwBS0KcQ9qtf/Souv/zy+O1vfxsnn3xynHPOOfHkk0/GySefHBERn//856O8vDxmzpwZnZ2dMX369Lj77ruL9z/uuONi+fLlMXfu3CgUCjF8+PCYPXt23HrrraV9VgAA9Ik5DwBIQVmWZdlAL6KvOjo6Ip/Px7lxUVSUDRno5QAAg0R31hWr46Fob2/3K3hHKXMeANAfhzrnHdZrhAEAAADAYCGEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCUIYAAAAAEkQwgAAAABIghAGAAAAQBKEMAAAAACSIIQBAAAAkAQhDAAAAIAkCGEAAAAAJEEIAwAAACAJQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAktDnEPbrX/86PvCBD8SoUaNi6NChMWnSpHj66aeL57Msi4ULF8aYMWNi6NCh0djYGM8991yvx9ixY0fMmjUrcrlcVFdXx5w5c2L37t2H/2wAAOg3cx4AcKzrUwj77//+7zj77LNjyJAh8cgjj8Szzz4b//AP/xAnnnhi8Zo77rgj7rzzzli8eHGsXbs2hg8fHtOnT4+9e/cWr5k1a1Zs3rw5Vq5cGcuXL4/HH388rrzyytI9KwAA+sScBwCkoCzLsuxQL77xxhvjhz/8YXz/+98/6Pksy6Kuri6uu+66+PjHPx4REe3t7VFTUxNLliyJyy67LH7yk59EfX19PPXUUzF16tSIiFixYkVceOGF8atf/Srq6upedR0dHR2Rz+fj3LgoKsqGHOryAYDEdWddsToeivb29sjlcgO9nKOKOQ8AGMwOdc7r00+EffOb34ypU6fG+9///hg9enSceeaZ8eUvf7l4fuvWrdHS0hKNjY3FY/l8PhoaGqK5uTkiIpqbm6O6uro4HEVENDY2Rnl5eaxdu7YvywEAoETMeQBACvoUwn7xi1/EPffcE6eeemo8+uijMXfu3PjoRz8a9913X0REtLS0RERETU1Nr/vV1NQUz7W0tMTo0aN7na+oqIiRI0cWr3m5zs7O6Ojo6HUDAKB0zHkAQAoq+nJxT09PTJ06NW677baIiDjzzDNj06ZNsXjx4pg9e/YRWWBExKJFi+KWW245Yo8PAJA6cx4AkII+/UTYmDFjor6+vtex0047LbZt2xYREbW1tRER0dra2uua1tbW4rna2tpoa2vrdb67uzt27NhRvOblFixYEO3t7cXb9u3b+7JsAABehTkPAEhBn0LY2WefHVu2bOl17Gc/+1mMHz8+IiImTJgQtbW1sWrVquL5jo6OWLt2bRQKhYiIKBQKsXPnzli/fn3xmsceeyx6enqioaHhoJ+3qqoqcrlcrxsAAKVjzgMAUtCnX4289tpr4x3veEfcdttt8Vd/9Vexbt26+NKXvhRf+tKXIiKirKwsrrnmmvjMZz4Tp556akyYMCE++clPRl1dXVx88cUR8fvvLL773e+Oj3zkI7F48eLo6uqKefPmxWWXXXZI7yQEAEDpmfMAgBT0KYSdddZZsWzZsliwYEHceuutMWHChPjCF74Qs2bNKl7ziU98Ivbs2RNXXnll7Ny5M84555xYsWJFHH/88cVr7r///pg3b16cd955UV5eHjNnzow777yzdM8KAIA+MecBACkoy7IsG+hF9FVHR0fk8/k4Ny6KirIhA70cAGCQ6M66YnU8FO3t7X4F7yhlzgMA+uNQ57w+vUYYAAAAAAxWQhgAAAAASRDCAAAAAEiCEAYAAABAEoQwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJAhhAAAAACRBCAMAAAAgCRUDvYD+yLIsIiK6oysiG+DFAACDRnd0RcQfZgmOPuY8AKA/DnXOG5QhbNeuXRER8YP49gCvBAAYjHbt2hX5fH6gl8FBmPMAgMPxanNeWTYIvyXa09MTW7Zsifr6+ti+fXvkcrmBXtKg1tHREWPHjrWXJWI/S8t+lpb9LC37WVqvxX5mWRa7du2Kurq6KC/3ChFHI3Neafl/qrTsZ2nZz9Kyn6VlP0vraJrzBuVPhJWXl8frXve6iIjI5XL+UpaIvSwt+1la9rO07Gdp2c/SOtL76SfBjm7mvCPDXpaW/Swt+1la9rO07GdpHQ1znm+FAgAAAJAEIQwAAACAJAzaEFZVVRU333xzVFVVDfRSBj17WVr2s7TsZ2nZz9Kyn6VlPznA34XSsZelZT9Ly36Wlv0sLftZWkfTfg7KF8sHAAAAgL4atD8RBgAAAAB9IYQBAAAAkAQhDAAAAIAkCGEAAAAAJGFQhrC77rorXv/618fxxx8fDQ0NsW7duoFe0lHp8ccfj/e+971RV1cXZWVl8Y1vfKPX+SzLYuHChTFmzJgYOnRoNDY2xnPPPdfrmh07dsSsWbMil8tFdXV1zJkzJ3bv3v0aPoujw6JFi+Kss86KE044IUaPHh0XX3xxbNmypdc1e/fujaamphg1alSMGDEiZs6cGa2trb2u2bZtW8yYMSOGDRsWo0ePjuuvvz66u7tfy6dyVLjnnnti8uTJkcvlIpfLRaFQiEceeaR43l4enttvvz3KysrimmuuKR6zp4fuU5/6VJSVlfW6TZw4sXjeXvbdr3/96/jABz4Qo0aNiqFDh8akSZPi6aefLp739Yg/Zs47NOa80jHnlZY578gy5x0ec17pDco5Lxtkli5dmlVWVmb/+q//mm3evDn7yEc+klVXV2etra0DvbSjzre//e3s7/7u77L/+I//yCIiW7ZsWa/zt99+e5bP57NvfOMb2X/+539mf/EXf5FNmDAh+93vfle85t3vfnd2xhlnZE8++WT2/e9/P3vjG9+YXX755a/xMxl406dPz+69995s06ZN2YYNG7ILL7wwGzduXLZ79+7iNVdddVU2duzYbNWqVdnTTz+dTZs2LXvHO95RPN/d3Z2dfvrpWWNjY/bMM89k3/72t7OTTjopW7BgwUA8pQH1zW9+M/vWt76V/exnP8u2bNmS/e3f/m02ZMiQbNOmTVmW2cvDsW7duuz1r399Nnny5OxjH/tY8bg9PXQ333xz9pa3vCV78cUXi7eXXnqpeN5e9s2OHTuy8ePHZx/60IeytWvXZr/4xS+yRx99NHv++eeL1/h6xAHmvENnzisdc15pmfOOHHPe4TPnldZgnfMGXQh7+9vfnjU1NRU/3r9/f1ZXV5ctWrRoAFd19Hv5gNTT05PV1tZmn/3sZ4vHdu7cmVVVVWVf+9rXsizLsmeffTaLiOypp54qXvPII49kZWVl2a9//evXbO1Ho7a2tiwisjVr1mRZ9vu9GzJkSPbggw8Wr/nJT36SRUTW3NycZdnvB9by8vKspaWleM0999yT5XK5rLOz87V9AkehE088MfuXf/kXe3kYdu3alZ166qnZypUrsz/90z8tDkj2tG9uvvnm7IwzzjjoOXvZdzfccEN2zjnn/K/nfT3ij5nz+secV1rmvNIz5x0+c15pmPNKa7DOeYPqVyP37dsX69evj8bGxuKx8vLyaGxsjObm5gFc2eCzdevWaGlp6bWX+Xw+GhoainvZ3Nwc1dXVMXXq1OI1jY2NUV5eHmvXrn3N13w0aW9vj4iIkSNHRkTE+vXro6urq9d+Tpw4McaNG9drPydNmhQ1NTXFa6ZPnx4dHR2xefPm13D1R5f9+/fH0qVLY8+ePVEoFOzlYWhqaooZM2b02rsIfz/747nnnou6urp4wxveELNmzYpt27ZFhL3sj29+85sxderUeP/73x+jR4+OM888M7785S8Xz/t6xAHmvNLx7+rwmPNKx5xXOua80jHnlc5gnfMGVQj7zW9+E/v37+/1ly4ioqamJlpaWgZoVYPTgf36v/aypaUlRo8e3et8RUVFjBw5Mun97unpiWuuuSbOPvvsOP300yPi93tVWVkZ1dXVva59+X4ebL8PnEvNxo0bY8SIEVFVVRVXXXVVLFu2LOrr6+1lPy1dujR+9KMfxaJFi15xzp72TUNDQyxZsiRWrFgR99xzT2zdujXe+c53xq5du+xlP/ziF7+Ie+65J0499dR49NFHY+7cufHRj3407rvvvojw9Yg/MOeVjn9X/WfOKw1zXmmZ80rHnFdag3XOqzgijwrHsKampti0aVP84Ac/GOilDGpvfvObY8OGDdHe3h7//u//HrNnz441a9YM9LIGpe3bt8fHPvaxWLlyZRx//PEDvZxB74ILLij+efLkydHQ0BDjx4+Pr3/96zF06NABXNng1NPTE1OnTo3bbrstIiLOPPPM2LRpUyxevDhmz549wKsD6M2cVxrmvNIx55WWOa+0BuucN6h+Iuykk06K44477hXv2tDa2hq1tbUDtKrB6cB+/V97WVtbG21tbb3Od3d3x44dO5Ld73nz5sXy5cvje9/7XpxyyinF47W1tbFv377YuXNnr+tfvp8H2+8D51JTWVkZb3zjG2PKlCmxaNGiOOOMM+KLX/yiveyH9evXR1tbW7ztbW+LioqKqKioiDVr1sSdd94ZFRUVUVNTY08PQ3V1dbzpTW+K559/3t/PfhgzZkzU19f3OnbaaacVfw3B1yMOMOeVjn9X/WPOKx1zXumY844sc97hGaxz3qAKYZWVlTFlypRYtWpV8VhPT0+sWrUqCoXCAK5s8JkwYULU1tb22suOjo5Yu3ZtcS8LhULs3Lkz1q9fX7zmsccei56enmhoaHjN1zyQsiyLefPmxbJly+Kxxx6LCRMm9Do/ZcqUGDJkSK/93LJlS2zbtq3Xfm7cuLHXP/KVK1dGLpd7xX8eKerp6YnOzk572Q/nnXdebNy4MTZs2FC8TZ06NWbNmlX8sz3tv927d8fPf/7zGDNmjL+f/XD22WfHli1beh372c9+FuPHj48IX4/4A3Ne6fh31TfmvCPPnNd/5rwjy5x3eAbtnHdEXoL/CFq6dGlWVVWVLVmyJHv22WezK6+8Mquuru71rg383q5du7Jnnnkme+aZZ7KIyD73uc9lzzzzTPbLX/4yy7Lfv41pdXV19tBDD2U//vGPs4suuuigb2N65plnZmvXrs1+8IMfZKeeemqSb6s9d+7cLJ/PZ6tXr+71Vrv/8z//U7zmqquuysaNG5c99thj2dNPP50VCoWsUCgUzx94q93zzz8/27BhQ7ZixYrs5JNPTvKtdm+88cZszZo12datW7Mf//jH2Y033piVlZVl3/nOd7Iss5el8MfvJpRl9rQvrrvuumz16tXZ1q1bsx/+8IdZY2NjdtJJJ2VtbW1ZltnLvlq3bl1WUVGR/f3f/3323HPPZffff382bNiw7Ktf/WrxGl+POMCcd+jMeaVjzistc96RZ87rP3NeaQ3WOW/QhbAsy7J//Md/zMaNG5dVVlZmb3/727Mnn3xyoJd0VPre976XRcQrbrNnz86y7PdvZfrJT34yq6mpyaqqqrLzzjsv27JlS6/H+O1vf5tdfvnl2YgRI7JcLpd9+MMfznbt2jUAz2ZgHWwfIyK79957i9f87ne/y/7mb/4mO/HEE7Nhw4Zlf/mXf5m9+OKLvR7nv/7rv7ILLrggGzp0aHbSSSdl1113XdbV1fUaP5uB99d//dfZ+PHjs8rKyuzkk0/OzjvvvOJwlGX2shRePiDZ00N36aWXZmPGjMkqKyuz173uddmll16aPf/888Xz9rLvHn744ez000/PqqqqsokTJ2Zf+tKXep339Yg/Zs47NOa80jHnlZY578gz5/WfOa/0BuOcV5ZlWXZkftYMAAAAAI4eg+o1wgAAAACgv4QwAAAAAJIghAEAAACQBCEMAAAAgCQIYQAAAAAkQQgDAAAAIAlCGAAAAABJEMIAAAAASIIQBgAAAEAShDAAAAAAkiCEAQAAAJAEIQwAAACAJPw/HP6hZFNLfccAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 45\n",
    "plt.figure(figsize=(15, 15))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.imshow(inferenced_array.argmax(0)[i])\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.imshow(zeros_array[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
