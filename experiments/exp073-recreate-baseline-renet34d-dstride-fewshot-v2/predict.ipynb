{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import timm\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# import torchvision.transforms.functional as F\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import Unet3D\n",
    "from src.utils import save_images, PadToSize\n",
    "from src.metric import (\n",
    "    score,\n",
    "    create_cls_pos,\n",
    "    create_cls_pos_sikii,\n",
    "    create_df,\n",
    "    SegmentationLoss,\n",
    "    DiceLoss,\n",
    ")\n",
    "from metric import visualize_epoch_results\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "from src.inference import inference, inference2pos\n",
    "from src.kaggle_notebook_metric import compute_lb\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>experiment</th>\n",
       "      <th>particle_type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>3045.036742</td>\n",
       "      <td>919.139280</td>\n",
       "      <td>421.270403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2969.078552</td>\n",
       "      <td>1027.114255</td>\n",
       "      <td>440.085721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2839.792769</td>\n",
       "      <td>1069.080767</td>\n",
       "      <td>425.839468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2875.180486</td>\n",
       "      <td>1077.907940</td>\n",
       "      <td>298.254286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TS_4</td>\n",
       "      <td>apo-ferritin</td>\n",
       "      <td>2765.950544</td>\n",
       "      <td>1019.336833</td>\n",
       "      <td>322.072039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14628</th>\n",
       "      <td>14628</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2609.876000</td>\n",
       "      <td>4569.876000</td>\n",
       "      <td>1169.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14629</th>\n",
       "      <td>14629</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>2213.287000</td>\n",
       "      <td>4135.017000</td>\n",
       "      <td>1286.851000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14630</th>\n",
       "      <td>14630</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>3303.905000</td>\n",
       "      <td>5697.825000</td>\n",
       "      <td>789.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>14631</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>1008.748000</td>\n",
       "      <td>5949.213000</td>\n",
       "      <td>1077.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>14632</td>\n",
       "      <td>TS_6_6</td>\n",
       "      <td>virus-like-particle</td>\n",
       "      <td>5749.052000</td>\n",
       "      <td>3911.392000</td>\n",
       "      <td>275.342000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14633 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index experiment        particle_type            x            y  \\\n",
       "0          0       TS_4         apo-ferritin  3045.036742   919.139280   \n",
       "1          1       TS_4         apo-ferritin  2969.078552  1027.114255   \n",
       "2          2       TS_4         apo-ferritin  2839.792769  1069.080767   \n",
       "3          3       TS_4         apo-ferritin  2875.180486  1077.907940   \n",
       "4          4       TS_4         apo-ferritin  2765.950544  1019.336833   \n",
       "...      ...        ...                  ...          ...          ...   \n",
       "14628  14628     TS_6_6  virus-like-particle  2609.876000  4569.876000   \n",
       "14629  14629     TS_6_6  virus-like-particle  2213.287000  4135.017000   \n",
       "14630  14630     TS_6_6  virus-like-particle  3303.905000  5697.825000   \n",
       "14631  14631     TS_6_6  virus-like-particle  1008.748000  5949.213000   \n",
       "14632  14632     TS_6_6  virus-like-particle  5749.052000  3911.392000   \n",
       "\n",
       "                 z  \n",
       "0       421.270403  \n",
       "1       440.085721  \n",
       "2       425.839468  \n",
       "3       298.254286  \n",
       "4       322.072039  \n",
       "...            ...  \n",
       "14628  1169.759000  \n",
       "14629  1286.851000  \n",
       "14630   789.744000  \n",
       "14631  1077.303000  \n",
       "14632   275.342000  \n",
       "\n",
       "[14633 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.train_exp_names)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "from typing import OrderedDict\n",
    "\n",
    "\n",
    "def combine_models(\n",
    "    models: list[torch.nn.Module],\n",
    "    model_weights: list[float],\n",
    ") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    How:\n",
    "        モデルのパラメータを、渡されたそれぞれの重みに応じて重み付き平均して1つのモデルにまとめる。\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    models : list[torch.nn.Module]\n",
    "        重み付き平均したいモデルたち。\n",
    "    model_weights : list[float]\n",
    "        上記モデルたちに対応した重み。\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    torch.nn.Module\n",
    "        重み付き平均されたモデル。\n",
    "    \"\"\"\n",
    "    # Why not: model_weightsの長さとmodelsの数が一致しない場合はエラーを出す以外に、\n",
    "    #         例外を投げる方法もあるが、そのままにする。\n",
    "    assert len(models) == len(model_weights), \"モデルと重みの数が一致していません。\"\n",
    "\n",
    "    # Why not: PyTorchのModuleを新規に作り直す方法もあるが、最初のモデルをコピーして\n",
    "    #         そこに重みを上書きする形が簡単。\n",
    "    # ここでは models[0] のstate_dictをコピーして初期化し、それに各モデルを加算していく\n",
    "    base_state_dict = models[0].state_dict()\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    # 合計重み(正規化のため)を計算\n",
    "    weight_sum = sum(model_weights)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for key in base_state_dict.keys():\n",
    "            # if \"encoder\" in key:  # encoderは重み平均しない\n",
    "            #     new_state_dict[key] = base_state_dict[key]\n",
    "            #     continue\n",
    "\n",
    "            # encoderの重みのみ平均\n",
    "            if \"encoder\" in key:\n",
    "                avg_param = base_state_dict[key] * model_weights[0]\n",
    "                for i in range(1, len(models)):\n",
    "                    avg_param += models[i].state_dict()[key] * model_weights[i]\n",
    "                avg_param /= weight_sum\n",
    "                new_state_dict[key] = avg_param\n",
    "                continue\n",
    "            else:\n",
    "                new_state_dict[key] = base_state_dict[key]\n",
    "                continue\n",
    "\n",
    "            # まず最初のモデルのパラメータ*重み で初期化\n",
    "            avg_param = base_state_dict[key] * model_weights[0]\n",
    "\n",
    "            # 残りのモデルを加算\n",
    "            for i in range(1, len(models)):\n",
    "                avg_param += models[i].state_dict()[key] * model_weights[i]\n",
    "\n",
    "            # 重み和で割って正規化\n",
    "            avg_param /= weight_sum\n",
    "            new_state_dict[key] = avg_param\n",
    "\n",
    "    # 新しいモデル(同じアーキテクチャ)を作り、new_state_dictをロード\n",
    "    # ここでは例としてmodels[0]と同じクラスを使う\n",
    "    combined_model = type(models[0])(\n",
    "        encoder=models[0].encoder,  # Unet3Dのコンストラクタ引数を流用\n",
    "        num_domains=5,\n",
    "    )\n",
    "    combined_model.load_state_dict(new_state_dict)\n",
    "\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Unet3D:\n\tMissing key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.0.weight\", \"encoder.conv1.1.weight\", \"encoder.conv1.1.bias\", \"encoder.conv1.1.running_mean\", \"encoder.conv1.1.running_var\", \"encoder.conv1.1.num_batches_tracked\", \"encoder.conv1.3.weight\", \"encoder.conv1.4.weight\", \"encoder.conv1.4.bias\", \"encoder.conv1.4.running_mean\", \"encoder.conv1.4.running_var\", \"encoder.conv1.4.num_batches_tracked\", \"encoder.conv1.6.weight\", \"encoder.layer2.0.downsample.2.weight\", \"encoder.layer2.0.downsample.2.bias\", \"encoder.layer2.0.downsample.2.running_mean\", \"encoder.layer2.0.downsample.2.running_var\", \"encoder.layer2.0.downsample.2.num_batches_tracked\", \"encoder.layer3.0.downsample.2.weight\", \"encoder.layer3.0.downsample.2.bias\", \"encoder.layer3.0.downsample.2.running_mean\", \"encoder.layer3.0.downsample.2.running_var\", \"encoder.layer3.0.downsample.2.num_batches_tracked\", \"encoder.layer4.0.downsample.2.weight\", \"encoder.layer4.0.downsample.2.bias\", \"encoder.layer4.0.downsample.2.running_mean\", \"encoder.layer4.0.downsample.2.running_var\", \"encoder.layer4.0.downsample.2.num_batches_tracked\". \n\tsize mismatch for encoder.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.0.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3, 3]).\n\tsize mismatch for encoder.layer1.0.bn2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for encoder.layer1.1.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3, 3]).\n\tsize mismatch for encoder.layer1.1.bn2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for encoder.layer1.2.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3, 3]).\n\tsize mismatch for encoder.layer1.2.bn2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for encoder.layer2.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for encoder.layer2.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for encoder.layer2.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.3.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for encoder.layer2.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.4.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.4.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.5.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.5.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for encoder.layer4.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 1, 1]).\n\tsize mismatch for encoder.layer4.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for encoder.layer4.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 1, 1]).\n\tsize mismatch for encoder.layer4.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for encoder.layer4.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.block.0.cross_attn.domain_embedding.weight: copying a param with shape torch.Size([5, 768]) from checkpoint, the shape in current model is torch.Size([5, 3072]).\n\tsize mismatch for decoder.block.0.cross_attn.conv.weight: copying a param with shape torch.Size([768, 1536, 5, 5]) from checkpoint, the shape in current model is torch.Size([3072, 6144, 5, 5]).\n\tsize mismatch for decoder.block.0.cross_attn.conv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.cross_attn.norm.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.cross_attn.norm.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.cross_attn.norm.running_mean: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.cross_attn.norm.running_var: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.conv1.0.weight: copying a param with shape torch.Size([256, 768, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 3072, 3, 3, 3]).\n\tsize mismatch for decoder.block.1.cross_attn.domain_embedding.weight: copying a param with shape torch.Size([5, 384]) from checkpoint, the shape in current model is torch.Size([5, 768]).\n\tsize mismatch for decoder.block.1.cross_attn.conv.weight: copying a param with shape torch.Size([384, 768, 5, 5]) from checkpoint, the shape in current model is torch.Size([768, 1536, 5, 5]).\n\tsize mismatch for decoder.block.1.cross_attn.conv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.cross_attn.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.cross_attn.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.cross_attn.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.cross_attn.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.conv1.0.weight: copying a param with shape torch.Size([128, 384, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 768, 3, 3, 3]).\n\tsize mismatch for decoder.block.2.cross_attn.domain_embedding.weight: copying a param with shape torch.Size([5, 192]) from checkpoint, the shape in current model is torch.Size([5, 384]).\n\tsize mismatch for decoder.block.2.cross_attn.conv.weight: copying a param with shape torch.Size([192, 384, 5, 5]) from checkpoint, the shape in current model is torch.Size([384, 768, 5, 5]).\n\tsize mismatch for decoder.block.2.cross_attn.conv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.cross_attn.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.cross_attn.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.cross_attn.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.cross_attn.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 384, 3, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m model06 \u001b[38;5;241m=\u001b[39m Unet3D(encoder\u001b[38;5;241m=\u001b[39mencoder, num_domains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# モデルのロード\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodel01\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./TS_69_2/best_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m model02\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./TS_6_4/best_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     26\u001b[0m model03\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./TS_6_6/best_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Unet3D:\n\tMissing key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.0.weight\", \"encoder.conv1.1.weight\", \"encoder.conv1.1.bias\", \"encoder.conv1.1.running_mean\", \"encoder.conv1.1.running_var\", \"encoder.conv1.1.num_batches_tracked\", \"encoder.conv1.3.weight\", \"encoder.conv1.4.weight\", \"encoder.conv1.4.bias\", \"encoder.conv1.4.running_mean\", \"encoder.conv1.4.running_var\", \"encoder.conv1.4.num_batches_tracked\", \"encoder.conv1.6.weight\", \"encoder.layer2.0.downsample.2.weight\", \"encoder.layer2.0.downsample.2.bias\", \"encoder.layer2.0.downsample.2.running_mean\", \"encoder.layer2.0.downsample.2.running_var\", \"encoder.layer2.0.downsample.2.num_batches_tracked\", \"encoder.layer3.0.downsample.2.weight\", \"encoder.layer3.0.downsample.2.bias\", \"encoder.layer3.0.downsample.2.running_mean\", \"encoder.layer3.0.downsample.2.running_var\", \"encoder.layer3.0.downsample.2.num_batches_tracked\", \"encoder.layer4.0.downsample.2.weight\", \"encoder.layer4.0.downsample.2.bias\", \"encoder.layer4.0.downsample.2.running_mean\", \"encoder.layer4.0.downsample.2.running_var\", \"encoder.layer4.0.downsample.2.num_batches_tracked\". \n\tsize mismatch for encoder.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.0.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3, 3]).\n\tsize mismatch for encoder.layer1.0.bn2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.0.bn2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for encoder.layer1.1.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3, 3]).\n\tsize mismatch for encoder.layer1.1.bn2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.1.bn2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for encoder.layer1.2.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 4, 3, 3]).\n\tsize mismatch for encoder.layer1.2.bn2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer1.2.bn2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for encoder.layer2.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for encoder.layer2.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for encoder.layer2.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.3.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for encoder.layer2.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer2.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.4.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.4.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.4.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.5.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for encoder.layer3.5.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer3.5.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for encoder.layer4.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 1, 1]).\n\tsize mismatch for encoder.layer4.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for encoder.layer4.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 1, 1]).\n\tsize mismatch for encoder.layer4.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for encoder.layer4.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer4.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.block.0.cross_attn.domain_embedding.weight: copying a param with shape torch.Size([5, 768]) from checkpoint, the shape in current model is torch.Size([5, 3072]).\n\tsize mismatch for decoder.block.0.cross_attn.conv.weight: copying a param with shape torch.Size([768, 1536, 5, 5]) from checkpoint, the shape in current model is torch.Size([3072, 6144, 5, 5]).\n\tsize mismatch for decoder.block.0.cross_attn.conv.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.cross_attn.norm.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.cross_attn.norm.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.cross_attn.norm.running_mean: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.cross_attn.norm.running_var: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for decoder.block.0.conv1.0.weight: copying a param with shape torch.Size([256, 768, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 3072, 3, 3, 3]).\n\tsize mismatch for decoder.block.1.cross_attn.domain_embedding.weight: copying a param with shape torch.Size([5, 384]) from checkpoint, the shape in current model is torch.Size([5, 768]).\n\tsize mismatch for decoder.block.1.cross_attn.conv.weight: copying a param with shape torch.Size([384, 768, 5, 5]) from checkpoint, the shape in current model is torch.Size([768, 1536, 5, 5]).\n\tsize mismatch for decoder.block.1.cross_attn.conv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.cross_attn.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.cross_attn.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.cross_attn.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.cross_attn.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for decoder.block.1.conv1.0.weight: copying a param with shape torch.Size([128, 384, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 768, 3, 3, 3]).\n\tsize mismatch for decoder.block.2.cross_attn.domain_embedding.weight: copying a param with shape torch.Size([5, 192]) from checkpoint, the shape in current model is torch.Size([5, 384]).\n\tsize mismatch for decoder.block.2.cross_attn.conv.weight: copying a param with shape torch.Size([192, 384, 5, 5]) from checkpoint, the shape in current model is torch.Size([384, 768, 5, 5]).\n\tsize mismatch for decoder.block.2.cross_attn.conv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.cross_attn.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.cross_attn.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.cross_attn.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.cross_attn.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for decoder.block.2.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 384, 3, 3, 3])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "\n",
    "# 例としてtimmのエンコーダを作成\n",
    "# (Unet3Dはユーザー定義クラスで、同一クラス・同一初期化が必要)\n",
    "encoder = timm.create_model(\n",
    "    model_name=CFG.model_name,\n",
    "    pretrained=True,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"\",\n",
    "    features_only=True,\n",
    ")\n",
    "\n",
    "# モデルのインスタンス化\n",
    "model01 = Unet3D(encoder=encoder, num_domains=5)\n",
    "model02 = Unet3D(encoder=encoder, num_domains=5)\n",
    "model03 = Unet3D(encoder=encoder, num_domains=5)\n",
    "model04 = Unet3D(encoder=encoder, num_domains=5)\n",
    "model05 = Unet3D(encoder=encoder, num_domains=5)\n",
    "model06 = Unet3D(encoder=encoder, num_domains=5)\n",
    "\n",
    "# モデルのロード\n",
    "model01.load_state_dict(torch.load(\"./TS_69_2/best_model.pth\"))\n",
    "model02.load_state_dict(torch.load(\"./TS_6_4/best_model.pth\"))\n",
    "model03.load_state_dict(torch.load(\"./TS_6_6/best_model.pth\"))\n",
    "model04.load_state_dict(torch.load(\"./TS_73_6/best_model.pth\"))\n",
    "model05.load_state_dict(torch.load(\"./TS_86_3/best_model.pth\"))\n",
    "model06.load_state_dict(torch.load(\"./TS_99_9/best_model.pth\"))\n",
    "\n",
    "# 各モデルに対する重み\n",
    "model01_m = 1.0\n",
    "model02_m = 1.0  # 01\n",
    "model03_m = 1.0  # 01\n",
    "model04_m = 1.0  # 01\n",
    "model05_m = 1.0  # 01\n",
    "model06_m = 1.0  # 01\n",
    "\n",
    "# モデルをまとめる\n",
    "models = [model01, model02, model03, model04, model05, model06]\n",
    "model_weights = [model01_m, model02_m, model03_m, model04_m, model05_m, model06_m]\n",
    "\n",
    "combined_model = combine_models(models, model_weights).cuda()\n",
    "torch.save(combined_model.state_dict(), \"./combined_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = combined_model\n",
    "# model = model01.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "# encoder = timm.create_model(\n",
    "#     model_name=CFG.model_name,\n",
    "#     pretrained=True,\n",
    "#     in_chans=3,\n",
    "#     num_classes=0,\n",
    "#     global_pool=\"\",\n",
    "#     features_only=True,\n",
    "# )\n",
    "# model = Unet3D(encoder=encoder, num_domains=5).to(\"cuda\")\n",
    "# model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "# inferenced_array = inference(model, exp_name, train=False)\n",
    "# 0.7303962244998289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = CFG.valid_exp_names  # [\"TS_6_4\", \"TS_5_4\", \"TS_69_2\"]\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "constant = 0.25\n",
    "sikii = {\n",
    "    \"apo-ferritin\": constant,\n",
    "    \"beta-amylase\": constant,\n",
    "    \"beta-galactosidase\": constant,\n",
    "    \"ribosome\": constant,\n",
    "    \"thyroglobulin\": constant,\n",
    "    \"virus-like-particle\": constant,\n",
    "}\n",
    "\n",
    "pred_dict = {}\n",
    "\n",
    "# for exp_name in tqdm(CFG.train_exp_names):\n",
    "for exp_name in tqdm(exp_names):  # 5つのデータで試す\n",
    "\n",
    "    inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "        combined_model.cuda(),\n",
    "        exp_name,\n",
    "        train=False,\n",
    "        base_dir=\"../../inputs/train/\",\n",
    "    )\n",
    "\n",
    "    # inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "    #     model01.cuda(),\n",
    "    #     exp_name,\n",
    "    #     train=False,\n",
    "    #     base_dir=\"../../inputs/train/\",\n",
    "    # )\n",
    "    # del model01\n",
    "    # pred_dict[exp_name] = inferenced_array\n",
    "\n",
    "    # i, _, _ = inference(\n",
    "    #     model02.cuda(),\n",
    "    #     exp_name,\n",
    "    #     train=False,\n",
    "    #     base_dir=\"../../inputs/train/\",\n",
    "    # )\n",
    "    # del model02\n",
    "    # inferenced_array += i\n",
    "\n",
    "    # i, _, _ = inference(\n",
    "    #     model03.cuda(),\n",
    "    #     exp_name,\n",
    "    #     train=False,\n",
    "    #     base_dir=\"../../inputs/train/\",\n",
    "    # )\n",
    "    # del model03\n",
    "    # inferenced_array += i\n",
    "\n",
    "    # i, _, _ = inference(\n",
    "    #     model04.cuda(),\n",
    "    #     exp_name,\n",
    "    #     train=False,\n",
    "    #     base_dir=\"../../inputs/train/\",\n",
    "    # )\n",
    "    # del model04\n",
    "    # inferenced_array += i\n",
    "\n",
    "    # i, _, _ = inference(\n",
    "    #     model05.cuda(),\n",
    "    #     exp_name,\n",
    "    #     train=False,\n",
    "    #     base_dir=\"../../inputs/train/\",\n",
    "    # )\n",
    "    # del model05\n",
    "    # inferenced_array += i\n",
    "\n",
    "    # i, _, _ = inference(\n",
    "    #     model06.cuda(),\n",
    "    #     exp_name,\n",
    "    #     train=False,\n",
    "    #     base_dir=\"../../inputs/train/\",\n",
    "    # )\n",
    "    # del model\n",
    "    # inferenced_array += i\n",
    "\n",
    "    # inferenced_array /= 3\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pd.concat(all_pred, axis=0).reset_index(drop=True)\n",
    "# pred_df = pred_df[pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "# pred_df = pred_df.drop_duplicates(\n",
    "#     subset=[\"experiment\", \"x\", \"y\", \"z\"], keep=\"first\"\n",
    "# ).reset_index(drop=True)\n",
    "# pred_df = pred_df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "# pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", exp_names)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sikii値とexp_namesを入れるとスコアを出力する関数\n",
    "\n",
    "\n",
    "def compute_score(sikii_list, inferenced_array, exp_name):\n",
    "    apo_ferritin = sikii_list[0]\n",
    "    beta_amylase = sikii_list[1]\n",
    "    beta_galactosidase = sikii_list[2]\n",
    "    ribosome = sikii_list[3]\n",
    "    thyroglobulin = sikii_list[4]\n",
    "    virus_like_particle = sikii_list[5]\n",
    "\n",
    "    sikii_dict = {\n",
    "        \"apo-ferritin\": apo_ferritin,\n",
    "        \"beta-amylase\": beta_amylase,\n",
    "        \"beta-galactosidase\": beta_galactosidase,\n",
    "        \"ribosome\": ribosome,\n",
    "        \"thyroglobulin\": thyroglobulin,\n",
    "        \"virus-like-particle\": virus_like_particle,\n",
    "    }\n",
    "\n",
    "    all_pred = []\n",
    "\n",
    "    pred_df = inference2pos(\n",
    "        pred_segmask=inferenced_array, exp_name=exp_name, sikii_dict=sikii_dict\n",
    "    )\n",
    "\n",
    "    all_pred.append(pred_df)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    pred_df = pd.concat(all_pred, axis=0).reset_index(drop=True)\n",
    "    pred_df = pred_df[pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "    pred_df = pred_df.drop_duplicates(\n",
    "        subset=[\"experiment\", \"x\", \"y\", \"z\"], keep=\"first\"\n",
    "    ).reset_index(drop=True)\n",
    "    pred_df = pred_df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "\n",
    "    gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", [exp_name])\n",
    "\n",
    "    result_df, lb_score = compute_lb(\n",
    "        pred_df, \"../../inputs/train/overlay/ExperimentRuns/\", [exp_name]\n",
    "    )\n",
    "\n",
    "    return lb_score\n",
    "\n",
    "\n",
    "def reduce_computation_sikii_search(\n",
    "    inferenced_array: np.ndarray, exp_name: str, threshold_candidates: list[float]\n",
    ") -> tuple[list[float], float]:\n",
    "    \"\"\"\n",
    "    # How\n",
    "    6つのしきい値が互いに独立してスコアに貢献しているという前提で、\n",
    "    1次元ずつ最適なしきい値を探す手法を実装する.\n",
    "\n",
    "    1. 初期の best_thresholds (全要素 0.5 など適当な値) を用意\n",
    "    2. i=0 から i=5 まで順番に:\n",
    "       - threshold_candidates をすべて試し、他は固定したまま i 番目だけ変化させてスコアを計算\n",
    "       - 最良スコアが得られる候補値を確定し、best_thresholds[i] とする\n",
    "    3. 全部決まったら最終的なスコアを計算して返す\n",
    "\n",
    "    これにより、全組み合わせ (product) を回すよりも計算量が大幅に減少する.\n",
    "    \"\"\"\n",
    "    # Why not: 6値独立であるという前提が満たされていない場合、近似解になる可能性あり\n",
    "    best_thresholds = [0.5] * 6  # 適当な初期値でOK\n",
    "\n",
    "    for i in tqdm(range(6)):\n",
    "        best_local_score = -float(\"inf\")\n",
    "        best_local_value = None\n",
    "\n",
    "        for candidate in threshold_candidates:\n",
    "            current_thresholds = best_thresholds[:]  # 現在のベストを複製\n",
    "            current_thresholds[i] = candidate\n",
    "            try:\n",
    "                score = compute_score(current_thresholds, inferenced_array, exp_name)\n",
    "            except:\n",
    "                score = -float(\"inf\")\n",
    "            if score > best_local_score:\n",
    "                best_local_score = score\n",
    "                best_local_value = candidate\n",
    "\n",
    "        # i番目のしきい値を最適値に更新\n",
    "        best_thresholds[i] = best_local_value\n",
    "\n",
    "    final_score = compute_score(best_thresholds, inferenced_array, exp_name)\n",
    "    return best_thresholds, final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_score([0.25, 0.25, 0.25, 0.25, 0.25, 0.25], exp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均値\n",
    "from sklearn.metrics import *\n",
    "from scipy.optimize import minimize\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "exp_name = CFG.valid_exp_names[0]\n",
    "\n",
    "# inferenced_array, n_tomogram, segmentation_map = inference(\n",
    "#     model,\n",
    "#     exp_name,\n",
    "#     train=False,\n",
    "#     base_dir=\"../../inputs/train/\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmx(x):\n",
    "    # x: (cls, depth, height, width)\n",
    "    x = np.exp(x)\n",
    "    x = x / x.sum(axis=0)\n",
    "    return x\n",
    "\n",
    "\n",
    "# inferenced_array = softmx(inferenced_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 130\n",
    "cls = 5\n",
    "# inferenced_array[cls, depth]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(inferenced_array[cls, depth], cmap=\"gray\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 121\n",
    "cls = 5\n",
    "# inferenced_array[cls, depth]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(inferenced_array[cls, depth], cmap=\"gray\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KappaOPtimizer = minimize(\n",
    "#     compute_score,\n",
    "#     x0=[0.90, 0.90, 0.90, 0.90, 0.90, 0.90],\n",
    "#     args=(inferenced_array, exp_name),\n",
    "#     bounds=[(0.0, 0.95) for _ in range(6)],\n",
    "#     method=\"nelder-mead\",\n",
    "#     options={\"maxiter\": 50},\n",
    "# )\n",
    "\n",
    "inferenced_array = softmx(inferenced_array)\n",
    "\n",
    "best_thresholds, final_score = reduce_computation_sikii_search(\n",
    "    # inferenced_array, exp_name, np.linspace(0.000001, 0.5, 20)\n",
    "    inferenced_array,\n",
    "    exp_name,\n",
    "    np.linspace(0.01, 0.75, 12),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_score(best_thresholds, inferenced_array, exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.valid_exp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apo_ferritin = best_thresholds[0]\n",
    "beta_amylase = best_thresholds[1]\n",
    "beta_galactosidase = best_thresholds[2]\n",
    "ribosome = best_thresholds[3]\n",
    "thyroglobulin = best_thresholds[4]\n",
    "virus_like_particle = best_thresholds[5]\n",
    "\n",
    "sikii_dict = {\n",
    "    \"apo-ferritin\": apo_ferritin,\n",
    "    \"beta-amylase\": beta_amylase,\n",
    "    \"beta-galactosidase\": beta_galactosidase,\n",
    "    \"ribosome\": ribosome,\n",
    "    \"thyroglobulin\": thyroglobulin,\n",
    "    \"virus-like-particle\": virus_like_particle,\n",
    "}\n",
    "\n",
    "sikii_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
