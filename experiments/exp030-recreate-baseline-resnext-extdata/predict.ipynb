{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./src/\")\n",
    "\n",
    "from src.config import CFG\n",
    "from src.dataloader import (\n",
    "    read_zarr,\n",
    "    read_info_json,\n",
    "    scale_coordinates,\n",
    "    create_dataset,\n",
    "    create_segmentation_map,\n",
    "    EziiDataset,\n",
    "    drop_padding,\n",
    ")\n",
    "from src.network import UNet_2D, aug\n",
    "from src.utils import save_images\n",
    "from src.metric import score, create_cls_pos, create_cls_pos_sikii, create_df\n",
    "\n",
    "sample_submission = pd.read_csv(\"../../inputs/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EziiDataset(\n",
    "    exp_names=CFG.train_exp_names,\n",
    "    base_dir=\"../../inputs/train\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.train_zarr_types,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "valid_dataset = EziiDataset(\n",
    "    exp_names=CFG.valid_exp_names,\n",
    "    # exp_names=CFG.train_exp_names,\n",
    "    base_dir=\"../../inputs/train\",\n",
    "    particles_name=CFG.particles_name,\n",
    "    resolution=CFG.resolution,\n",
    "    zarr_type=CFG.valid_zarr_types,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "for row in tqdm(valid_loader):\n",
    "    normalized_tomogram = row[\"normalized_tomogram\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadToSize(nn.Module):\n",
    "    def __init__(self, resolution):\n",
    "        super().__init__()\n",
    "        if resolution == \"0\":\n",
    "            self.size = 640\n",
    "        elif resolution == \"1\":\n",
    "            self.size = 320\n",
    "        elif resolution == \"2\":\n",
    "            self.size = 160\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.pad(x, (0, 0, self.size - x.shape[-1], self.size - x.shape[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3900193069940028: : 368it [00:17, 21.15it/s]\n"
     ]
    }
   ],
   "source": [
    "model = UNet_2D().to(\"cuda\")\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor([0.5, 32, 32, 32, 32, 32, 32]).to(\"cuda\")\n",
    ")\n",
    "# criterion = DiceLoss()\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "batch_size = 4\n",
    "\n",
    "valid_loss = []\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "model.eval()\n",
    "tq = tqdm(range(len(valid_loader) * normalized_tomogram.shape[0]))\n",
    "for data in valid_loader:\n",
    "    exp_name = data[\"exp_name\"][0]\n",
    "    tomogram = data[\"normalized_tomogram\"].to(\"cuda\")\n",
    "    segmentation_map = data[\"segmentation_map\"].to(\"cuda\").long()\n",
    "\n",
    "    for i in range(tomogram.shape[1]):\n",
    "        input_ = tomogram[:, i].unsqueeze(0)\n",
    "        gt = segmentation_map[:, i]\n",
    "\n",
    "        input_ = PadToSize(CFG.resolution)(input_)\n",
    "        gt = PadToSize(CFG.resolution)(gt)\n",
    "        output = model(input_)\n",
    "        output = nn.functional.softmax(output, dim=1)\n",
    "        loss = criterion(output, gt)\n",
    "\n",
    "        valid_loss.append(loss.item())\n",
    "        tq.set_description(f\"Loss: {np.mean(valid_loss)}\")\n",
    "        tq.update(1)\n",
    "\n",
    "        output = drop_padding(output, CFG.resolution)\n",
    "\n",
    "        valid_pred_tomogram[exp_name].append(output.cpu().detach().numpy())\n",
    "        valid_gt_tomogram[exp_name].append(gt.cpu().detach().numpy())\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_df(base_dir, exp_names):\n",
    "    result_df = None\n",
    "    particle_names = CFG.particles_name\n",
    "\n",
    "    for exp_name in exp_names:\n",
    "        for particle in particle_names:\n",
    "            np_corrds = read_info_json(\n",
    "                base_dir=base_dir, exp_name=exp_name, particle_name=particle\n",
    "            )  # (n, 3)\n",
    "            # 各行にexp_nameとparticle_name追加\n",
    "            particle_df = pd.DataFrame(np_corrds, columns=[\"z\", \"y\", \"x\"])\n",
    "            particle_df[\"experiment\"] = exp_name\n",
    "            particle_df[\"particle_type\"] = particle\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = particle_df\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, particle_df], axis=0).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "\n",
    "    result_df = result_df.reset_index()  # index\texperiment\tparticle_type\tx\ty\tz\n",
    "    result_df = result_df[[\"index\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"]]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.valid_exp_names)\n",
    "gt_df = gt_df[gt_df[\"particle_type\"] != \"beta-amylase\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pd.read_csv(\"../../inputs/train_submission.csv\")\n",
    "\n",
    "\n",
    "def calc_score(initial_sikii):\n",
    "    all_pred_df = None\n",
    "\n",
    "    for exp_name in CFG.valid_exp_names:\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "        # pred_df = create_df(pred_cls_pos, exp_name)\n",
    "\n",
    "        if all_pred_df is None:\n",
    "            all_pred_df = pred_df\n",
    "        else:\n",
    "            all_pred_df = pd.concat([all_pred_df, pred_df], axis=0).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "    pred_df = all_pred_df[all_pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "    pred_df = pred_df.drop_duplicates(subset=[\"x\", \"y\", \"z\"], keep=\"first\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    pred_df = pred_df.reset_index()\n",
    "\n",
    "    score_ = score(\n",
    "        pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "    )\n",
    "\n",
    "    return score_\n",
    "\n",
    "\n",
    "def calc_score_by_exp(initial_sikii):\n",
    "    exp_scores = {}\n",
    "\n",
    "    for exp_name in CFG.valid_exp_names:\n",
    "        gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", [exp_name])\n",
    "\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "\n",
    "        pred_df = pred_df[pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "        pred_df = pred_df.drop_duplicates(\n",
    "            subset=[\"x\", \"y\", \"z\"], keep=\"first\"\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        pred_df = pred_df.reset_index()\n",
    "\n",
    "        score_ = score(\n",
    "            pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "        )\n",
    "\n",
    "        exp_scores[exp_name] = score_\n",
    "\n",
    "    return exp_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40905056505945697"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = 0.35\n",
    "\n",
    "initial_sikii = {\n",
    "    \"apo-ferritin\": constant,\n",
    "    \"beta-amylase\": constant,\n",
    "    \"beta-galactosidase\": constant,\n",
    "    \"ribosome\": constant,\n",
    "    \"thyroglobulin\": constant,\n",
    "    \"virus-like-particle\": constant,\n",
    "}\n",
    "\n",
    "score_ = calc_score(initial_sikii)\n",
    "score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TS_86_3': 0.4891645161984996, 'TS_6_6': 0.32778489591101295}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = 0.35\n",
    "\n",
    "initial_sikii = {\n",
    "    \"apo-ferritin\": constant,\n",
    "    \"beta-amylase\": constant,\n",
    "    \"beta-galactosidase\": constant,\n",
    "    \"ribosome\": constant,\n",
    "    \"thyroglobulin\": constant,\n",
    "    \"virus-like-particle\": constant,\n",
    "}\n",
    "\n",
    "score_ = calc_score_by_exp(initial_sikii)\n",
    "score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.36800004366629324\n",
      "0.25202020202020203 0.37121187025437813\n",
      "0.25404040404040407 0.37147745064740506\n",
      "0.25606060606060604 0.372337397464804\n",
      "0.2580808080808081 0.37440163157323697\n",
      "0.2601010101010101 0.3748863455423777\n",
      "0.26212121212121214 0.3757872057637299\n",
      "0.2641414141414141 0.3765742670927833\n",
      "0.26616161616161615 0.3810862487128103\n",
      "0.2681818181818182 0.38125061856186443\n",
      "0.2702020202020202 0.3803468781414561\n",
      "0.2722222222222222 0.38125061856186443\n",
      "0.27424242424242423 0.38319018423286166\n",
      "0.27626262626262627 0.38319018423286166\n",
      "0.2782828282828283 0.3843242854559256\n",
      "0.2803030303030303 0.38871518329401195\n",
      "0.2823232323232323 0.38168590658685514\n",
      "0.28434343434343434 0.3818364510556787\n",
      "0.2863636363636364 0.3827369846215912\n",
      "0.2883838383838384 0.38093820851302207\n",
      "0.2904040404040404 0.3837330744657828\n",
      "0.2924242424242424 0.38225237994322253\n",
      "0.29444444444444445 0.38328759351582936\n",
      "0.2964646464646465 0.38631377037639264\n",
      "0.29848484848484846 0.38809948466210686\n",
      "0.3005050505050505 0.38756133010165306\n",
      "0.30252525252525253 0.3868152589028688\n",
      "0.30454545454545456 0.385226168883852\n",
      "0.3065656565656566 0.38532041282213303\n",
      "0.3085858585858586 0.3850137423971969\n",
      "0.3106060606060606 0.38807294894804045\n",
      "0.31262626262626264 0.3919765109142742\n",
      "0.3146464646464646 0.39369494166310864\n",
      "0.31666666666666665 0.39417042771551775\n",
      "0.3186868686868687 0.39494262848771855\n",
      "0.3207070707070707 0.39625285672102367\n",
      "0.32272727272727275 0.40103358283800433\n",
      "0.32474747474747473 0.40064834621115697\n",
      "0.32676767676767676 0.40064834621115697\n",
      "0.3287878787878788 0.40015650746382375\n",
      "0.3308080808080808 0.4020749905293028\n",
      "0.3328282828282828 0.4015107006959403\n",
      "0.33484848484848484 0.40255863006735776\n",
      "0.3368686868686869 0.4029536114390281\n",
      "0.3388888888888889 0.40345844197434644\n",
      "0.34090909090909094 0.40448680047221713\n",
      "0.3429292929292929 0.4037638498470605\n",
      "0.34494949494949495 0.40480494379864485\n",
      "0.346969696969697 0.4062030503227003\n",
      "0.34898989898989896 0.4082978088352473\n",
      "0.351010101010101 0.4085232976114578\n",
      "0.353030303030303 0.40983112632892504\n",
      "0.35505050505050506 0.410448587694078\n",
      "0.3570707070707071 0.4115557628984958\n",
      "0.35909090909090907 0.41262624692519495\n",
      "0.3611111111111111 0.41208776102085537\n",
      "0.36313131313131314 0.41793031723920676\n",
      "0.36515151515151517 0.4195748892041316\n",
      "0.36717171717171715 0.4208969642736505\n",
      "0.3691919191919192 0.4212366475482799\n",
      "0.3712121212121212 0.419070378282954\n",
      "0.37323232323232325 0.41898672124854536\n",
      "0.3752525252525253 0.4199769627753596\n",
      "0.37727272727272726 0.4081486757182663\n",
      "0.3792929292929293 0.40530649513826916\n",
      "0.3813131313131313 0.40591950895494305\n",
      "0.3833333333333333 0.40413164837802\n",
      "0.38535353535353534 0.4080152423172961\n",
      "0.38737373737373737 0.4052345974326424\n",
      "0.3893939393939394 0.40468773645951417\n",
      "0.39141414141414144 0.4060938572204736\n",
      "0.39343434343434347 0.40748206561505146\n",
      "0.39545454545454545 0.4050100254404393\n",
      "0.3974747474747475 0.4056803847692903\n",
      "0.39949494949494946 0.4080148466350653\n",
      "0.4015151515151515 0.40717734025958424\n",
      "0.4035353535353535 0.4077297448442469\n",
      "0.40555555555555556 0.406872089954334\n",
      "0.4075757575757576 0.40828932351442465\n",
      "0.4095959595959596 0.4095750759471041\n",
      "0.4116161616161616 0.40565466850185994\n",
      "0.41363636363636364 0.40565466850185994\n",
      "0.41565656565656567 0.40362583590653395\n",
      "0.41767676767676765 0.3885507013355767\n",
      "0.4196969696969697 0.39104248894204063\n",
      "0.4217171717171717 0.3911128467241367\n",
      "0.42373737373737375 0.3905646011101016\n",
      "0.4257575757575758 0.39097225761490895\n",
      "0.4277777777777778 0.3887622469872555\n",
      "0.4297979797979798 0.40173226887914104\n",
      "0.4318181818181818 0.4028885624898709\n",
      "0.4338383838383838 0.40053414451825103\n",
      "0.43585858585858583 0.40012648801344375\n",
      "0.43787878787878787 0.3996102100736964\n",
      "0.4398989898989899 0.3994939980685568\n",
      "0.44191919191919193 0.3993086057728291\n",
      "0.44393939393939397 0.3982967010109243\n",
      "0.445959595959596 0.39794909902136005\n",
      "0.447979797979798 0.39859817247430884\n",
      "0.45 0.39978319829977543\n"
     ]
    }
   ],
   "source": [
    "best_sikii = 0\n",
    "best_score = -np.inf\n",
    "\n",
    "for sikii in np.linspace(0.3, 0.7, 100):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": sikii,\n",
    "        \"beta-amylase\": sikii,\n",
    "        \"beta-galactosidase\": sikii,\n",
    "        \"ribosome\": sikii,\n",
    "        \"thyroglobulin\": sikii,\n",
    "        \"virus-like-particle\": sikii,\n",
    "    }\n",
    "    score_ = calc_score(initial_sikii)\n",
    "    if score_ > best_score:\n",
    "        best_score = score_\n",
    "        best_sikii = sikii\n",
    "    print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3691919191919192, 0.4212366475482799)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sikii, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.35843947565426: : 3680it [04:45, 12.91it/s]                      \n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor([0.5, 32, 32, 32, 32, 32, 32]).to(\"cuda\")\n",
    ")\n",
    "# criterion = DiceLoss()\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "batch_size = 4\n",
    "\n",
    "train_loss = []\n",
    "valid_pred_tomogram = defaultdict(list)\n",
    "valid_gt_tomogram = defaultdict(list)\n",
    "model.eval()\n",
    "tq = tqdm(range(len(train_loader) * normalized_tomogram.shape[0]))\n",
    "for data in train_loader:\n",
    "    exp_name = data[\"exp_name\"][0]\n",
    "    tomogram = data[\"normalized_tomogram\"].to(\"cuda\")\n",
    "    segmentation_map = data[\"segmentation_map\"].to(\"cuda\").long()\n",
    "\n",
    "    for i in range(tomogram.shape[1]):\n",
    "        input_ = tomogram[:, i].unsqueeze(0)\n",
    "        gt = segmentation_map[:, i]\n",
    "\n",
    "        input_ = PadToSize(CFG.resolution)(input_)\n",
    "        gt = PadToSize(CFG.resolution)(gt)\n",
    "        output = model(input_)\n",
    "        output = nn.functional.softmax(output, dim=1)\n",
    "        loss = criterion(output, gt)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        tq.set_description(f\"Loss: {np.mean(train_loss)}\")\n",
    "        tq.update(1)\n",
    "\n",
    "        output = drop_padding(output, CFG.resolution)\n",
    "\n",
    "        valid_pred_tomogram[exp_name].append(output.cpu().detach().numpy())\n",
    "        valid_gt_tomogram[exp_name].append(gt.cpu().detach().numpy())\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(initial_sikii):\n",
    "    all_pred_df = None\n",
    "\n",
    "    for exp_name in CFG.train_exp_names:\n",
    "        pred_tomogram = valid_pred_tomogram[exp_name]\n",
    "        pred_tomogram = np.array(pred_tomogram)  # (92, 1, 7, 315, 315)\n",
    "        pred_tomogram = pred_tomogram.squeeze(1)  # (92, 7, 315, 315)\n",
    "\n",
    "        pred_cls_pos, pred_Ascale_pos = create_cls_pos_sikii(\n",
    "            pred_tomogram, sikii_dict=initial_sikii\n",
    "        )\n",
    "        pred_df = create_df(pred_Ascale_pos, exp_name)\n",
    "        # pred_df = create_df(pred_cls_pos, exp_name)\n",
    "\n",
    "        if all_pred_df is None:\n",
    "            all_pred_df = pred_df\n",
    "        else:\n",
    "            all_pred_df = pd.concat([all_pred_df, pred_df], axis=0).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "    pred_df = all_pred_df[all_pred_df[\"particle_type\"] != \"beta-amylase\"]\n",
    "    pred_df = pred_df.drop_duplicates(subset=[\"x\", \"y\", \"z\"], keep=\"first\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    pred_df = pred_df.reset_index()\n",
    "\n",
    "    score_ = score(\n",
    "        pred_df, gt_df, row_id_column_name=\"index\", distance_multiplier=1, beta=4\n",
    "    )\n",
    "\n",
    "    return score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = create_gt_df(\"../../inputs/train/overlay/ExperimentRuns/\", CFG.train_exp_names)\n",
    "gt_df = gt_df[gt_df[\"particle_type\"] != \"beta-amylase\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.2158016280706467\n",
      "0.25202020202020203 0.21571803316555968\n",
      "0.25404040404040407 0.2164215309217528\n",
      "0.25606060606060604 0.21706368654184563\n",
      "0.2580808080808081 0.2178370344852624\n",
      "0.2601010101010101 0.21818796410467947\n",
      "0.26212121212121214 0.21832081553992375\n",
      "0.2641414141414141 0.21837685013150118\n",
      "0.26616161616161615 0.21852894902050662\n",
      "0.2681818181818182 0.21859694292454002\n",
      "0.2702020202020202 0.21818692123634978\n",
      "0.2722222222222222 0.21831692195465724\n",
      "0.27424242424242423 0.21886794983117955\n"
     ]
    }
   ],
   "source": [
    "best_sikii = 0\n",
    "best_score = -np.inf\n",
    "\n",
    "for sikii in np.linspace(0.25, 0.45, 100):\n",
    "    initial_sikii = {\n",
    "        \"apo-ferritin\": sikii,\n",
    "        \"beta-amylase\": sikii,\n",
    "        \"beta-galactosidase\": sikii,\n",
    "        \"ribosome\": sikii,\n",
    "        \"thyroglobulin\": sikii,\n",
    "        \"virus-like-particle\": sikii,\n",
    "    }\n",
    "    score_ = calc_score(initial_sikii)\n",
    "    if score_ > best_score:\n",
    "        best_score = score_\n",
    "        best_sikii = sikii\n",
    "    print(sikii, score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
